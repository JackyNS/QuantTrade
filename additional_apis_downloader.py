#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ–°å¢žAPIä¸‹è½½å™¨ - ä¸‹è½½8ä¸ªé¢å¤–çš„é‡è¦æ•°æ®æŽ¥å£
"""

import uqer
import pandas as pd
from pathlib import Path
import logging
from datetime import datetime, date
import time

class AdditionalAPIsDownloader:
    """æ–°å¢žAPIä¸‹è½½å™¨"""
    
    def __init__(self, token):
        self.token = token
        self.target_dir = Path("data/final_comprehensive_download/additional_apis")
        self.target_dir.mkdir(exist_ok=True)
        self.setup_logging()
        
        # éœ€è¦ä¸‹è½½çš„APIé…ç½® - ä½¿ç”¨æ­£ç¡®çš„APIåç§°
        self.additional_apis = {
            "EquFancyFactorsLiteGet": {
                "dir_name": "equ_fancy_factors_lite",
                "description": "è‚¡ç²¾é€‰ç²¾å“å› å­æ•°æ®",
                "date_pattern": "daily",
                "start_date": "20200101",
                "end_date": "20250901"
            },
            "EcoDataChinaLiteGet": {
                "dir_name": "eco_data_china_lite", 
                "description": "å®è§‚è¡Œä¸š-ä¸­å›½å®è§‚é‡ç‚¹æŒ‡æ ‡",
                "date_pattern": "monthly",
                "start_date": "20200101", 
                "end_date": "20250901"
            },
            "SecTypeRegionGet": {
                "dir_name": "sec_type_region",
                "description": "åœ°åŸŸåˆ†ç±»",
                "date_pattern": "snapshot",
                "start_date": None,
                "end_date": None
            },
            "SecTypeRelGet": {
                "dir_name": "sec_type_rel",
                "description": "è¯åˆ¸æ¿å—æˆåˆ†",
                "date_pattern": "snapshot",
                "start_date": None,
                "end_date": None
            },
            "SecTypeGet": {
                "dir_name": "sec_type",
                "description": "è¯åˆ¸æ¿å—",
                "date_pattern": "snapshot", 
                "start_date": None,
                "end_date": None
            },
            "IndustryGet": {
                "dir_name": "industry",
                "description": "è¡Œä¸šåˆ†ç±»æ ‡å‡†",
                "date_pattern": "snapshot",
                "start_date": None,
                "end_date": None
            },
            "FstTotalGet": {
                "dir_name": "fst_total",
                "description": "æ²ªæ·±èžèµ„èžåˆ¸æ¯æ—¥æ±‡æ€»ä¿¡æ¯",
                "date_pattern": "daily",
                "start_date": "20200101",
                "end_date": "20250901"
            },
            "FstDetailGet": {
                "dir_name": "fst_detail", 
                "description": "æ²ªæ·±èžèµ„èžåˆ¸æ¯æ—¥äº¤æ˜“æ˜Žç»†ä¿¡æ¯",
                "date_pattern": "daily",
                "start_date": "20200101",
                "end_date": "20250901"
            }
        }
    
    def setup_logging(self):
        """è®¾ç½®æ—¥å¿—"""
        log_file = Path("additional_apis_download.log")
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_file, encoding='utf-8'),
                logging.StreamHandler()
            ]
        )
    
    def login_uqer(self):
        """ç™»å½•ä¼˜çŸ¿"""
        try:
            client = uqer.Client(token=self.token)
            logging.info("âœ… ä¼˜çŸ¿ç™»å½•æˆåŠŸ")
            return client
        except Exception as e:
            logging.error(f"âŒ ä¼˜çŸ¿ç™»å½•å¤±è´¥: {e}")
            return None
    
    def check_api_existence(self):
        """æ£€æŸ¥APIæ˜¯å¦å­˜åœ¨"""
        logging.info("ðŸ” æ£€æŸ¥æ–°å¢žAPIæ˜¯å¦å­˜åœ¨...")
        
        available_apis = []
        
        for api_name in self.additional_apis.keys():
            if hasattr(uqer.DataAPI, api_name):
                logging.info(f"âœ… æ‰¾åˆ°API: {api_name}")
                available_apis.append(api_name)
            else:
                logging.error(f"âŒ APIä¸å­˜åœ¨: {api_name}")
        
        return available_apis
    
    def generate_date_list(self, start_date, end_date, pattern):
        """ç”Ÿæˆæ—¥æœŸåˆ—è¡¨"""
        if pattern == "snapshot":
            return [("", "snapshot")]
        
        date_list = []
        
        if pattern == "daily":
            # æŒ‰å¹´ç”Ÿæˆï¼Œæ¯å¹´å–4ä¸ªå­£åº¦æœ«
            for year in range(2020, 2026):
                quarters = [
                    f"{year}0331",
                    f"{year}0630", 
                    f"{year}0930",
                    f"{year}1231"
                ]
                for i, quarter_date in enumerate(quarters, 1):
                    if year == 2025 and i > 3:  # 2025å¹´åªåˆ°Q3
                        break
                    date_list.append((quarter_date, f"{year}_Q{i}"))
                        
        elif pattern == "monthly":
            # æŒ‰å¹´ç”Ÿæˆ
            for year in range(2020, 2026):
                if year == 2025:
                    break
                date_list.append((f"{year}1231", f"year_{year}"))
        
        return date_list
    
    def download_snapshot_api(self, api_name, api_config):
        """ä¸‹è½½å¿«ç…§åž‹APIï¼ˆæ— æ—¥æœŸå‚æ•°ï¼‰"""
        logging.info(f"ðŸ“¸ ä¸‹è½½å¿«ç…§API: {api_name}")
        
        api_dir = self.target_dir / api_config["dir_name"]
        api_dir.mkdir(exist_ok=True)
        
        output_file = api_dir / "snapshot.csv"
        
        if output_file.exists():
            logging.info(f"â­ï¸ æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡: snapshot.csv")
            return 1, 0
        
        try:
            api_func = getattr(uqer.DataAPI, api_name)
            result = api_func()
            
            if hasattr(result, 'getData') and callable(getattr(result, 'getData')):
                df = result.getData()
            else:
                df = result
            
            if df is None or (isinstance(df, pd.DataFrame) and df.empty):
                logging.warning(f"âš ï¸ æ— æ•°æ®: {api_name}")
                return 0, 0
            
            df.to_csv(output_file, index=False, encoding='utf-8')
            logging.info(f"âœ… æˆåŠŸ: {len(df):,} æ¡è®°å½•")
            return 1, len(df)
            
        except Exception as e:
            logging.error(f"âŒ ä¸‹è½½å¤±è´¥ {api_name}: {e}")
            return 0, 0
    
    def download_dated_api(self, api_name, api_config):
        """ä¸‹è½½æœ‰æ—¥æœŸå‚æ•°çš„API"""
        logging.info(f"ðŸ“… ä¸‹è½½æ—¥æœŸåž‹API: {api_name}")
        
        api_dir = self.target_dir / api_config["dir_name"]
        api_dir.mkdir(exist_ok=True)
        
        api_func = getattr(uqer.DataAPI, api_name)
        date_list = self.generate_date_list(
            api_config["start_date"], 
            api_config["end_date"], 
            api_config["date_pattern"]
        )
        
        success_count = 0
        total_records = 0
        
        for i, (trade_date, filename) in enumerate(date_list, 1):
            try:
                logging.info(f"ðŸ“¥ [{i}/{len(date_list)}] {api_name} - {filename}")
                
                output_file = api_dir / f"{filename}.csv"
                
                if output_file.exists():
                    logging.info(f"â­ï¸ æ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡: {filename}")
                    continue
                
                # å°è¯•ä¸åŒçš„å‚æ•°ç»„åˆ
                result = None
                param_combinations = [
                    {"tradeDate": trade_date} if trade_date else {},
                    {"beginDate": trade_date, "endDate": trade_date} if trade_date else {},
                    {"date": trade_date} if trade_date else {}
                ]
                
                for params in param_combinations:
                    try:
                        result = api_func(**params)
                        break
                    except:
                        continue
                
                if result is None:
                    # æ— å‚æ•°è°ƒç”¨
                    result = api_func()
                
                if hasattr(result, 'getData') and callable(getattr(result, 'getData')):
                    df = result.getData()
                else:
                    df = result
                
                if df is None or (isinstance(df, pd.DataFrame) and df.empty):
                    logging.warning(f"âš ï¸ æ— æ•°æ®: {filename}")
                    continue
                
                df.to_csv(output_file, index=False, encoding='utf-8')
                success_count += 1
                total_records += len(df)
                logging.info(f"âœ… æˆåŠŸ: {len(df):,} æ¡è®°å½•")
                
                time.sleep(0.3)
                
            except Exception as e:
                logging.error(f"âŒ ä¸‹è½½å¤±è´¥ {filename}: {e}")
                continue
        
        return success_count, total_records
    
    def download_single_api(self, api_name, api_config):
        """ä¸‹è½½å•ä¸ªAPI"""
        logging.info(f"ðŸš€ å¼€å§‹ä¸‹è½½ {api_name} ({api_config['description']})")
        
        if api_config["date_pattern"] == "snapshot":
            return self.download_snapshot_api(api_name, api_config)
        else:
            return self.download_dated_api(api_name, api_config)
    
    def run_download(self):
        """è¿è¡Œä¸‹è½½ä»»åŠ¡"""
        logging.info("ðŸš€ å¼€å§‹ä¸‹è½½æ–°å¢žçš„8ä¸ªAPI...")
        
        start_time = datetime.now()
        
        # ç™»å½•
        client = self.login_uqer()
        if not client:
            return False
        
        # æ£€æŸ¥APIå­˜åœ¨æ€§
        available_apis = self.check_api_existence()
        if not available_apis:
            logging.error("âŒ æ²¡æœ‰å¯ç”¨çš„API")
            return False
        
        total_stats = {
            "apis_downloaded": 0,
            "files_downloaded": 0,
            "total_records": 0
        }
        
        # é€ä¸ªä¸‹è½½API
        for api_name in available_apis:
            if api_name in self.additional_apis:
                api_config = self.additional_apis[api_name]
                
                try:
                    success_files, records = self.download_single_api(api_name, api_config)
                    
                    total_stats["apis_downloaded"] += 1
                    total_stats["files_downloaded"] += success_files
                    total_stats["total_records"] += records
                    
                except Exception as e:
                    logging.error(f"âŒ APIä¸‹è½½å¤±è´¥ {api_name}: {e}")
        
        # è¾“å‡ºæœ€ç»ˆç»Ÿè®¡
        end_time = datetime.now()
        duration = end_time - start_time
        
        logging.info("ðŸŽŠ æ–°å¢žAPIä¸‹è½½å®Œæˆ!")
        logging.info("=" * 50)
        logging.info(f"ðŸ“Š ä¸‹è½½ç»Ÿè®¡:")
        logging.info(f"  APIæ•°é‡: {total_stats['apis_downloaded']}")
        logging.info(f"  æ–‡ä»¶æ•°é‡: {total_stats['files_downloaded']}")
        logging.info(f"  è®°å½•æ€»æ•°: {total_stats['total_records']:,}")
        logging.info(f"  ç”¨æ—¶: {duration}")
        
        return total_stats["apis_downloaded"] > 0

if __name__ == "__main__":
    token = "68b9922817ae6273137bda7acba81e293582ba347281dfcc056dcb245b23faf3"
    downloader = AdditionalAPIsDownloader(token)
    downloader.run_download()