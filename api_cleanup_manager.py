#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
APIæ¸…ç†ç®¡ç†å™¨ - åˆ é™¤æ— æ•ˆAPIå’Œæ•´ç†æ•°æ®ç»“æ„
"""

import pandas as pd
from pathlib import Path
import shutil
import logging
from datetime import datetime

class APICleanupManager:
    """APIæ¸…ç†ç®¡ç†å™¨"""
    
    def __init__(self):
        self.base_dir = Path("data/final_comprehensive_download")
        self.setup_logging()
        
        # æ— æ•°æ®çš„APIåˆ—è¡¨ï¼ˆéœ€è¦åˆ é™¤ï¼‰
        self.invalid_apis = {
            'special_trading': ['equmarginsec', 'mktequperfget', 'equmarginsecget'],
            'additional_apis': ['eco_data_china_lite']
        }
        
    def setup_logging(self):
        """è®¾ç½®æ—¥å¿—"""
        log_file = Path("api_cleanup.log")
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_file, encoding='utf-8'),
                logging.StreamHandler()
            ]
        )
    
    def backup_current_structure(self):
        """å¤‡ä»½å½“å‰æ•°æ®ç»“æ„"""
        backup_dir = Path("data_backup_before_cleanup")
        if backup_dir.exists():
            shutil.rmtree(backup_dir)
        
        logging.info("ğŸ”„ åˆ›å»ºæ•°æ®ç»“æ„å¤‡ä»½...")
        
        # åªå¤‡ä»½ç›®å½•ç»“æ„ï¼Œä¸å¤‡ä»½å¤§æ–‡ä»¶
        for category_dir in self.base_dir.iterdir():
            if category_dir.is_dir():
                backup_category = backup_dir / category_dir.name
                backup_category.mkdir(parents=True, exist_ok=True)
                
                for api_dir in category_dir.iterdir():
                    if api_dir.is_dir():
                        backup_api = backup_category / api_dir.name
                        backup_api.mkdir(exist_ok=True)
                        
                        # åªå¤‡ä»½ç›®å½•ç»“æ„ä¿¡æ¯
                        info_file = backup_api / "info.txt"
                        csv_files = list(api_dir.glob("*.csv"))
                        with open(info_file, 'w', encoding='utf-8') as f:
                            f.write(f"åŸå§‹æ–‡ä»¶æ•°: {len(csv_files)}\n")
                            f.write(f"å¤‡ä»½æ—¶é—´: {datetime.now()}\n")
        
        logging.info(f"âœ… å¤‡ä»½å®Œæˆ: {backup_dir}")
    
    def remove_invalid_apis(self):
        """åˆ é™¤æ— æ•ˆçš„APIç›®å½•"""
        logging.info("ğŸ—‘ï¸ å¼€å§‹åˆ é™¤æ— æ•ˆAPI...")
        
        removed_count = 0
        for category, api_list in self.invalid_apis.items():
            category_path = self.base_dir / category
            if not category_path.exists():
                continue
                
            for api_name in api_list:
                api_path = category_path / api_name
                if api_path.exists():
                    try:
                        shutil.rmtree(api_path)
                        logging.info(f"ğŸ—‘ï¸ å·²åˆ é™¤: {category}/{api_name}")
                        removed_count += 1
                    except Exception as e:
                        logging.error(f"âŒ åˆ é™¤å¤±è´¥ {category}/{api_name}: {e}")
                else:
                    logging.warning(f"âš ï¸ ç›®å½•ä¸å­˜åœ¨: {category}/{api_name}")
        
        logging.info(f"âœ… åˆ é™¤å®Œæˆï¼Œå…±åˆ é™¤ {removed_count} ä¸ªæ— æ•ˆAPI")
        return removed_count
    
    def generate_cleanup_report(self):
        """ç”Ÿæˆæ¸…ç†æŠ¥å‘Š"""
        logging.info("ğŸ“Š ç”Ÿæˆæ¸…ç†æŠ¥å‘Š...")
        
        # é‡æ–°æ‰«æå½“å‰ç»“æ„
        current_structure = {}
        total_apis = 0
        total_files = 0
        total_size = 0
        
        for category_dir in self.base_dir.iterdir():
            if category_dir.is_dir():
                category_name = category_dir.name
                api_count = 0
                files_count = 0
                size_mb = 0
                
                for api_dir in category_dir.iterdir():
                    if api_dir.is_dir():
                        csv_files = list(api_dir.glob("*.csv"))
                        if csv_files:  # åªç»Ÿè®¡æœ‰æ•°æ®çš„API
                            api_count += 1
                            files_count += len(csv_files)
                            size_mb += sum(f.stat().st_size for f in csv_files) / (1024 * 1024)
                
                current_structure[category_name] = {
                    'api_count': api_count,
                    'file_count': files_count,
                    'size_mb': size_mb
                }
                
                total_apis += api_count
                total_files += files_count
                total_size += size_mb
        
        # ç”ŸæˆæŠ¥å‘Š
        report = []
        report.append("="*80)
        report.append("ğŸ§¹ **APIæ¸…ç†æŠ¥å‘Š**")
        report.append("="*80)
        report.append(f"ğŸ“… æ¸…ç†æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append("")
        report.append("ğŸ—‘ï¸ **å·²åˆ é™¤çš„æ— æ•ˆAPI:**")
        
        for category, api_list in self.invalid_apis.items():
            report.append(f"  ğŸ“ {category}:")
            for api_name in api_list:
                report.append(f"    âŒ {api_name}")
        
        report.append("")
        report.append("ğŸ“Š **æ¸…ç†åæ•°æ®ç»“æ„:**")
        report.append(f"  ğŸ”Œ æ€»APIæ•°é‡: {total_apis} ä¸ª")
        report.append(f"  ğŸ“„ æ€»æ–‡ä»¶æ•°é‡: {total_files} ä¸ª")
        report.append(f"  ğŸ’¾ æ€»æ•°æ®å¤§å°: {total_size:.1f} MB ({total_size/1024:.1f} GB)")
        report.append("")
        report.append("ğŸ“‹ **å„åˆ†ç±»ç»Ÿè®¡:**")
        
        for category, stats in current_structure.items():
            report.append(f"  ğŸ“ {category}: {stats['api_count']} APIs, "
                         f"{stats['file_count']} æ–‡ä»¶, {stats['size_mb']:.1f}MB")
        
        report.append("")
        report.append("âœ… **æ¸…ç†å®Œæˆï¼Œæ•°æ®ç»“æ„å·²ä¼˜åŒ–**")
        report.append("="*80)
        
        # è¾“å‡ºåˆ°æ§åˆ¶å°
        for line in report:
            print(line)
        
        # ä¿å­˜åˆ°æ–‡ä»¶
        with open('api_cleanup_report.txt', 'w', encoding='utf-8') as f:
            f.write('\n'.join(report))
        
        logging.info("ğŸ“„ æ¸…ç†æŠ¥å‘Šå·²ä¿å­˜: api_cleanup_report.txt")
        return current_structure
    
    def update_csv_reports(self, current_structure):
        """æ›´æ–°CSVæŠ¥å‘Šï¼Œç§»é™¤æ— æ•ˆAPIè®°å½•"""
        logging.info("ğŸ“ æ›´æ–°CSVæŠ¥å‘Šæ–‡ä»¶...")
        
        # éœ€è¦ç§»é™¤çš„APIåç§°
        apis_to_remove = []
        for category, api_list in self.invalid_apis.items():
            apis_to_remove.extend(api_list)
        
        # æ›´æ–°æ¦‚è§ˆæŠ¥å‘Š
        overview_file = Path("APIè¯¦ç»†åˆ†ææŠ¥å‘Š_æ¦‚è§ˆ.csv")
        if overview_file.exists():
            df_overview = pd.read_csv(overview_file)
            original_count = len(df_overview)
            
            # åˆ é™¤æ— æ•ˆAPIçš„è®°å½•
            df_overview = df_overview[~df_overview['api_name'].isin(apis_to_remove)]
            
            # ä¿å­˜æ›´æ–°åçš„æ–‡ä»¶
            df_overview.to_csv(overview_file, index=False, encoding='utf-8-sig')
            
            logging.info(f"ğŸ“Š æ¦‚è§ˆæŠ¥å‘Šå·²æ›´æ–°: åˆ é™¤ {original_count - len(df_overview)} ä¸ªæ— æ•ˆè®°å½•")
        
        # æ›´æ–°åˆ†ç±»æ±‡æ€»
        summary_file = Path("APIè¯¦ç»†åˆ†ææŠ¥å‘Š_åˆ†ç±»æ±‡æ€».csv")
        if summary_file.exists():
            # é‡æ–°ç”Ÿæˆåˆ†ç±»æ±‡æ€»
            summary_data = []
            for category, stats in current_structure.items():
                summary_data.append({
                    'category': category,
                    'api_count': stats['api_count'],
                    'apis_with_data': stats['api_count'], # ç°åœ¨æ‰€æœ‰APIéƒ½æœ‰æ•°æ®
                    'data_coverage_rate': 100.0,
                    'total_files': stats['file_count'],
                    'total_size_mb': stats['size_mb'],
                    'estimated_total_records': stats['file_count'] * 1000  # ä¼°ç®—
                })
            
            df_summary = pd.DataFrame(summary_data)
            df_summary.to_csv(summary_file, index=False, encoding='utf-8-sig')
            
            logging.info("ğŸ“Š åˆ†ç±»æ±‡æ€»æŠ¥å‘Šå·²æ›´æ–°")
    
    def run_cleanup(self):
        """æ‰§è¡Œå®Œæ•´çš„æ¸…ç†æµç¨‹"""
        logging.info("ğŸš€ å¼€å§‹APIæ¸…ç†æµç¨‹...")
        
        # 1. å¤‡ä»½
        self.backup_current_structure()
        
        # 2. åˆ é™¤æ— æ•ˆAPI
        removed_count = self.remove_invalid_apis()
        
        # 3. ç”ŸæˆæŠ¥å‘Š
        current_structure = self.generate_cleanup_report()
        
        # 4. æ›´æ–°CSVæŠ¥å‘Š
        self.update_csv_reports(current_structure)
        
        logging.info("ğŸŠ APIæ¸…ç†æµç¨‹å®Œæˆï¼")
        return current_structure

if __name__ == "__main__":
    cleanup_manager = APICleanupManager()
    result = cleanup_manager.run_cleanup()