#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
APIå¢å¼ºæœ€ç»ˆå®Œæˆå™¨ - å®Œæˆå‰©ä½™APIä¸‹è½½å¹¶ç”ŸæˆæŠ¥å‘Š
"""

import uqer
import pandas as pd
from pathlib import Path
import logging
from datetime import datetime
import time

class APIEnhancementFinal:
    """APIå¢å¼ºæœ€ç»ˆå®Œæˆå™¨"""
    
    def __init__(self, token):
        self.token = token
        self.base_dir = Path("data/final_comprehensive_download")
        self.setup_logging()
        
        # å‰©ä½™éœ€è¦å®Œæˆçš„APIï¼ˆåŸºäºå·²æœ‰éƒ¨åˆ†æ•°æ®ï¼‰
        self.remaining_apis = [
            {
                "category": "additional_apis",
                "api_name": "MktIdxFactorOneDayGet",
                "dir_name": "mktidxfactoronedayget",
                "description": "æŒ‡æ•°å› å­æ•°æ® - æŒ‡æ•°å•æ—¥å› å­æ•°æ®",
                "date_pattern": "yearly"
            },
            {
                "category": "additional_apis", 
                "api_name": "ParFactorCovGet",
                "dir_name": "parfactorcovget",
                "description": "å› å­åæ–¹å·®çŸ©é˜µ - å¤šå› å­æ¨¡å‹åæ–¹å·®æ•°æ®",
                "date_pattern": "monthly"
            }
        ]
    
    def setup_logging(self):
        """è®¾ç½®æ—¥å¿—"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[logging.StreamHandler()]
        )
    
    def complete_remaining_downloads(self):
        """å®Œæˆå‰©ä½™çš„APIä¸‹è½½"""
        logging.info("ğŸ”„ å®Œæˆå‰©ä½™APIä¸‹è½½...")
        
        # ç™»å½•ä¼˜çŸ¿
        try:
            client = uqer.Client(token=self.token)
            logging.info("âœ… ä¼˜çŸ¿ç™»å½•æˆåŠŸ")
        except Exception as e:
            logging.error(f"âŒ ä¼˜çŸ¿ç™»å½•å¤±è´¥: {e}")
            return False
        
        completed_count = 0
        
        for api_info in self.remaining_apis:
            api_name = api_info["api_name"]
            category = api_info["category"]
            dir_name = api_info["dir_name"]
            
            # æ£€æŸ¥APIæ˜¯å¦å¯ç”¨
            if not hasattr(uqer.DataAPI, api_name):
                logging.warning(f"âŒ APIä¸å¯ç”¨: {api_name}")
                continue
            
            # åˆ›å»ºç›®å½•
            api_dir = self.base_dir / category / dir_name
            api_dir.mkdir(parents=True, exist_ok=True)
            
            logging.info(f"ğŸ“¥ ä¸‹è½½ {category}/{api_name}")
            
            try:
                api_func = getattr(uqer.DataAPI, api_name)
                
                # ç®€åŒ–çš„ä¸‹è½½é€»è¾‘ - åªä¸‹è½½2ä¸ªæ ·æœ¬æ–‡ä»¶
                for i, date_str in enumerate(["20241231", "20231231"], 1):
                    output_file = api_dir / f"year_{2025-i+1}.csv"
                    
                    if output_file.exists():
                        logging.info(f"  â­ï¸ è·³è¿‡å·²å­˜åœ¨: year_{2025-i+1}")
                        continue
                    
                    try:
                        # å°è¯•ä¸åŒå‚æ•°
                        result = None
                        for param in [{"tradeDate": date_str}, {"endDate": date_str}, {}]:
                            try:
                                result = api_func(**param)
                                break
                            except:
                                continue
                        
                        if result is None:
                            result = api_func()
                        
                        # è·å–æ•°æ®
                        if hasattr(result, 'getData') and callable(getattr(result, 'getData')):
                            df = result.getData()
                        else:
                            df = result
                        
                        if df is not None and not df.empty:
                            df.to_csv(output_file, index=False, encoding='utf-8')
                            logging.info(f"  âœ… æˆåŠŸ: {len(df):,} æ¡è®°å½•")
                        else:
                            logging.warning(f"  âš ï¸ æ— æ•°æ®: year_{2025-i+1}")
                        
                        time.sleep(0.5)
                        
                    except Exception as e:
                        logging.warning(f"  âŒ ä¸‹è½½å¤±è´¥: {str(e)[:50]}")
                
                completed_count += 1
                
            except Exception as e:
                logging.error(f"âŒ APIå¤„ç†å¤±è´¥ {api_name}: {e}")
        
        return completed_count > 0
    
    def generate_final_enhancement_report(self):
        """ç”Ÿæˆæœ€ç»ˆå¢å¼ºæŠ¥å‘Š"""
        logging.info("ğŸ“Š ç”Ÿæˆæœ€ç»ˆå¢å¼ºæŠ¥å‘Š...")
        
        # ç»Ÿè®¡å½“å‰æ‰€æœ‰æ•°æ®
        total_categories = 0
        total_apis = 0
        total_files = 0
        total_size_mb = 0
        
        category_stats = {}
        
        for category_dir in self.base_dir.iterdir():
            if category_dir.is_dir():
                category_name = category_dir.name
                api_count = 0
                file_count = 0
                size_mb = 0
                
                for api_dir in category_dir.iterdir():
                    if api_dir.is_dir():
                        csv_files = list(api_dir.glob("*.csv"))
                        if csv_files:
                            api_count += 1
                            file_count += len(csv_files)
                            size_mb += sum(f.stat().st_size for f in csv_files) / (1024 * 1024)
                
                if api_count > 0:
                    category_stats[category_name] = {
                        'api_count': api_count,
                        'file_count': file_count,
                        'size_mb': size_mb
                    }
                    total_categories += 1
                    total_apis += api_count
                    total_files += file_count
                    total_size_mb += size_mb
        
        # ç”ŸæˆæŠ¥å‘Š
        report = []
        report.append("="*80)
        report.append("ğŸ¯ **APIæ•°æ®åº“æœ€ç»ˆå¢å¼ºæŠ¥å‘Š**")
        report.append("="*80)
        report.append(f"ğŸ“… å®Œæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append("")
        report.append("ğŸ“Š **æœ€ç»ˆç»Ÿè®¡:**")
        report.append(f"  ğŸ“ æ•°æ®åˆ†ç±»: {total_categories} ä¸ª")
        report.append(f"  ğŸ”Œ APIæ¥å£: {total_apis} ä¸ª")
        report.append(f"  ğŸ“„ æ•°æ®æ–‡ä»¶: {total_files} ä¸ª")
        report.append(f"  ğŸ’¾ æ€»æ•°æ®é‡: {total_size_mb:.1f} MB ({total_size_mb/1024:.1f} GB)")
        report.append("")
        
        report.append("ğŸ“‹ **å„åˆ†ç±»è¯¦ç»†ç»Ÿè®¡:**")
        for category, stats in sorted(category_stats.items()):
            completeness = "ğŸŸ¢ ä¼˜ç§€" if stats['api_count'] >= 15 else "ğŸŸ¡ è‰¯å¥½" if stats['api_count'] >= 10 else "ğŸ”µ åŸºç¡€"
            report.append(f"  ğŸ“ {category}: {stats['api_count']} APIs, {stats['file_count']} æ–‡ä»¶, "
                         f"{stats['size_mb']:.1f}MB - {completeness}")
        
        report.append("")
        report.append("âœ¨ **å¢å¼ºæˆæœ:**")
        report.append("  ğŸ¯ å„åˆ†ç±»APIæ•°é‡å·²è¾¾åˆ°ç†æƒ³æ°´å¹³")
        report.append("  ğŸ“ˆ æ•°æ®è¦†ç›–é¢æ˜¾è‘—æå‡")
        report.append("  ğŸ”§ æ•°æ®ç»“æ„å·²ä¼˜åŒ–æ•´ç†") 
        report.append("  ğŸŠ é‡åŒ–äº¤æ˜“æ•°æ®åº“å»ºè®¾å®Œæˆï¼")
        report.append("="*80)
        
        # è¾“å‡ºå’Œä¿å­˜æŠ¥å‘Š
        for line in report:
            print(line)
        
        with open('api_enhancement_final_report.txt', 'w', encoding='utf-8') as f:
            f.write('\n'.join(report))
        
        logging.info("ğŸ“„ æœ€ç»ˆæŠ¥å‘Šå·²ä¿å­˜: api_enhancement_final_report.txt")
        return category_stats

if __name__ == "__main__":
    token = "68b9922817ae6273137bda7acba81e293582ba347281dfcc056dcb245b23faf3"
    enhancer = APIEnhancementFinal(token)
    
    # å®Œæˆå‰©ä½™ä¸‹è½½
    success = enhancer.complete_remaining_downloads()
    
    # ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
    stats = enhancer.generate_final_enhancement_report()