#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é¡¹ç›®ç»“æ„åˆ†æå’Œä¼˜åŒ–å·¥å…·
"""

import os
from pathlib import Path
from datetime import datetime
import json

class ProjectAnalyzer:
    """é¡¹ç›®ç»“æ„åˆ†æå™¨"""
    
    def __init__(self):
        self.root = Path(".")
        self.analysis = {
            'redundant_files': [],
            'temporary_files': [],
            'outdated_files': [],
            'duplicate_functionality': [],
            'optimization_suggestions': []
        }
    
    def analyze_root_files(self):
        """åˆ†ææ ¹ç›®å½•æ–‡ä»¶"""
        print("ğŸ” åˆ†ææ ¹ç›®å½•æ–‡ä»¶...")
        
        # åˆ†ç±»æ–‡ä»¶
        categories = {
            'core_scripts': [],
            'data_downloaders': [],
            'analysis_tools': [],
            'setup_tools': [],
            'test_files': [],
            'temporary_files': [],
            'documentation': [],
            'config_files': []
        }
        
        # Python æ–‡ä»¶åˆ†æ
        py_files = list(self.root.glob("*.py"))
        print(f"ğŸ“Š æ ¹ç›®å½•Pythonæ–‡ä»¶: {len(py_files)} ä¸ª")
        
        for file in py_files:
            filename = file.name
            
            # æ ¸å¿ƒè„šæœ¬
            if filename in ['main.py', 'setup.py']:
                categories['core_scripts'].append(filename)
            
            # æ•°æ®ä¸‹è½½å™¨
            elif any(keyword in filename for keyword in ['download', 'uqer', 'historical', 'priority', 'smart']):
                categories['data_downloaders'].append(filename)
            
            # åˆ†æå·¥å…·
            elif any(keyword in filename for keyword in ['analyze', 'analysis', 'monitor', 'quality', 'optimizer']):
                categories['analysis_tools'].append(filename)
            
            # è®¾ç½®å·¥å…·
            elif any(keyword in filename for keyword in ['setup', 'github', 'backup', 'scheduler']):
                categories['setup_tools'].append(filename)
            
            # æµ‹è¯•æ–‡ä»¶
            elif any(keyword in filename for keyword in ['test', 'check', 'simple', 'example']):
                categories['test_files'].append(filename)
            
            # ä¸´æ—¶æ–‡ä»¶
            elif any(keyword in filename for keyword in ['temp', 'tmp', 'old', 'backup']):
                categories['temporary_files'].append(filename)
        
        # Markdown æ–‡ä»¶
        md_files = list(self.root.glob("*.md"))
        print(f"ğŸ“‹ æ ¹ç›®å½•Markdownæ–‡ä»¶: {len(md_files)} ä¸ª")
        
        for file in md_files:
            categories['documentation'].append(file.name)
        
        # é…ç½®æ–‡ä»¶
        config_files = list(self.root.glob("*.json")) + list(self.root.glob("*.txt"))
        for file in config_files:
            categories['config_files'].append(file.name)
        
        return categories
    
    def identify_redundant_files(self, categories):
        """è¯†åˆ«å†—ä½™æ–‡ä»¶"""
        print("\nğŸ” è¯†åˆ«å†—ä½™å’Œé‡å¤æ–‡ä»¶...")
        
        redundant_files = []
        
        # æ•°æ®ä¸‹è½½å™¨é‡å¤æ£€æŸ¥
        downloaders = categories['data_downloaders']
        if len(downloaders) > 5:  # è¶…è¿‡5ä¸ªä¸‹è½½å™¨å¯èƒ½æœ‰å†—ä½™
            redundant_files.extend([
                {
                    'file': f,
                    'reason': 'å¯èƒ½çš„å†—ä½™ä¸‹è½½å™¨',
                    'action': 'review_and_merge'
                } for f in downloaders[5:]  # ä¿ç•™å‰5ä¸ª
            ])
        
        # æµ‹è¯•æ–‡ä»¶æ£€æŸ¥
        test_files = categories['test_files']
        redundant_files.extend([
            {
                'file': f,
                'reason': 'ä¸´æ—¶æµ‹è¯•æ–‡ä»¶',
                'action': 'move_to_tests_dir'
            } for f in test_files if 'simple' in f or 'example' in f
        ])
        
        # åˆ†æå·¥å…·é‡å¤æ£€æŸ¥
        analysis_files = categories['analysis_tools']
        if 'analyze_existing_data.py' in analysis_files and 'detailed_data_analysis.py' in analysis_files:
            redundant_files.append({
                'file': 'analyze_existing_data.py',
                'reason': 'detailed_data_analysis.pyæä¾›æ›´å®Œæ•´åŠŸèƒ½',
                'action': 'remove'
            })
        
        return redundant_files
    
    def identify_temporary_files(self, categories):
        """è¯†åˆ«ä¸´æ—¶æ–‡ä»¶"""
        temporary_files = []
        
        # æ˜æ˜¾çš„ä¸´æ—¶æ–‡ä»¶
        for file in categories['temporary_files']:
            temporary_files.append({
                'file': file,
                'reason': 'ä¸´æ—¶æ–‡ä»¶',
                'action': 'remove'
            })
        
        # GitHubè®¾ç½®ç›¸å…³æ–‡ä»¶
        github_setup_files = [f for f in categories['setup_tools'] 
                             if 'github' in f and f != 'auto_backup.py']
        for file in github_setup_files:
            if file != 'setup_daily_backup.py':  # ä¿ç•™æœ‰ç”¨çš„è®¾ç½®è„šæœ¬
                temporary_files.append({
                    'file': file,
                    'reason': 'GitHubè®¾ç½®å®Œæˆåä¸å†éœ€è¦',
                    'action': 'move_to_archive'
                })
        
        return temporary_files
    
    def check_file_usage(self):
        """æ£€æŸ¥æ–‡ä»¶ä½¿ç”¨æƒ…å†µ"""
        print("\nğŸ” æ£€æŸ¥æ–‡ä»¶ä½¿ç”¨å’Œä¾èµ–...")
        
        # æ£€æŸ¥importä½¿ç”¨æƒ…å†µ
        py_files = list(self.root.glob("*.py"))
        usage_map = {}
        
        for file in py_files:
            usage_map[file.name] = {
                'imported_by': [],
                'imports': [],
                'size_kb': file.stat().st_size / 1024
            }
        
        # åˆ†æimportå…³ç³»
        for file in py_files:
            try:
                content = file.read_text(encoding='utf-8')
                for other_file in py_files:
                    if other_file != file:
                        module_name = other_file.stem
                        if f"import {module_name}" in content or f"from {module_name}" in content:
                            usage_map[other_file.name]['imported_by'].append(file.name)
            except:
                continue
        
        return usage_map
    
    def generate_optimization_plan(self, categories, redundant_files, temporary_files, usage_map):
        """ç”Ÿæˆä¼˜åŒ–æ–¹æ¡ˆ"""
        print("\nğŸ’¡ ç”Ÿæˆä¼˜åŒ–æ–¹æ¡ˆ...")
        
        optimization_plan = {
            'immediate_actions': [],
            'reorganization': [],
            'consolidation': [],
            'archive': []
        }
        
        # ç«‹å³æ¸…ç†
        for item in temporary_files:
            optimization_plan['immediate_actions'].append({
                'action': 'delete',
                'file': item['file'],
                'reason': item['reason']
            })
        
        # é‡ç»„å»ºè®®
        if len(categories['data_downloaders']) > 5:
            optimization_plan['reorganization'].append({
                'action': 'create_directory',
                'name': 'tools/data_download/',
                'move_files': categories['data_downloaders']
            })
        
        if len(categories['analysis_tools']) > 3:
            optimization_plan['reorganization'].append({
                'action': 'create_directory', 
                'name': 'tools/analysis/',
                'move_files': categories['analysis_tools']
            })
        
        # åˆå¹¶å»ºè®®
        similar_files = self._find_similar_files(categories)
        for group in similar_files:
            if len(group) > 1:
                optimization_plan['consolidation'].append({
                    'action': 'merge_files',
                    'files': group,
                    'target': f"merged_{group[0]}"
                })
        
        # å½’æ¡£å»ºè®®
        documentation_files = [f for f in categories['documentation'] 
                              if any(keyword in f.lower() for keyword in ['setup', 'guide', 'instructions'])]
        if documentation_files:
            optimization_plan['archive'].append({
                'action': 'move_to_docs',
                'files': documentation_files
            })
        
        return optimization_plan
    
    def _find_similar_files(self, categories):
        """æ‰¾åˆ°ç›¸ä¼¼åŠŸèƒ½çš„æ–‡ä»¶"""
        similar_groups = []
        
        # æ•°æ®ä¸‹è½½ç›¸å…³
        downloaders = categories['data_downloaders']
        if 'download_uqer_data.py' in downloaders and 'download_data_example.py' in downloaders:
            similar_groups.append(['download_uqer_data.py', 'download_data_example.py'])
        
        # GitHubè®¾ç½®ç›¸å…³
        setup_tools = categories['setup_tools']
        github_files = [f for f in setup_tools if 'github' in f]
        if len(github_files) > 1:
            similar_groups.append(github_files)
        
        return similar_groups
    
    def create_cleanup_script(self, optimization_plan):
        """åˆ›å»ºæ¸…ç†è„šæœ¬"""
        script_content = '''#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é¡¹ç›®æ¸…ç†è„šæœ¬ - è‡ªåŠ¨æ‰§è¡Œä¼˜åŒ–å»ºè®®
"""

import os
import shutil
from pathlib import Path

def cleanup_project():
    """æ‰§è¡Œé¡¹ç›®æ¸…ç†"""
    print("ğŸ§¹ å¼€å§‹é¡¹ç›®æ¸…ç†...")
    
    # åˆ›å»ºå½’æ¡£ç›®å½•
    archive_dir = Path("archive")
    archive_dir.mkdir(exist_ok=True)
    
    tools_dir = Path("tools")
    tools_dir.mkdir(exist_ok=True)
    
'''
        
        # æ·»åŠ å…·ä½“æ¸…ç†æ“ä½œ
        for action in optimization_plan['immediate_actions']:
            if action['action'] == 'delete':
                script_content += f'''    
    # åˆ é™¤ {action['file']} - {action['reason']}
    if Path("{action['file']}").exists():
        Path("{action['file']}").unlink()
        print("ğŸ—‘ï¸ åˆ é™¤: {action['file']}")
'''
        
        script_content += '''
    print("âœ… é¡¹ç›®æ¸…ç†å®Œæˆ!")

if __name__ == "__main__":
    cleanup_project()
'''
        
        return script_content
    
    def generate_report(self):
        """ç”Ÿæˆå®Œæ•´åˆ†ææŠ¥å‘Š"""
        print("ğŸš€ å¼€å§‹é¡¹ç›®ç»“æ„åˆ†æ...\n")
        
        # æ‰§è¡Œåˆ†æ
        categories = self.analyze_root_files()
        redundant_files = self.identify_redundant_files(categories)
        temporary_files = self.identify_temporary_files(categories)
        usage_map = self.check_file_usage()
        optimization_plan = self.generate_optimization_plan(categories, redundant_files, temporary_files, usage_map)
        
        # ç”ŸæˆæŠ¥å‘Š
        report = {
            'analysis_time': datetime.now().isoformat(),
            'file_categories': categories,
            'redundant_files': redundant_files,
            'temporary_files': temporary_files,
            'usage_map': usage_map,
            'optimization_plan': optimization_plan,
            'summary': {
                'total_py_files': len(list(self.root.glob("*.py"))),
                'total_md_files': len(list(self.root.glob("*.md"))),
                'redundant_count': len(redundant_files),
                'temporary_count': len(temporary_files),
                'optimization_actions': sum(len(actions) for actions in optimization_plan.values())
            }
        }
        
        # ä¿å­˜æŠ¥å‘Š
        report_file = Path("project_optimization_report.json")
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        # åˆ›å»ºæ¸…ç†è„šæœ¬
        cleanup_script = self.create_cleanup_script(optimization_plan)
        with open("cleanup_project.py", 'w', encoding='utf-8') as f:
            f.write(cleanup_script)
        
        return report
    
    def print_summary(self, report):
        """æ‰“å°åˆ†ææ‘˜è¦"""
        print("\n" + "="*60)
        print("ğŸ“Š é¡¹ç›®ç»“æ„ä¼˜åŒ–åˆ†ææŠ¥å‘Š")
        print("="*60)
        
        summary = report['summary']
        print(f"ğŸ“ æ ¹ç›®å½•Pythonæ–‡ä»¶: {summary['total_py_files']} ä¸ª")
        print(f"ğŸ“‹ æ ¹ç›®å½•Markdownæ–‡ä»¶: {summary['total_md_files']} ä¸ª")
        print(f"ğŸ” å‘ç°å†—ä½™æ–‡ä»¶: {summary['redundant_count']} ä¸ª")
        print(f"ğŸ§¹ ä¸´æ—¶æ–‡ä»¶: {summary['temporary_count']} ä¸ª")
        print(f"ğŸ’¡ ä¼˜åŒ–å»ºè®®: {summary['optimization_actions']} é¡¹")
        
        # æ˜¾ç¤ºæ–‡ä»¶åˆ†ç±»
        print(f"\nğŸ“‚ æ–‡ä»¶åˆ†ç±»:")
        categories = report['file_categories']
        for category, files in categories.items():
            if files:
                print(f"   {category}: {len(files)} ä¸ª")
        
        # æ˜¾ç¤ºä¸»è¦ä¼˜åŒ–å»ºè®®
        print(f"\nğŸ’¡ ä¸»è¦ä¼˜åŒ–å»ºè®®:")
        plan = report['optimization_plan']
        
        if plan['immediate_actions']:
            print(f"   ğŸ—‘ï¸ ç«‹å³æ¸…ç†: {len(plan['immediate_actions'])} ä¸ªæ–‡ä»¶")
        
        if plan['reorganization']:
            print(f"   ğŸ“ é‡æ–°ç»„ç»‡: {len(plan['reorganization'])} é¡¹")
        
        if plan['consolidation']:
            print(f"   ğŸ”„ åˆå¹¶æ–‡ä»¶: {len(plan['consolidation'])} ç»„")
        
        # æ˜¾ç¤ºå…·ä½“å»ºè®®
        print(f"\nğŸ¯ å…·ä½“å»ºè®®:")
        for action in plan['immediate_actions'][:5]:  # æ˜¾ç¤ºå‰5ä¸ª
            print(f"   â€¢ åˆ é™¤ {action['file']} - {action['reason']}")

def main():
    """ä¸»å‡½æ•°"""
    analyzer = ProjectAnalyzer()
    report = analyzer.generate_report()
    analyzer.print_summary(report)
    
    print(f"\nğŸ“‹ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜: project_optimization_report.json")
    print(f"ğŸ§¹ æ¸…ç†è„šæœ¬å·²åˆ›å»º: cleanup_project.py")

if __name__ == "__main__":
    main()