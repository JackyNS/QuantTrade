#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è‚¡ç¥¨ä¸“ç”¨æ•°æ®ä¸‹è½½å™¨ - åªä¸‹è½½è‚¡ç¥¨ç›¸å…³æ•°æ®
"""

import uqer
import pandas as pd
from datetime import datetime
from pathlib import Path
import time
import logging

# é…ç½®
UQER_TOKEN = "68b9922817ae6273137bda7acba81e293582ba347281dfcc056dcb245b23faf3"

class StockOnlyDownloader:
    """è‚¡ç¥¨ä¸“ç”¨æ•°æ®ä¸‹è½½å™¨"""
    
    def __init__(self):
        self.client = uqer.Client(token=UQER_TOKEN)
        self.data_dir = Path("data/stock_only")
        self.data_dir.mkdir(parents=True, exist_ok=True)
        
        # åªé€‰æ‹©è‚¡ç¥¨ç›¸å…³çš„æ ¸å¿ƒæ¥å£
        self.stock_apis = {
            # 1. è‚¡ç¥¨åŸºç¡€ä¿¡æ¯ (å¿…éœ€)
            "basic_info": {
                "EquGet": "è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯",
                "EquIPOGet": "IPOä¸Šå¸‚ä¿¡æ¯", 
                "EquIndustryGet": "è‚¡ç¥¨è¡Œä¸šåˆ†ç±»",
                "EquDivGet": "è‚¡ç¥¨åˆ†çº¢ä¿¡æ¯",
                "EquSplitsGet": "è‚¡ç¥¨æ‹†è‚¡ä¿¡æ¯",
                "EquAllotGet": "è‚¡ç¥¨é…è‚¡ä¿¡æ¯"
            },
            
            # 2. è‚¡ç¥¨è¡Œæƒ…æ•°æ® (æ ¸å¿ƒ)
            "market_data": {
                "MktEqudGet": "æ—¥è¡Œæƒ…æ•°æ®",
                "MktEquwGet": "å‘¨è¡Œæƒ…æ•°æ®",
                "MktEqumGet": "æœˆè¡Œæƒ…æ•°æ®",
                "MktEqudAdjGet": "å‰å¤æƒæ—¥è¡Œæƒ…",
                "MktAdjfGet": "å¤æƒå› å­"
            },
            
            # 3. è‚¡ç¥¨è´¢åŠ¡æ•°æ® (é‡è¦)
            "financial_data": {
                "FdmtBSAllLatestGet": "èµ„äº§è´Ÿå€ºè¡¨",
                "FdmtISAllLatestGet": "åˆ©æ¶¦è¡¨", 
                "FdmtCFAllLatestGet": "ç°é‡‘æµé‡è¡¨",
                "FdmtDerGet": "è´¢åŠ¡è¡ç”ŸæŒ‡æ ‡",
                "FdmtIndiPSGet": "æ¯è‚¡æŒ‡æ ‡",
                "FdmtIndiGrowthGet": "æˆé•¿èƒ½åŠ›æŒ‡æ ‡",
                "FdmtIndiRtnGet": "ç›ˆåˆ©èƒ½åŠ›æŒ‡æ ‡",
                "FdmtIndiLqdGet": "å¿å€ºèƒ½åŠ›æŒ‡æ ‡"
            },
            
            # 4. è‚¡ç¥¨èµ„é‡‘æµå‘ (ç­–ç•¥ç›¸å…³)
            "flow_data": {
                "MktEquFlowGet": "ä¸ªè‚¡èµ„é‡‘æµå‘",
                "MktIndustryFlowGet": "è¡Œä¸šèµ„é‡‘æµå‘"
            },
            
            # 5. è‚¡ç¥¨æŠ€æœ¯å› å­ (é‡åŒ–å¿…éœ€)
            "factor_data": {
                "StockFactorsDateRangeGet": "è‚¡ç¥¨å› å­æ—¶é—´åºåˆ—"
            },
            
            # 6. è‚¡ç¥¨å¸‚åœºå¾®è§‚ç»“æ„
            "microstructure": {
                "MktBlockdGet": "å¤§å®—äº¤æ˜“æ•°æ®",
                "FstTotalGet": "èèµ„èåˆ¸æ±‡æ€»",
                "MktLimitGet": "æ¶¨è·Œåœæ•°æ®",
                "SecHaltGet": "åœå¤ç‰Œæ•°æ®"
            }
        }
        
        # é…ç½®æ—¥å¿—
        log_file = self.data_dir / "stock_download.log"
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_file),
                logging.StreamHandler()
            ]
        )
        
    def get_stock_list_with_listing_dates(self):
        """è·å–è‚¡ç¥¨åˆ—è¡¨åŠä¸Šå¸‚æ—¥æœŸ"""
        logging.info("ğŸ“‹ è·å–è‚¡ç¥¨åˆ—è¡¨åŠä¸Šå¸‚æ—¥æœŸ...")
        
        try:
            stocks = uqer.DataAPI.EquGet(
                field='secID,ticker,secShortName,exchangeCD,listStatusCD,listDate,delistDate'
            )
            
            if stocks is not None and not stocks.empty:
                # åªä¿ç•™Aè‚¡
                a_stocks = stocks[stocks['listStatusCD'] == 'L'].copy()
                
                # è½¬æ¢ä¸Šå¸‚æ—¥æœŸæ ¼å¼
                a_stocks['listDate'] = pd.to_datetime(a_stocks['listDate'])
                a_stocks['listYear'] = a_stocks['listDate'].dt.year
                
                logging.info(f"âœ… è·å–è‚¡ç¥¨åˆ—è¡¨æˆåŠŸ: {len(a_stocks)} åªAè‚¡")
                
                # æŒ‰å¹´ä»½ç»Ÿè®¡
                yearly_stats = a_stocks['listYear'].value_counts().sort_index()
                logging.info("ğŸ“Š æŒ‰å¹´åº¦ä¸Šå¸‚è‚¡ç¥¨åˆ†å¸ƒ:")
                for year in range(1990, 2025):
                    if year in yearly_stats.index:
                        logging.info(f"   {year}å¹´: {yearly_stats[year]} åª")
                
                return a_stocks
            
        except Exception as e:
            logging.error(f"âŒ è·å–è‚¡ç¥¨åˆ—è¡¨å¤±è´¥: {e}")
            return None
    
    def download_optimized_historical_data(self):
        """ä¼˜åŒ–çš„å†å²æ•°æ®ä¸‹è½½"""
        logging.info("ğŸš€ å¼€å§‹ä¼˜åŒ–çš„è‚¡ç¥¨å†å²æ•°æ®ä¸‹è½½...")
        
        # è·å–è‚¡ç¥¨åˆ—è¡¨
        stocks = self.get_stock_list_with_listing_dates()
        if stocks is None:
            return False
        
        # æŒ‰å¹´åº¦æ™ºèƒ½ä¸‹è½½
        return self._download_by_year_smart(stocks)
    
    def _download_by_year_smart(self, stocks):
        """æŒ‰å¹´åº¦æ™ºèƒ½ä¸‹è½½ï¼Œåªä¸‹è½½å·²ä¸Šå¸‚çš„è‚¡ç¥¨"""
        logging.info("ğŸ“ˆ å¼€å§‹æŒ‰å¹´åº¦æ™ºèƒ½ä¸‹è½½å†å²è¡Œæƒ…...")
        
        market_dir = self.data_dir / "market_data"
        market_dir.mkdir(exist_ok=True)
        
        total_records = 0
        
        for year in range(2000, datetime.now().year + 1):
            logging.info(f"ğŸ“… å¤„ç† {year} å¹´æ•°æ®...")
            
            # ç­›é€‰è¯¥å¹´åº¦å·²ä¸Šå¸‚çš„è‚¡ç¥¨
            year_stocks = stocks[stocks['listYear'] <= year].copy()
            
            if len(year_stocks) == 0:
                logging.info(f"â­ï¸ {year} å¹´æ— å·²ä¸Šå¸‚è‚¡ç¥¨ï¼Œè·³è¿‡")
                continue
            
            logging.info(f"ğŸ¯ {year} å¹´å·²ä¸Šå¸‚è‚¡ç¥¨: {len(year_stocks)} åª")
            
            # ä¸‹è½½è¯¥å¹´åº¦æ•°æ®
            year_records = self._download_year_data_smart(year_stocks, year, market_dir)
            total_records += year_records
            
            logging.info(f"âœ… {year} å¹´å®Œæˆ: {year_records} æ¡è®°å½•")
        
        logging.info(f"ğŸ‰ å†å²è¡Œæƒ…ä¸‹è½½å®Œæˆ: æ€»è®¡ {total_records} æ¡è®°å½•")
        return total_records > 0
    
    def _download_year_data_smart(self, stocks, year, market_dir):
        """æ™ºèƒ½ä¸‹è½½å¹´åº¦æ•°æ®"""
        year_dir = market_dir / f"year_{year}"
        year_dir.mkdir(exist_ok=True)
        
        start_date = f"{year}0101"
        end_date = f"{year}1231"
        
        # åˆ†æ‰¹ä¸‹è½½ï¼Œæ¯æ‰¹100åªè‚¡ç¥¨
        batch_size = 100
        batches = [stocks[i:i+batch_size] for i in range(0, len(stocks), batch_size)]
        
        total_records = 0
        
        for batch_idx, batch_stocks in enumerate(batches):
            batch_file = year_dir / f"batch_{batch_idx+1:03d}.csv"
            
            # è·³è¿‡å·²å­˜åœ¨çš„æ–‡ä»¶
            if batch_file.exists():
                existing_data = pd.read_csv(batch_file)
                total_records += len(existing_data)
                continue
            
            try:
                tickers = ','.join(batch_stocks['ticker'].tolist())
                
                data = uqer.DataAPI.MktEqudGet(
                    secID='',
                    ticker=tickers,
                    beginDate=start_date,
                    endDate=end_date,
                    field='secID,ticker,tradeDate,preClosePrice,openPrice,highestPrice,lowestPrice,closePrice,turnoverVol,marketValue,dealAmount,turnoverRate'
                )
                
                if data is not None and not data.empty:
                    data.to_csv(batch_file, index=False)
                    total_records += len(data)
                    logging.info(f"âœ… {year} æ‰¹æ¬¡ {batch_idx+1}: {len(data)} æ¡")
                else:
                    logging.info(f"âš ï¸ {year} æ‰¹æ¬¡ {batch_idx+1}: ç©ºæ•°æ®")
                
                time.sleep(0.2)
                
            except Exception as e:
                logging.error(f"âŒ {year} æ‰¹æ¬¡ {batch_idx+1} å¤±è´¥: {e}")
                continue
        
        return total_records
    
    def download_stock_basics_only(self):
        """åªä¸‹è½½è‚¡ç¥¨åŸºç¡€ä¿¡æ¯"""
        logging.info("ğŸ“‹ ä¸‹è½½è‚¡ç¥¨åŸºç¡€ä¿¡æ¯...")
        
        basics_dir = self.data_dir / "basics"
        basics_dir.mkdir(exist_ok=True)
        
        for api_name, description in self.stock_apis["basic_info"].items():
            try:
                logging.info(f"ğŸ“¥ {description}...")
                
                api_func = getattr(uqer.DataAPI, api_name, None)
                if not api_func:
                    continue
                
                # æ ¹æ®æ¥å£è°ƒæ•´å‚æ•°
                if api_name == "EquIndustryGet":
                    data = api_func(intoDate="20251231")
                elif api_name in ["EquDivGet", "EquSplitsGet", "EquAllotGet"]:
                    data = api_func(beginDate="20000101", endDate="20251231")
                else:
                    data = api_func()
                
                if data is not None and not data.empty:
                    file_path = basics_dir / f"{api_name}.csv"
                    data.to_csv(file_path, index=False)
                    logging.info(f"âœ… {description}: {len(data)} æ¡")
                
                time.sleep(0.3)
                
            except Exception as e:
                logging.error(f"âŒ {description} å¤±è´¥: {e}")
    
    def show_download_plan(self):
        """æ˜¾ç¤ºä¸‹è½½è®¡åˆ’"""
        total_apis = sum(len(category) for category in self.stock_apis.values())
        
        print("ğŸ¯ è‚¡ç¥¨ä¸“ç”¨æ•°æ®ä¸‹è½½è®¡åˆ’")
        print("=" * 50)
        print(f"ğŸ“Š æ€»APIæ•°é‡: {total_apis} ä¸ª (çº¯è‚¡ç¥¨ç›¸å…³)")
        print(f"ğŸ“… æ—¶é—´èŒƒå›´: 2000å¹´-è‡³ä»Š")
        print(f"ğŸ¯ æ•°æ®ç±»å‹: ä»…è‚¡ç¥¨æ•°æ®")
        print("\nğŸ“‹ APIåˆ†ç±»:")
        
        for category, apis in self.stock_apis.items():
            print(f"\n{category}:")
            for api, desc in apis.items():
                print(f"  - {desc}")
        
        print(f"\nğŸ’¾ æ•°æ®ä¿å­˜: {self.data_dir}")
        
def main():
    downloader = StockOnlyDownloader()
    
    print("é€‰æ‹©ä¸‹è½½æ¨¡å¼:")
    print("1. åªä¸‹è½½åŸºç¡€ä¿¡æ¯")
    print("2. å®Œæ•´å†å²æ•°æ®ä¸‹è½½")
    print("3. æ˜¾ç¤ºä¸‹è½½è®¡åˆ’")
    
    choice = input("è¯·é€‰æ‹© (1-3): ").strip()
    
    if choice == "1":
        downloader.download_stock_basics_only()
    elif choice == "2":
        downloader.download_optimized_historical_data()
    elif choice == "3":
        downloader.show_download_plan()
    else:
        print("âŒ æ— æ•ˆé€‰æ‹©")

if __name__ == "__main__":
    main()