#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¼˜çŸ¿æ ¸å¿ƒæ•°æ®ä¼˜å…ˆä¸‹è½½å™¨ - æ¸…æ´ç‰ˆ
===============================

åŸºäºä¼˜çŸ¿APIå’Œcoreæ¨¡å—éœ€æ±‚çš„ä¼˜å…ˆçº§ä¸‹è½½æ–¹æ¡ˆ
"""

import uqer
import pandas as pd
from pathlib import Path
from datetime import datetime
import time
import logging
import json
from typing import Dict, List, Optional, Tuple

# ä¼˜çŸ¿Token
UQER_TOKEN = "68b9922817ae6273137bda7acba81e293582ba347281dfcc056dcb245b23faf3"

class CleanPriorityDownloader:
    """ä¼˜çŸ¿æ ¸å¿ƒæ•°æ®ä¼˜å…ˆä¸‹è½½å™¨"""
    
    def __init__(self):
        # åˆå§‹åŒ–uqerå®¢æˆ·ç«¯
        uqer.Client(token=UQER_TOKEN)
        self.client = uqer
        self.base_path = Path("/Users/jackstudio/QuantTrade/data")
        self.base_path.mkdir(exist_ok=True)
        
        # è®¾ç½®ç®€å•æ—¥å¿—
        logging.basicConfig(level=logging.INFO)
        self.logger = logging.getLogger(__name__)
        
        # ä¸‹è½½ç»Ÿè®¡
        self.stats = {'success': 0, 'failed': 0, 'records': 0}
        
        # ä¼˜å…ˆAPIé…ç½®
        self.priority_apis = {
            # ç¬¬1ä¼˜å…ˆçº§ï¼šè‚¡ç¥¨åŸºæœ¬ä¿¡æ¯ï¼ˆé™æ€æ•°æ®ï¼‰
            "EquGet": {
                "name": "è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯",
                "dir": "basic_info",
                "fields": "secID,ticker,secShortName,exchangeCD,listStatusCD,listDate,delistDate",
                "time_based": False
            },
            
            # ç¬¬2ä¼˜å…ˆçº§ï¼šè‚¡ç¥¨æ—¥è¡Œæƒ…ï¼ˆæ ¸å¿ƒï¼‰
            "MktEqudGet": {
                "name": "è‚¡ç¥¨æ—¥è¡Œæƒ…",
                "dir": "daily", 
                "fields": "secID,ticker,tradeDate,preClosePrice,openPrice,highestPrice,lowestPrice,closePrice,turnoverVol,marketValue",
                "time_based": True
            },
            
            # ç¬¬3ä¼˜å…ˆçº§ï¼šäº¤æ˜“æ—¥å†
            "TradeCalGet": {
                "name": "äº¤æ˜“æ—¥å†",
                "dir": "calendar", 
                "fields": "calendarDate,exchangeCD,isOpen",
                "time_based": True,
                "special": True
            },
            
            # ç¬¬4ä¼˜å…ˆçº§ï¼šå¤æƒå› å­
            "MktAdjfGet": {
                "name": "å¤æƒå› å­",
                "dir": "adjustment",
                "fields": "secID,ticker,exDivDate,adjfactor",
                "time_based": True
            },
            
            # ç¬¬5ä¼˜å…ˆçº§ï¼šåˆ†çº¢æ•°æ®  
            "EquDivGet": {
                "name": "è‚¡ç¥¨åˆ†çº¢",
                "dir": "dividend",
                "fields": "secID,ticker,exDate,dividend,splitRatio",
                "time_based": True
            },
            
            # ç¬¬6ä¼˜å…ˆçº§ï¼šå¸‚å€¼æ•°æ® (ä½¿ç”¨MktEqudä¸­çš„marketValueï¼Œæ— éœ€å•ç‹¬API)
            # æ³¨é‡Šï¼šå¸‚å€¼æ•°æ®å·²åŒ…å«åœ¨MktEqudGetä¸­çš„marketValueå­—æ®µ
            
            # ç¬¬7ä¼˜å…ˆçº§ï¼šè´¢åŠ¡æ•°æ® - èµ„äº§è´Ÿå€ºè¡¨
            "FdmtBs2018Get": {
                "name": "èµ„äº§è´Ÿå€ºè¡¨(2018æ–°å‡†åˆ™)",
                "dir": "financial",
                "fields": "secID,ticker,endDate,totalAssets,totalLiab,totalShrhldrEqty",
                "time_based": True,
                "special": True
            },
            
            # ç¬¬7.5ä¼˜å…ˆçº§ï¼šè´¢åŠ¡è¡ç”Ÿæ•°æ®
            "FdmtDerGet": {
                "name": "è´¢åŠ¡è¡ç”Ÿæ•°æ®",
                "dir": "financial",
                "fields": "secID,ticker,endDate,revenue,netProfit,roe,roa",
                "time_based": True,
                "special": True
            },
            
            # ç¬¬8ä¼˜å…ˆçº§ï¼šèµ„é‡‘æµå‘ï¼ˆæƒ…ç»ªæ ¸å¿ƒï¼‰
            "MktEquFlowGet": {
                "name": "ä¸ªè‚¡èµ„é‡‘æµå‘",
                "dir": "capital_flow",
                "fields": "secID,ticker,tradeDate,mainNetFlow,superNetFlow,largeNetFlow,mediumNetFlow,smallNetFlow",
                "time_based": True
            },
            
            # ç¬¬9ä¼˜å…ˆçº§ï¼šæ¶¨è·Œåœé™åˆ¶ï¼ˆå¸‚åœºæƒ…ç»ªï¼‰
            "MktLimitGet": {
                "name": "æ¶¨è·Œåœé™åˆ¶",
                "dir": "limit_info",
                "fields": "secID,ticker,tradeDate,upLimit,downLimit,limitStatus",
                "time_based": True
            },
            
            # ç¬¬10ä¼˜å…ˆçº§ï¼šé¾™è™æ¦œæ•°æ®ï¼ˆå¼‚åŠ¨æƒ…ç»ªï¼‰
            "MktRankListStocksGet": {
                "name": "é¾™è™æ¦œæ•°æ®", 
                "dir": "rank_list",
                "fields": "secID,ticker,tradeDate,rankReason,buyAmt,sellAmt",
                "time_based": True
            }
        }
    
    def get_stock_list(self) -> List[str]:
        """è·å–è‚¡ç¥¨åˆ—è¡¨"""
        try:
            print("ğŸ“‹ è·å–è‚¡ç¥¨åˆ—è¡¨...")
            result = self.client.DataAPI.EquGet(
                listStatusCD='L',  # åªè¦ä¸Šå¸‚è‚¡ç¥¨
                field='secID,ticker',
                pandas='1'
            )
            
            if isinstance(result, pd.DataFrame) and not result.empty:
                stocks = result['secID'].unique().tolist()
                print(f"âœ… è·å–åˆ° {len(stocks)} åªè‚¡ç¥¨")
                print(f"ğŸ“Š å°†ä¸‹è½½å…¨éƒ¨ {len(stocks)} åªAè‚¡å†å²æ•°æ®")
                return stocks  # ä¸‹è½½å…¨éƒ¨è‚¡ç¥¨
            return []
            
        except Exception as e:
            print(f"âŒ è·å–è‚¡ç¥¨åˆ—è¡¨å¤±è´¥: {e}")
            return []
    
    def download_static_data(self, api_name: str, config: Dict) -> bool:
        """ä¸‹è½½é™æ€æ•°æ®"""
        try:
            print(f"ğŸ“Š ä¸‹è½½ {config['name']}...")
            
            # åˆ›å»ºç›®å½•
            output_dir = self.base_path / config['dir'] 
            output_dir.mkdir(exist_ok=True)
            
            # è°ƒç”¨API
            api_func = getattr(self.client.DataAPI, api_name)
            result = api_func(
                field=config['fields'],
                pandas='1'
            )
            
            if isinstance(result, pd.DataFrame) and not result.empty:
                output_file = output_dir / f"{api_name.lower()}.csv"
                result.to_csv(output_file, index=False)
                
                self.stats['success'] += 1
                self.stats['records'] += len(result)
                print(f"âœ… {config['name']} å®Œæˆ: {len(result)} æ¡è®°å½•")
                return True
            else:
                print(f"âŒ {config['name']} æ— æ•°æ®")
                return False
                
        except Exception as e:
            print(f"âŒ {config['name']} å¤±è´¥: {e}")
            self.stats['failed'] += 1
            return False
    
    def download_time_series(self, api_name: str, config: Dict, stocks: List[str]) -> bool:
        """ä¸‹è½½æ—¶é—´åºåˆ—æ•°æ® - æ”¯æŒåˆ†æ‰¹ä¸‹è½½"""
        try:
            print(f"ğŸ“ˆ ä¸‹è½½ {config['name']}...")
            
            # åˆ›å»ºç›®å½•
            output_dir = self.base_path / config['dir']
            output_dir.mkdir(exist_ok=True)
            
            # å¤„ç†ç‰¹æ®ŠAPI
            if config.get('special'):
                return self.download_special_api(api_name, config, output_dir)
            
            api_func = getattr(self.client.DataAPI, api_name)
            
            # åˆ†æ‰¹ä¸‹è½½ - æ¯æ‰¹100åªè‚¡ç¥¨
            batch_size = 100
            all_data = []
            
            print(f"   ğŸ“Š åˆ†æ‰¹ä¸‹è½½: {len(stocks)} åªè‚¡ç¥¨, æ¯æ‰¹ {batch_size} åª")
            
            for i in range(0, len(stocks), batch_size):
                batch_stocks = stocks[i:i+batch_size]
                batch_tickers = ','.join([s.split('.')[0] for s in batch_stocks])
                
                print(f"   ğŸ”„ æ‰¹æ¬¡ {i//batch_size + 1}/{(len(stocks)-1)//batch_size + 1}: {len(batch_stocks)} åªè‚¡ç¥¨")
                
                try:
                    result = api_func(
                        secID='',
                        ticker=batch_tickers,
                        beginDate='20100101',
                        endDate='20250831',
                        field=config['fields'],
                        pandas='1'
                    )
                    
                    if isinstance(result, pd.DataFrame) and not result.empty:
                        all_data.append(result)
                        print(f"   âœ… æ‰¹æ¬¡å®Œæˆ: {len(result)} æ¡è®°å½•")
                    else:
                        print(f"   âš ï¸ æ‰¹æ¬¡æ— æ•°æ®")
                    
                    # æ‰¹æ¬¡é—´åœé¡¿
                    time.sleep(0.5)
                    
                except Exception as e:
                    print(f"   âŒ æ‰¹æ¬¡å¤±è´¥: {e}")
                    continue
            
            # åˆå¹¶æ‰€æœ‰æ•°æ®
            if all_data:
                combined_data = pd.concat(all_data, ignore_index=True)
                output_file = output_dir / f"{api_name.lower()}_2010_2025.csv"
                combined_data.to_csv(output_file, index=False)
                
                self.stats['success'] += 1
                self.stats['records'] += len(combined_data)
                print(f"âœ… {config['name']} å®Œæˆ: {len(combined_data)} æ¡è®°å½•")
                return True
            else:
                print(f"âŒ {config['name']} æ— æ•°æ®")
                return False
                
        except Exception as e:
            print(f"âŒ {config['name']} å¤±è´¥: {e}")
            self.stats['failed'] += 1
            return False
    
    def download_special_api(self, api_name: str, config: Dict, output_dir: Path) -> bool:
        """ä¸‹è½½ç‰¹æ®ŠAPIï¼ˆå¦‚äº¤æ˜“æ—¥å†å’Œè´¢åŠ¡æ•°æ®ï¼‰"""
        try:
            api_func = getattr(self.client.DataAPI, api_name)
            
            if api_name == 'TradeCalGet':
                # äº¤æ˜“æ—¥å†
                result = api_func(
                    exchangeCD='XSHG,XSHE',
                    beginDate='20100101',
                    endDate='20251231',
                    field=config['fields'],
                    pandas='1'
                )
                output_file = output_dir / "trading_calendar.csv"
                
            elif api_name == 'FdmtBs2018Get':
                # è´¢åŠ¡æ•°æ® - èµ„äº§è´Ÿå€ºè¡¨(2018æ–°å‡†åˆ™)
                result = api_func(
                    reportType='A',  # å¹´æŠ¥
                    beginDate='20180101',  # 2018æ–°å‡†åˆ™å¼€å§‹
                    endDate='20251231', 
                    field=config['fields'],
                    pandas='1'
                )
                output_file = output_dir / "balance_sheet_2018.csv"
                
            elif api_name == 'FdmtDerGet':
                # è´¢åŠ¡è¡ç”Ÿæ•°æ®
                result = api_func(
                    reportType='A',  # å¹´æŠ¥
                    beginDate='20100101',
                    endDate='20251231',
                    field=config['fields'],
                    pandas='1'
                )
                output_file = output_dir / "financial_derived.csv"
            
            else:
                print(f"âŒ æœªæ”¯æŒçš„ç‰¹æ®ŠAPI: {api_name}")
                return False
                
            if isinstance(result, pd.DataFrame) and not result.empty:
                result.to_csv(output_file, index=False)
                
                self.stats['success'] += 1
                self.stats['records'] += len(result)
                print(f"âœ… {config['name']} å®Œæˆ: {len(result)} æ¡è®°å½•")
                return True
            else:
                print(f"âŒ {config['name']} æ— æ•°æ®")
                return False
            
        except Exception as e:
            print(f"âŒ ç‰¹æ®ŠAPI {api_name} å¤±è´¥: {e}")
            self.stats['failed'] += 1
            return False
    
    def run_download(self):
        """è¿è¡Œä¸‹è½½"""
        start_time = datetime.now()
        
        print("ğŸš€ ä¼˜çŸ¿æ ¸å¿ƒæ•°æ®æ­£å¼ä¸‹è½½å™¨")
        print("ğŸ¯ ç›®æ ‡: ä¸‹è½½å®Œæ•´Aè‚¡æ•°æ® (2010-2025)")
        print("ğŸ“Š èŒƒå›´: å…¨éƒ¨Aè‚¡, 15å¹´å†å²æ•°æ®")
        print("=" * 60)
        
        try:
            # 1. è·å–è‚¡ç¥¨åˆ—è¡¨
            stocks = self.get_stock_list()
            if not stocks:
                print("âŒ æ— æ³•è·å–è‚¡ç¥¨åˆ—è¡¨")
                return
            
            # 2. æŒ‰ä¼˜å…ˆçº§ä¸‹è½½
            for api_name, config in self.priority_apis.items():
                print(f"\nğŸ“¡ {config['name']}")
                print("-" * 30)
                
                if config.get('time_based'):
                    success = self.download_time_series(api_name, config, stocks)
                else:
                    success = self.download_static_data(api_name, config)
                
                # APIé—´åœé¡¿
                time.sleep(1)
            
            # 3. ç”ŸæˆæŠ¥å‘Š
            self.generate_report(start_time)
            
        except Exception as e:
            print(f"âŒ ä¸‹è½½å¼‚å¸¸: {e}")
    
    def generate_report(self, start_time):
        """ç”Ÿæˆç®€å•æŠ¥å‘Š"""
        end_time = datetime.now()
        duration = end_time - start_time
        
        print(f"\nğŸŠ ä¸‹è½½å®Œæˆ!")
        print(f"â±ï¸ è€—æ—¶: {duration}")
        print(f"âœ… æˆåŠŸ: {self.stats['success']}")
        print(f"âŒ å¤±è´¥: {self.stats['failed']}")
        print(f"ğŸ“‹ è®°å½•: {self.stats['records']:,}")
        
        # æ˜¾ç¤ºæ•°æ®ç»“æ„
        print(f"\nğŸ“ æ•°æ®ç›®å½•:")
        for item in self.base_path.iterdir():
            if item.is_dir():
                files = list(item.glob("*.csv"))
                if files:
                    print(f"   ğŸ“‚ {item.name}: {len(files)} æ–‡ä»¶")

def main():
    downloader = CleanPriorityDownloader()
    downloader.run_download()

if __name__ == "__main__":
    main()