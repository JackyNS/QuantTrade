#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å®Œæ•´APIè¯¦æƒ…æŸ¥çœ‹å™¨ - å±•ç¤ºæ‰€æœ‰69ä¸ªAPIçš„å®Œæ•´æ˜ç»†
"""

import pandas as pd
from pathlib import Path

def display_complete_api_details():
    """å±•ç¤ºæ‰€æœ‰APIçš„å®Œæ•´è¯¦ç»†ä¿¡æ¯"""
    
    # è¯»å–è¯¦ç»†åˆ†ææŠ¥å‘Š
    overview_file = Path("APIè¯¦ç»†åˆ†ææŠ¥å‘Š_æ¦‚è§ˆ.csv")
    quality_file = Path("APIè¯¦ç»†åˆ†ææŠ¥å‘Š_è´¨é‡.csv")
    
    if not overview_file.exists():
        print("âŒ æœªæ‰¾åˆ°APIè¯¦ç»†åˆ†ææŠ¥å‘Šï¼Œè¯·å…ˆè¿è¡Œ detailed_api_analyzer.py")
        return
    
    # è¯»å–æ•°æ®
    df_overview = pd.read_csv(overview_file)
    
    print("="*120)
    print("ğŸ¯ **QuantTrade å…¨éƒ¨69ä¸ªAPIè¯¦ç»†æ˜ç»†** ğŸ¯")
    print("="*120)
    print(f"ğŸ“Š æ•°æ®ç»Ÿè®¡æ—¶é—´: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ğŸ“‹ APIæ€»æ•°: {len(df_overview)} ä¸ª")
    
    # æŒ‰åˆ†ç±»å±•ç¤ºæ¯ä¸ªAPI
    categories = df_overview['category'].unique()
    
    for category in categories:
        category_apis = df_overview[df_overview['category'] == category].sort_values('total_size_mb', ascending=False)
        
        print(f"\n" + "="*100)
        print(f"ğŸ“ **{category.upper()}** - {len(category_apis)} ä¸ªAPI")
        print("="*100)
        
        for idx, api in category_apis.iterrows():
            # APIåŸºæœ¬ä¿¡æ¯
            print(f"\nğŸ”¹ **{api['api_name']}**")
            print(f"   ğŸ“ ä¸­æ–‡æè¿°: {api['chinese_description']}")
            
            # æ•°æ®è§„æ¨¡
            if api['file_count'] > 0:
                print(f"   ğŸ“Š æ•°æ®è§„æ¨¡: {api['file_count']} ä¸ªæ–‡ä»¶, {api['total_size_mb']:.1f}MB")
                print(f"   ğŸ“ˆ è®°å½•ç»Ÿè®¡: çº¦ {api['estimated_total_records']:,} æ¡è®°å½•")
                print(f"   ğŸ“ æ•°æ®ç»“æ„: å¹³å‡ {api['avg_rows_per_file']:,} è¡Œ Ã— {api['avg_columns_per_file']} åˆ—")
            else:
                print(f"   âš ï¸  æ•°æ®çŠ¶æ€: æš‚æ— æ•°æ®æ–‡ä»¶")
                continue
            
            # æ—¶é—´è¦†ç›–
            time_desc = api['date_range_description'] if pd.notna(api['date_range_description']) else "æ—¶é—´èŒƒå›´æœªçŸ¥"
            print(f"   ğŸ“… æ—¶é—´è¦†ç›–: {time_desc}")
            
            # æ•°æ®è´¨é‡
            missing_rate = api['avg_missing_rate']
            if missing_rate == 0:
                quality_status = "ğŸŸ¢ ä¼˜ç§€"
            elif missing_rate < 10:
                quality_status = "ğŸŸ¡ è‰¯å¥½"
            elif missing_rate < 30:
                quality_status = "ğŸŸ  ä¸€èˆ¬"
            else:
                quality_status = "ğŸ”´ å¾…ä¼˜åŒ–"
            
            print(f"   ğŸ¯ æ•°æ®è´¨é‡: {quality_status} (ç¼ºå¤±ç‡: {missing_rate:.2f}%)")
            
            # æ•°æ®æ›´æ–°æ¨¡å¼
            pattern_desc = {
                'yearly': 'æŒ‰å¹´æ›´æ–°',
                'quarterly': 'æŒ‰å­£åº¦æ›´æ–°', 
                'monthly': 'æŒ‰æœˆæ›´æ–°',
                'daily': 'æŒ‰æ—¥æ›´æ–°',
                'snapshot': 'å¿«ç…§æ•°æ®',
                'data_driven': 'æ•°æ®é©±åŠ¨',
                'unknown': 'æ›´æ–°æ¨¡å¼æœªçŸ¥'
            }.get(api['time_pattern'], api['time_pattern'])
            
            print(f"   ğŸ”„ æ›´æ–°æ¨¡å¼: {pattern_desc}")
            
            # ç›¸å¯¹é‡è¦æ€§ï¼ˆåŸºäºæ•°æ®é‡ï¼‰
            size_mb = api['total_size_mb']
            if size_mb > 1000:
                importance = "ğŸ”´ æ ¸å¿ƒæ•°æ®æº"
            elif size_mb > 100:
                importance = "ğŸŸ  é‡è¦æ•°æ®æº"
            elif size_mb > 10:
                importance = "ğŸŸ¡ å¸¸ç”¨æ•°æ®æº"
            else:
                importance = "ğŸŸ¢ è¾…åŠ©æ•°æ®æº"
            
            print(f"   â­ é‡è¦ç¨‹åº¦: {importance}")
    
    # ç”Ÿæˆæ±‡æ€»ç»Ÿè®¡
    print(f"\n" + "="*100)
    print("ğŸ“Š **å…¨ä½“APIæ±‡æ€»ç»Ÿè®¡**")
    print("="*100)
    
    # æŒ‰åˆ†ç±»ç»Ÿè®¡
    print("\nğŸ·ï¸ **æŒ‰åˆ†ç±»ç»Ÿè®¡**:")
    category_stats = df_overview.groupby('category').agg({
        'api_name': 'count',
        'file_count': 'sum',
        'total_size_mb': 'sum',
        'estimated_total_records': 'sum'
    }).round(1)
    
    for category, stats in category_stats.iterrows():
        print(f"  ğŸ“ {category}: {int(stats['api_name'])} APIs, "
              f"{int(stats['file_count'])} æ–‡ä»¶, "
              f"{stats['total_size_mb']:.0f}MB, "
              f"{int(stats['estimated_total_records']):,} è®°å½•")
    
    # æŒ‰æ•°æ®é‡æ’åºçš„Top 10
    print(f"\nğŸ” **æ•°æ®é‡Top 10 API**:")
    top_apis = df_overview.nlargest(10, 'total_size_mb')
    for i, (_, api) in enumerate(top_apis.iterrows(), 1):
        print(f"  {i:2d}. {api['api_name']}: {api['total_size_mb']:.0f}MB "
              f"({api['estimated_total_records']:,} æ¡è®°å½•)")
    
    # æŒ‰è®°å½•æ•°æ’åºçš„Top 10
    print(f"\nğŸ“ˆ **è®°å½•æ•°é‡Top 10 API**:")
    top_records = df_overview.nlargest(10, 'estimated_total_records')
    for i, (_, api) in enumerate(top_records.iterrows(), 1):
        print(f"  {i:2d}. {api['api_name']}: {api['estimated_total_records']:,} æ¡è®°å½• "
              f"({api['total_size_mb']:.0f}MB)")
    
    # æ•°æ®è´¨é‡åˆ†å¸ƒ
    print(f"\nğŸ¯ **æ•°æ®è´¨é‡åˆ†å¸ƒ**:")
    quality_ranges = [
        (0, 5, "ğŸŸ¢ ä¼˜ç§€"),
        (5, 15, "ğŸŸ¡ è‰¯å¥½"), 
        (15, 35, "ğŸŸ  ä¸€èˆ¬"),
        (35, 100, "ğŸ”´ å¾…ä¼˜åŒ–")
    ]
    
    for min_rate, max_rate, status in quality_ranges:
        count = len(df_overview[
            (df_overview['avg_missing_rate'] >= min_rate) & 
            (df_overview['avg_missing_rate'] < max_rate) &
            (df_overview['file_count'] > 0)
        ])
        print(f"  {status} (ç¼ºå¤±ç‡{min_rate}-{max_rate}%): {count} ä¸ªAPI")
    
    # æ—¶é—´æ¨¡å¼åˆ†å¸ƒ
    print(f"\nğŸ“… **æ•°æ®æ›´æ–°æ¨¡å¼åˆ†å¸ƒ**:")
    pattern_counts = df_overview[df_overview['file_count'] > 0]['time_pattern'].value_counts()
    pattern_names = {
        'yearly': 'å¹´åº¦æ›´æ–°',
        'quarterly': 'å­£åº¦æ›´æ–°',
        'monthly': 'æœˆåº¦æ›´æ–°', 
        'daily': 'æ—¥åº¦æ›´æ–°',
        'snapshot': 'å¿«ç…§æ•°æ®',
        'data_driven': 'æ•°æ®é©±åŠ¨',
        'unknown': 'æœªçŸ¥æ¨¡å¼'
    }
    
    for pattern, count in pattern_counts.items():
        pattern_name = pattern_names.get(pattern, pattern)
        print(f"  ğŸ“Š {pattern_name}: {count} ä¸ªAPI")
    
    # æ— æ•°æ®çš„API
    no_data_apis = df_overview[df_overview['file_count'] == 0]
    if len(no_data_apis) > 0:
        print(f"\nâš ï¸  **æš‚æ— æ•°æ®çš„API ({len(no_data_apis)} ä¸ª)**:")
        for _, api in no_data_apis.iterrows():
            print(f"  ğŸ”´ {api['api_name']} ({api['category']})")
    
    print(f"\n" + "="*100)
    print("âœ… **å®Œæ•´APIæ˜ç»†å±•ç¤ºå®Œæ¯•**")
    print(f"ğŸ’¾ è¯¦ç»†æ•°æ®å·²ä¿å­˜è‡³: APIè¯¦ç»†åˆ†ææŠ¥å‘Š_æ¦‚è§ˆ.csv")
    print(f"ğŸ“Š è´¨é‡è¯¦æƒ…å·²ä¿å­˜è‡³: APIè¯¦ç»†åˆ†ææŠ¥å‘Š_è´¨é‡.csv") 
    print(f"ğŸ“ åˆ†ç±»æ±‡æ€»å·²ä¿å­˜è‡³: APIè¯¦ç»†åˆ†ææŠ¥å‘Š_åˆ†ç±»æ±‡æ€».csv")
    print("="*100)

if __name__ == "__main__":
    display_complete_api_details()