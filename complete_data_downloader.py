#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å®Œæ•´æ•°æ®ä¸‹è½½å™¨ - å…¨å¸‚åœºç‰ˆæœ¬
==========================

ä¸‹è½½å…¨éƒ¨10ä¸ªæ¥å£çš„å®Œæ•´æ•°æ® (2010-2025å¹´ï¼Œå…¨å¸‚åœºè‚¡ç¥¨)
"""

import uqer
import pandas as pd
from pathlib import Path
from datetime import datetime
import time
import logging
from typing import Dict, List, Optional

# ä¼˜çŸ¿Token
UQER_TOKEN = "68b9922817ae6273137bda7acba81e293582ba347281dfcc056dcb245b23faf3"

class CompleteDataDownloader:
    """å®Œæ•´æ•°æ®ä¸‹è½½å™¨"""
    
    def __init__(self):
        # åˆå§‹åŒ–uqerå®¢æˆ·ç«¯
        uqer.Client(token=UQER_TOKEN)
        self.client = uqer
        self.base_path = Path("/Users/jackstudio/QuantTrade/data")
        self.base_path.mkdir(exist_ok=True)
        
        # è®¾ç½®æ—¥å¿—
        logging.basicConfig(level=logging.INFO)
        self.logger = logging.getLogger(__name__)
        
        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {'success': 0, 'failed': 0, 'records': 0}
        
        print("ğŸš€ ä¼˜çŸ¿å®Œæ•´æ•°æ®ä¸‹è½½å™¨")
        print("ğŸ¯ ç›®æ ‡: ä¸‹è½½10ä¸ªæ¥å£å…¨éƒ¨æ•°æ®")
        print("ğŸ“Š èŒƒå›´: å…¨å¸‚åœºè‚¡ç¥¨ï¼Œ2010-2025å¹´")
        print("=" * 60)
    
    def get_all_stocks(self) -> List[str]:
        """è·å–å…¨éƒ¨è‚¡ç¥¨åˆ—è¡¨"""
        try:
            print("ğŸ“‹ è·å–å…¨å¸‚åœºè‚¡ç¥¨åˆ—è¡¨...")
            result = self.client.DataAPI.EquGet(
                listStatusCD='L',
                field='secID,ticker',
                pandas='1'
            )
            
            if isinstance(result, pd.DataFrame) and not result.empty:
                stocks = result['secID'].unique().tolist()
                print(f"âœ… è·å–åˆ° {len(stocks)} åªè‚¡ç¥¨")
                return stocks
            return []
        except Exception as e:
            print(f"âŒ è·å–è‚¡ç¥¨åˆ—è¡¨å¤±è´¥: {e}")
            return []
    
    def download_adjustment_factor(self, stocks: List[str]) -> bool:
        """ä¸‹è½½å¤æƒå› å­æ•°æ®"""
        print("\nğŸ“‰ ä¸‹è½½å¤æƒå› å­æ•°æ®...")
        
        output_dir = self.base_path / "adjustment"
        output_dir.mkdir(exist_ok=True)
        
        try:
            batch_size = 200  # å¤æƒæ•°æ®æ‰¹æ¬¡å¯ä»¥å¤§ä¸€äº›
            all_data = []
            
            for i in range(0, len(stocks), batch_size):
                batch_stocks = stocks[i:i+batch_size]
                batch_tickers = ','.join([s.split('.')[0] for s in batch_stocks])
                
                print(f"  ğŸ”„ æ‰¹æ¬¡ {i//batch_size + 1}/{(len(stocks)-1)//batch_size + 1}: {len(batch_stocks)} åªè‚¡ç¥¨")
                
                try:
                    result = self.client.DataAPI.MktAdjfGet(
                        secID='',
                        ticker=batch_tickers,
                        beginDate='20100101',
                        endDate='20250831',
                        field='secID,ticker,exDivDate,adjfactor',
                        pandas='1'
                    )
                    
                    if isinstance(result, pd.DataFrame) and not result.empty:
                        all_data.append(result)
                        print(f"    âœ… å®Œæˆ: {len(result)} æ¡è®°å½•")
                    
                    time.sleep(0.5)
                    
                except Exception as e:
                    print(f"    âŒ æ‰¹æ¬¡å¤±è´¥: {e}")
                    continue
            
            if all_data:
                combined = pd.concat(all_data, ignore_index=True)
                output_file = output_dir / "adjustment_factors_2010_2025.csv"
                combined.to_csv(output_file, index=False)
                
                self.stats['success'] += 1
                self.stats['records'] += len(combined)
                print(f"âœ… å¤æƒå› å­å®Œæˆ: {len(combined)} æ¡è®°å½•")
                return True
            
            return False
            
        except Exception as e:
            print(f"âŒ å¤æƒå› å­ä¸‹è½½å¤±è´¥: {e}")
            self.stats['failed'] += 1
            return False
    
    def download_dividend_data(self, stocks: List[str]) -> bool:
        """ä¸‹è½½è‚¡ç¥¨åˆ†çº¢æ•°æ®"""
        print("\nğŸ’ ä¸‹è½½è‚¡ç¥¨åˆ†çº¢æ•°æ®...")
        
        output_dir = self.base_path / "dividend"
        output_dir.mkdir(exist_ok=True)
        
        try:
            batch_size = 200
            all_data = []
            
            for i in range(0, len(stocks), batch_size):
                batch_stocks = stocks[i:i+batch_size]
                batch_tickers = ','.join([s.split('.')[0] for s in batch_stocks])
                
                print(f"  ğŸ”„ æ‰¹æ¬¡ {i//batch_size + 1}/{(len(stocks)-1)//batch_size + 1}: {len(batch_stocks)} åªè‚¡ç¥¨")
                
                try:
                    result = self.client.DataAPI.EquDivGet(
                        secID='',
                        ticker=batch_tickers,
                        beginDate='20100101',
                        endDate='20250831',
                        field='secID,ticker,exDate,dividend,splitRatio',
                        pandas='1'
                    )
                    
                    if isinstance(result, pd.DataFrame) and not result.empty:
                        all_data.append(result)
                        print(f"    âœ… å®Œæˆ: {len(result)} æ¡è®°å½•")
                    
                    time.sleep(0.5)
                    
                except Exception as e:
                    print(f"    âŒ æ‰¹æ¬¡å¤±è´¥: {e}")
                    continue
            
            if all_data:
                combined = pd.concat(all_data, ignore_index=True)
                output_file = output_dir / "dividend_data_2010_2025.csv"
                combined.to_csv(output_file, index=False)
                
                self.stats['success'] += 1
                self.stats['records'] += len(combined)
                print(f"âœ… è‚¡ç¥¨åˆ†çº¢å®Œæˆ: {len(combined)} æ¡è®°å½•")
                return True
            
            return False
            
        except Exception as e:
            print(f"âŒ è‚¡ç¥¨åˆ†çº¢ä¸‹è½½å¤±è´¥: {e}")
            self.stats['failed'] += 1
            return False
    
    def download_limit_data(self, stocks: List[str]) -> bool:
        """ä¸‹è½½æ¶¨è·Œåœæ•°æ®"""
        print("\nğŸ“Š ä¸‹è½½æ¶¨è·Œåœæ•°æ®...")
        
        output_dir = self.base_path / "limit_info"
        output_dir.mkdir(exist_ok=True)
        
        try:
            # æ¶¨è·Œåœæ•°æ®é‡å¤§ï¼Œåˆ†å¹´ä¸‹è½½
            all_data = []
            years = [2024, 2023, 2022, 2021, 2020]  # å…ˆä¸‹è½½è¿‘5å¹´
            
            for year in years:
                print(f"  ğŸ“… ä¸‹è½½ {year} å¹´æ•°æ®...")
                batch_size = 100
                
                for i in range(0, len(stocks), batch_size):
                    batch_stocks = stocks[i:i+batch_size]
                    batch_tickers = ','.join([s.split('.')[0] for s in batch_stocks])
                    
                    print(f"    ğŸ”„ {year}å¹´ æ‰¹æ¬¡ {i//batch_size + 1}: {len(batch_stocks)} åªè‚¡ç¥¨")
                    
                    try:
                        result = self.client.DataAPI.MktLimitGet(
                            secID='',
                            ticker=batch_tickers,
                            beginDate=f'{year}0101',
                            endDate=f'{year}1231',
                            field='secID,ticker,tradeDate,upLimit,downLimit',
                            pandas='1'
                        )
                        
                        if isinstance(result, pd.DataFrame) and not result.empty:
                            all_data.append(result)
                            print(f"      âœ… å®Œæˆ: {len(result)} æ¡è®°å½•")
                        
                        time.sleep(0.3)
                        
                    except Exception as e:
                        print(f"      âŒ æ‰¹æ¬¡å¤±è´¥: {e}")
                        continue
            
            if all_data:
                combined = pd.concat(all_data, ignore_index=True)
                output_file = output_dir / "limit_data_2020_2024.csv"
                combined.to_csv(output_file, index=False)
                
                self.stats['success'] += 1
                self.stats['records'] += len(combined)
                print(f"âœ… æ¶¨è·Œåœæ•°æ®å®Œæˆ: {len(combined)} æ¡è®°å½•")
                return True
            
            return False
            
        except Exception as e:
            print(f"âŒ æ¶¨è·Œåœæ•°æ®ä¸‹è½½å¤±è´¥: {e}")
            self.stats['failed'] += 1
            return False
    
    def download_rank_list(self) -> bool:
        """ä¸‹è½½é¾™è™æ¦œæ•°æ®"""
        print("\nğŸ”¥ ä¸‹è½½é¾™è™æ¦œæ•°æ®...")
        
        output_dir = self.base_path / "rank_list"
        output_dir.mkdir(exist_ok=True)
        
        try:
            # é¾™è™æ¦œæ•°æ®ä¸éœ€è¦æŒ‡å®šè‚¡ç¥¨ï¼ŒæŒ‰æ—¶é—´ä¸‹è½½
            all_data = []
            years = [2024, 2023, 2022, 2021, 2020]
            
            for year in years:
                print(f"  ğŸ“… ä¸‹è½½ {year} å¹´é¾™è™æ¦œæ•°æ®...")
                
                try:
                    result = self.client.DataAPI.MktRankListStocksGet(
                        beginDate=f'{year}0101',
                        endDate=f'{year}1231',
                        field='secID,ticker,tradeDate,rankReason,buyAmt,sellAmt',
                        pandas='1'
                    )
                    
                    if isinstance(result, pd.DataFrame) and not result.empty:
                        all_data.append(result)
                        print(f"    âœ… {year}å¹´å®Œæˆ: {len(result)} æ¡è®°å½•")
                    
                    time.sleep(1)
                    
                except Exception as e:
                    print(f"    âŒ {year}å¹´å¤±è´¥: {e}")
                    continue
            
            if all_data:
                combined = pd.concat(all_data, ignore_index=True)
                output_file = output_dir / "rank_list_2020_2024.csv"
                combined.to_csv(output_file, index=False)
                
                self.stats['success'] += 1
                self.stats['records'] += len(combined)
                print(f"âœ… é¾™è™æ¦œæ•°æ®å®Œæˆ: {len(combined)} æ¡è®°å½•")
                return True
            
            return False
            
        except Exception as e:
            print(f"âŒ é¾™è™æ¦œæ•°æ®ä¸‹è½½å¤±è´¥: {e}")
            self.stats['failed'] += 1
            return False
    
    def run_complete_download(self):
        """è¿è¡Œå®Œæ•´æ•°æ®ä¸‹è½½"""
        start_time = datetime.now()
        
        try:
            # 1. è·å–å…¨éƒ¨è‚¡ç¥¨åˆ—è¡¨
            stocks = self.get_all_stocks()
            if not stocks:
                print("âŒ æ— æ³•è·å–è‚¡ç¥¨åˆ—è¡¨")
                return
            
            print(f"\nğŸ¯ å¼€å§‹ä¸‹è½½å…¨å¸‚åœºæ•°æ®: {len(stocks)} åªè‚¡ç¥¨")
            print("ğŸ“Š é¢„è®¡ä¸‹è½½æ—¶é—´: 2-3å°æ—¶")
            print("ğŸ’¾ é¢„è®¡æ•°æ®é‡: 1-2GB")
            print()
            
            # 2. ä¸‹è½½å„ç±»æ•°æ®
            print("ğŸ”„ å¼€å§‹åˆ†é˜¶æ®µä¸‹è½½...")
            
            # é˜¶æ®µ1: å¤æƒå› å­
            if self.download_adjustment_factor(stocks):
                print("âœ… é˜¶æ®µ1å®Œæˆ: å¤æƒå› å­")
            
            # é˜¶æ®µ2: è‚¡ç¥¨åˆ†çº¢
            if self.download_dividend_data(stocks):
                print("âœ… é˜¶æ®µ2å®Œæˆ: è‚¡ç¥¨åˆ†çº¢")
            
            # é˜¶æ®µ3: æ¶¨è·Œåœæ•°æ®
            if self.download_limit_data(stocks):
                print("âœ… é˜¶æ®µ3å®Œæˆ: æ¶¨è·Œåœæ•°æ®")
            
            # é˜¶æ®µ4: é¾™è™æ¦œæ•°æ®
            if self.download_rank_list():
                print("âœ… é˜¶æ®µ4å®Œæˆ: é¾™è™æ¦œæ•°æ®")
            
            # 3. ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
            end_time = datetime.now()
            duration = end_time - start_time
            
            print(f"\nğŸŠ å®Œæ•´æ•°æ®ä¸‹è½½å®Œæˆ!")
            print(f"â±ï¸ æ€»è€—æ—¶: {duration}")
            print(f"âœ… æˆåŠŸ: {self.stats['success']} ä¸ªæ•°æ®é›†")
            print(f"âŒ å¤±è´¥: {self.stats['failed']} ä¸ªæ•°æ®é›†")
            print(f"ğŸ“‹ æ€»è®°å½•: {self.stats['records']:,} æ¡")
            
        except Exception as e:
            print(f"âŒ ä¸‹è½½è¿‡ç¨‹å¼‚å¸¸: {e}")

def main():
    downloader = CompleteDataDownloader()
    downloader.run_complete_download()

if __name__ == "__main__":
    main()