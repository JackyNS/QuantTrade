#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å…¨è‚¡ç¥¨è¦†ç›–åˆ†æå™¨
æ£€æŸ¥æ‰€æœ‰Aè‚¡ä»2000å¹´1æœˆ1æ—¥åˆ°2025å¹´8æœˆ31æ—¥çš„æ•°æ®å®Œæ•´æ€§
"""

import pandas as pd
import numpy as np
from pathlib import Path
from datetime import datetime, timedelta
import json
import warnings
from collections import defaultdict
import os
warnings.filterwarnings('ignore')

class CompleteStockCoverageAnalyzer:
    """å…¨è‚¡ç¥¨è¦†ç›–åˆ†æå™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–åˆ†æå™¨"""
        self.base_path = Path("/Users/jackstudio/QuantTrade/data")
        self.target_start = pd.Timestamp('2000-01-01')
        self.target_end = pd.Timestamp('2025-08-31')
        
        self.stats = {
            'analysis_start': datetime.now(),
            'all_stocks_found': set(),
            'stock_coverage': {},
            'invalid_stocks': [],
            'incomplete_stocks': [],
            'complete_stocks': []
        }
    
    def get_all_stocks_from_batches(self):
        """ä»æ‰€æœ‰æ‰¹æ¬¡æ–‡ä»¶ä¸­è·å–å®Œæ•´çš„è‚¡ç¥¨åˆ—è¡¨"""
        print("ğŸ” æ‰«ææ‰€æœ‰æ‰¹æ¬¡æ–‡ä»¶è·å–å®Œæ•´è‚¡ç¥¨åˆ—è¡¨...")
        
        daily_path = self.base_path / "priority_download/market_data/daily"
        batch_files = list(daily_path.glob("*.csv"))
        
        print(f"   ğŸ“„ æ‰¾åˆ°æ‰¹æ¬¡æ–‡ä»¶: {len(batch_files)} ä¸ª")
        
        all_stocks = set()
        file_count = 0
        
        for file_path in batch_files:
            try:
                df = pd.read_csv(file_path)
                stocks_in_file = set(df['secID'].unique())
                all_stocks.update(stocks_in_file)
                file_count += 1
                
                if file_count % 100 == 0:
                    print(f"   ğŸ“Š å·²å¤„ç†: {file_count}/{len(batch_files)} æ–‡ä»¶, ç´¯è®¡è‚¡ç¥¨: {len(all_stocks)}")
                    
            except Exception as e:
                print(f"   âŒ æ–‡ä»¶è¯»å–å¤±è´¥: {file_path.name}")
                continue
        
        print(f"   âœ… æ‰«æå®Œæˆ: {len(all_stocks)} åªè‚¡ç¥¨")
        self.stats['all_stocks_found'] = all_stocks
        return all_stocks
    
    def analyze_stock_coverage(self, stock_id):
        """åˆ†æå•åªè‚¡ç¥¨çš„æ•°æ®è¦†ç›–æƒ…å†µ"""
        daily_path = self.base_path / "priority_download/market_data/daily"
        batch_files = list(daily_path.glob("*.csv"))
        
        stock_data = []
        
        # éå†æ‰€æœ‰æ‰¹æ¬¡æ–‡ä»¶å¯»æ‰¾è¯¥è‚¡ç¥¨æ•°æ®
        for file_path in batch_files:
            try:
                df = pd.read_csv(file_path)
                stock_df = df[df['secID'] == stock_id]
                
                if len(stock_df) > 0:
                    stock_data.append(stock_df)
                    
            except Exception as e:
                continue
        
        if not stock_data:
            return {
                'has_data': False,
                'date_range': None,
                'completeness': 'no_data'
            }
        
        # åˆå¹¶æ‰€æœ‰æ•°æ®
        combined_df = pd.concat(stock_data, ignore_index=True)
        combined_df['tradeDate'] = pd.to_datetime(combined_df['tradeDate'])
        combined_df = combined_df.drop_duplicates(subset=['tradeDate']).sort_values('tradeDate')
        
        # åˆ†æè¦†ç›–èŒƒå›´
        min_date = combined_df['tradeDate'].min()
        max_date = combined_df['tradeDate'].max()
        total_records = len(combined_df)
        
        # åˆ¤æ–­å®Œæ•´æ€§
        start_coverage = min_date <= self.target_start + timedelta(days=365)  # å…è®¸1å¹´å†…å¼€å§‹
        end_coverage = max_date >= self.target_end - timedelta(days=30)       # å…è®¸1æœˆå†…ç»“æŸ
        
        if start_coverage and end_coverage:
            completeness = 'complete'
        elif start_coverage:
            completeness = 'partial_end_missing'
        elif end_coverage:
            completeness = 'partial_start_missing'
        else:
            completeness = 'insufficient'
        
        return {
            'has_data': True,
            'date_range': (min_date, max_date),
            'total_records': total_records,
            'completeness': completeness,
            'start_coverage': start_coverage,
            'end_coverage': end_coverage
        }
    
    def batch_analyze_all_stocks(self, all_stocks):
        """æ‰¹é‡åˆ†ææ‰€æœ‰è‚¡ç¥¨çš„è¦†ç›–æƒ…å†µ"""
        print(f"\\nğŸ“Š å¼€å§‹åˆ†æ {len(all_stocks)} åªè‚¡ç¥¨çš„æ•°æ®å®Œæ•´æ€§...")
        print("ğŸ¯ ç›®æ ‡èŒƒå›´: 2000å¹´1æœˆ1æ—¥ - 2025å¹´8æœˆ31æ—¥")
        print("=" * 80)
        
        complete_stocks = []
        incomplete_stocks = []
        invalid_stocks = []
        
        stock_list = list(all_stocks)
        
        # åˆ†ææ¯åªè‚¡ç¥¨ï¼ˆæ˜¾ç¤ºè¿›åº¦ï¼‰
        for i, stock_id in enumerate(stock_list, 1):
            coverage = self.analyze_stock_coverage(stock_id)
            
            if not coverage['has_data']:
                invalid_stocks.append(stock_id)
                status = "âŒ æ— æ•°æ®"
            elif coverage['completeness'] == 'complete':
                complete_stocks.append({
                    'stock_id': stock_id,
                    'date_range': coverage['date_range'],
                    'records': coverage['total_records']
                })
                status = "âœ… å®Œæ•´"
            else:
                incomplete_stocks.append({
                    'stock_id': stock_id,
                    'date_range': coverage['date_range'],
                    'completeness': coverage['completeness'],
                    'records': coverage['total_records']
                })
                status = f"âš ï¸ {coverage['completeness']}"
            
            # æ˜¾ç¤ºè¿›åº¦
            if i % 50 == 0 or i <= 20:
                print(f"[{i:4}/{len(stock_list)}] {stock_id}: {status}")
            elif i % 100 == 0:
                progress = (i / len(stock_list)) * 100
                print(f"ğŸ“ˆ è¿›åº¦: {i}/{len(stock_list)} ({progress:.1f}%) | å®Œæ•´:{len(complete_stocks)} ä¸å®Œæ•´:{len(incomplete_stocks)} æ— æ•ˆ:{len(invalid_stocks)}")
        
        # ä¿å­˜ç»“æœ
        self.stats['complete_stocks'] = complete_stocks
        self.stats['incomplete_stocks'] = incomplete_stocks
        self.stats['invalid_stocks'] = invalid_stocks
        
        return complete_stocks, incomplete_stocks, invalid_stocks
    
    def generate_coverage_report(self):
        """ç”Ÿæˆè¦†ç›–æƒ…å†µæŠ¥å‘Š"""
        print("ğŸ” å¼€å§‹å…¨Aè‚¡æ•°æ®è¦†ç›–åˆ†æ...")
        print("=" * 80)
        
        # è·å–æ‰€æœ‰è‚¡ç¥¨
        all_stocks = self.get_all_stocks_from_batches()
        
        if not all_stocks:
            print("âŒ æœªæ‰¾åˆ°ä»»ä½•è‚¡ç¥¨æ•°æ®")
            return
        
        # åˆ†ææ‰€æœ‰è‚¡ç¥¨è¦†ç›–æƒ…å†µ
        complete_stocks, incomplete_stocks, invalid_stocks = self.batch_analyze_all_stocks(all_stocks)
        
        # ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
        total_stocks = len(all_stocks)
        complete_count = len(complete_stocks)
        incomplete_count = len(incomplete_stocks)
        invalid_count = len(invalid_stocks)
        
        coverage_rate = (complete_count / total_stocks) * 100 if total_stocks > 0 else 0
        
        report = {
            'analysis_info': {
                'analysis_time': self.stats['analysis_start'].isoformat(),
                'target_period': '2000å¹´1æœˆ1æ—¥ - 2025å¹´8æœˆ31æ—¥',
                'analysis_scope': 'å…¨Aè‚¡æ•°æ®å®Œæ•´æ€§åˆ†æ'
            },
            'coverage_summary': {
                'total_stocks_found': total_stocks,
                'complete_stocks': complete_count,
                'incomplete_stocks': incomplete_count,
                'invalid_stocks': invalid_count,
                'coverage_rate': f"{coverage_rate:.1f}%"
            },
            'detailed_results': {
                'complete_stocks_list': [stock['stock_id'] for stock in complete_stocks],
                'incomplete_stocks_detail': [
                    {
                        'stock_id': stock['stock_id'],
                        'issue': stock['completeness'],
                        'date_range': f"{stock['date_range'][0].date()} - {stock['date_range'][1].date()}" if stock['date_range'] else 'N/A',
                        'records': stock.get('records', 0)
                    } for stock in incomplete_stocks
                ],
                'invalid_stocks_list': invalid_stocks
            },
            'data_quality_assessment': {
                'overall_quality': 'excellent' if coverage_rate >= 90 else 'good' if coverage_rate >= 70 else 'needs_improvement',
                'recommendation': self._get_recommendation(coverage_rate, complete_count, total_stocks)
            }
        }
        
        # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
        report_file = self.base_path / 'complete_stock_coverage_report.json'
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2, default=str)
        
        # è¾“å‡ºæ‘˜è¦
        print("\\nğŸŠ å…¨Aè‚¡æ•°æ®è¦†ç›–åˆ†æå®Œæˆ!")
        print("=" * 80)
        print("ğŸ“Š è¦†ç›–ç»Ÿè®¡:")
        print(f"   ğŸ“ˆ è‚¡ç¥¨æ€»æ•°: {total_stocks}")
        print(f"   âœ… å®Œæ•´è¦†ç›–: {complete_count} ({coverage_rate:.1f}%)")
        print(f"   âš ï¸ ä¸å®Œæ•´: {incomplete_count}")
        print(f"   âŒ æ— æ•ˆæ•°æ®: {invalid_count}")
        
        if complete_count > 0:
            print(f"\\nâœ… å®Œæ•´æ•°æ®æ ·æœ¬ (å‰10åª):")
            for stock in complete_stocks[:10]:
                date_range = f"{stock['date_range'][0].date()} - {stock['date_range'][1].date()}"
                print(f"      {stock['stock_id']}: {stock['records']} æ¡è®°å½• ({date_range})")
        
        if incomplete_stocks:
            print(f"\\nâš ï¸ ä¸å®Œæ•´æ•°æ®æ ·æœ¬ (å‰10åª):")
            for stock in incomplete_stocks[:10]:
                date_range = f"{stock['date_range'][0].date()} - {stock['date_range'][1].date()}" if stock['date_range'] else 'N/A'
                print(f"      {stock['stock_id']}: {stock['completeness']} ({date_range})")
        
        print(f"\\nğŸ“„ è¯¦ç»†æŠ¥å‘Š: {report_file}")
        print(f"ğŸ’¡ è¯„ä¼°: {report['data_quality_assessment']['overall_quality']}")
        print(f"ğŸ”§ å»ºè®®: {report['data_quality_assessment']['recommendation']}")
    
    def _get_recommendation(self, coverage_rate, complete_count, total_stocks):
        """æ ¹æ®è¦†ç›–ç‡ç”Ÿæˆå»ºè®®"""
        if coverage_rate >= 90:
            return f"æ•°æ®è´¨é‡ä¼˜ç§€ï¼Œ{complete_count}åªè‚¡ç¥¨æ•°æ®å®Œæ•´ï¼Œå¯ç›´æ¥ç”¨äºåˆ†æ"
        elif coverage_rate >= 70:
            return f"æ•°æ®è´¨é‡è‰¯å¥½ï¼Œå»ºè®®é‡ç‚¹ä½¿ç”¨{complete_count}åªå®Œæ•´è‚¡ç¥¨è¿›è¡Œåˆ†æ"
        else:
            return f"æ•°æ®å®Œæ•´æ€§éœ€è¦æ”¹è¿›ï¼Œå»ºè®®è¡¥å……ç¼ºå¤±æ•°æ®æˆ–ä½¿ç”¨ç°æœ‰{complete_count}åªå®Œæ•´è‚¡ç¥¨"

def main():
    """ä¸»å‡½æ•°"""
    analyzer = CompleteStockCoverageAnalyzer()
    analyzer.generate_coverage_report()

if __name__ == "__main__":
    main()