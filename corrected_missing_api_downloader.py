#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¿®æ­£ç‰ˆç¼ºå¤±APIä¸‹è½½å™¨ - åŸºäºAPIæµ‹è¯•ç»“æœä¼˜åŒ–è°ƒç”¨æ–¹å¼
"""

import uqer
import pandas as pd
from datetime import datetime, timedelta
from pathlib import Path
import time
import logging
import json

UQER_TOKEN = "68b9922817ae6273137bda7acba81e293582ba347281dfcc056dcb245b23faf3"

class CorrectedMissingAPIDownloader:
    """ä¿®æ­£ç‰ˆç¼ºå¤±APIä¸‹è½½å™¨"""
    
    def __init__(self):
        self.client = uqer.Client(token=UQER_TOKEN)
        self.data_dir = Path("data/final_comprehensive_download")
        
        # é…ç½®æ—¥å¿—
        log_file = self.data_dir / "corrected_missing_apis_download.log"
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_file),
                logging.StreamHandler()
            ]
        )
        
        # åŸºäºæµ‹è¯•ç»“æœçš„æ­£ç¡®APIé…ç½®
        self.api_configs = {
            "EquMarginSecGet": {
                "desc": "å¯å……æŠµä¿è¯é‡‘è¯åˆ¸",
                "call_method": "date_range_required",
                "dir_name": "equmarginsec",
                "start_year": 2010  # ä»2010å¹´å¼€å§‹å°è¯•ï¼Œmargin tradingå¼€å§‹æ—¶é—´
            },
            "MktRANKInstTrGet": {
                "desc": "è¡Œä¸šæˆåˆ†æ¢æ‰‹ç‡æ’å", 
                "call_method": "trade_date_required",
                "dir_name": "mktrankinstr",
                "start_year": 2005  # ä»2005å¹´å¼€å§‹å°è¯•
            },
            "FdmtEeGet": {
                "desc": "ä¸šç»©å¿«æŠ¥",
                "call_method": "no_params",
                "dir_name": "fdmtee",
                "start_year": 2000  # æ— å‚æ•°è°ƒç”¨ï¼Œè·å–å…¨éƒ¨æ•°æ®
            }
        }
        
    def download_fdmt_ee(self):
        """ä¸‹è½½ä¸šç»©å¿«æŠ¥ - æ— å‚æ•°è°ƒç”¨è·å–å…¨éƒ¨æ•°æ®"""
        config = self.api_configs["FdmtEeGet"]
        desc = config["desc"]
        dir_name = config["dir_name"]
        
        category_dir = self.data_dir / "special_trading"
        api_dir = category_dir / dir_name
        api_dir.mkdir(parents=True, exist_ok=True)
        
        try:
            logging.info(f"ğŸ“¥ å¼€å§‹ä¸‹è½½ {desc}ï¼ˆæ— å‚æ•°è·å–å…¨éƒ¨æ•°æ®ï¼‰...")
            
            # ç›´æ¥è°ƒç”¨APIè·å–æ‰€æœ‰æ•°æ®
            df = uqer.DataAPI.FdmtEeGet()
            
            if not df.empty:
                # ä¿å­˜å®Œæ•´æ•°æ®
                file_path = api_dir / "all_data.csv"
                df.to_csv(file_path, index=False, encoding='utf-8-sig')
                
                # æŒ‰å¹´ä»½åˆ†ç»„ä¿å­˜
                if 'publishDate' in df.columns:
                    df['year'] = pd.to_datetime(df['publishDate']).dt.year
                    for year in sorted(df['year'].unique()):
                        year_data = df[df['year'] == year].drop('year', axis=1)
                        if not year_data.empty:
                            year_file = api_dir / f"year_{year}.csv"
                            year_data.to_csv(year_file, index=False, encoding='utf-8-sig')
                            logging.info(f"âœ… {desc} {year}å¹´: {len(year_data)} æ¡è®°å½•")
                
                total_records = len(df)
                logging.info(f"ğŸ“Š {desc} å®Œæˆ: æ€»è®¡ {total_records} æ¡è®°å½•")
                return total_records
            else:
                logging.info(f"âšª {desc}: æ— æ•°æ®")
                return 0
                
        except Exception as e:
            logging.error(f"âŒ {desc} ä¸‹è½½å¤±è´¥: {str(e)}")
            return 0
    
    def download_margin_sec(self):
        """ä¸‹è½½å¯å……æŠµä¿è¯é‡‘è¯åˆ¸ - éœ€è¦beginDateå’ŒendDate"""
        config = self.api_configs["EquMarginSecGet"]
        desc = config["desc"]
        dir_name = config["dir_name"]
        start_year = config["start_year"]
        
        category_dir = self.data_dir / "special_trading"
        api_dir = category_dir / dir_name
        api_dir.mkdir(parents=True, exist_ok=True)
        
        total_records = 0
        logging.info(f"ğŸ“¥ å¼€å§‹ä¸‹è½½ {desc}ï¼ˆä»{start_year}å¹´å¼€å§‹ï¼‰...")
        
        # ä»margin tradingå¼€å§‹çš„å¹´ä»½å°è¯•
        for year in range(start_year, 2025):
            try:
                begin_date = f"{year}-01-01"
                end_date = f"{year}-12-31" if year < 2024 else "2024-12-31"
                
                df = uqer.DataAPI.EquMarginSecGet(beginDate=begin_date, endDate=end_date)
                
                if not df.empty:
                    file_path = api_dir / f"year_{year}.csv"
                    df.to_csv(file_path, index=False, encoding='utf-8-sig')
                    logging.info(f"âœ… {desc} {year}å¹´: {len(df)} æ¡è®°å½•")
                    total_records += len(df)
                else:
                    logging.info(f"âšª {desc} {year}å¹´: æ— æ•°æ®")
                
                time.sleep(1)
                
            except Exception as e:
                if "æ— æ•ˆçš„è¯·æ±‚å‚æ•°" in str(e):
                    logging.info(f"âšª {desc} {year}å¹´: è¯¥å¹´ä»½æ— æ•°æ®æˆ–æœåŠ¡ä¸å¯ç”¨")
                else:
                    logging.error(f"âŒ {desc} {year}å¹´ä¸‹è½½å¤±è´¥: {str(e)}")
                time.sleep(2)
        
        logging.info(f"ğŸ“Š {desc} å®Œæˆ: æ€»è®¡ {total_records} æ¡è®°å½•")
        return total_records
    
    def download_rank_inst_tr(self):
        """ä¸‹è½½è¡Œä¸šæˆåˆ†æ¢æ‰‹ç‡æ’å - éœ€è¦tradeDate"""
        config = self.api_configs["MktRANKInstTrGet"]
        desc = config["desc"]
        dir_name = config["dir_name"]
        start_year = config["start_year"]
        
        category_dir = self.data_dir / "special_trading"
        api_dir = category_dir / dir_name
        api_dir.mkdir(parents=True, exist_ok=True)
        
        total_records = 0
        logging.info(f"ğŸ“¥ å¼€å§‹ä¸‹è½½ {desc}ï¼ˆä»{start_year}å¹´å¼€å§‹ï¼ŒæŒ‰æœˆé‡‡æ ·ï¼‰...")
        
        # ä»æŒ‡å®šå¹´ä»½å¼€å§‹ï¼Œæ¯å¹´å–å‡ ä¸ªå…³é”®æ—¥æœŸé‡‡æ ·
        sample_dates = ["-01-01", "-03-31", "-06-30", "-09-30", "-12-31"]
        
        for year in range(start_year, 2025):
            year_records = 0
            for date_suffix in sample_dates:
                try:
                    trade_date = f"{year}{date_suffix}"
                    if year == 2024 and date_suffix in ["-09-30", "-12-31"]:
                        continue  # è·³è¿‡æœªæ¥æ—¥æœŸ
                    
                    df = uqer.DataAPI.MktRANKInstTrGet(tradeDate=trade_date)
                    
                    if not df.empty:
                        date_file = api_dir / f"{trade_date.replace('-', '')}.csv"
                        df.to_csv(date_file, index=False, encoding='utf-8-sig')
                        year_records += len(df)
                    
                    time.sleep(0.5)
                    
                except Exception as e:
                    if "æ— æ•ˆçš„è¯·æ±‚å‚æ•°" not in str(e):
                        logging.error(f"âŒ {desc} {trade_date}ä¸‹è½½å¤±è´¥: {str(e)}")
                    time.sleep(1)
            
            if year_records > 0:
                logging.info(f"âœ… {desc} {year}å¹´: {year_records} æ¡è®°å½•")
                total_records += year_records
            else:
                logging.info(f"âšª {desc} {year}å¹´: æ— æ•°æ®")
        
        logging.info(f"ğŸ“Š {desc} å®Œæˆ: æ€»è®¡ {total_records} æ¡è®°å½•")
        return total_records
    
    def run(self):
        """æ‰§è¡Œä¿®æ­£ç‰ˆä¸‹è½½"""
        logging.info("ğŸš€ å¼€å§‹ä¿®æ­£ç‰ˆç¼ºå¤±APIä¸‹è½½...")
        logging.info("ğŸ“‹ åŸºäºAPIæµ‹è¯•ç»“æœä¼˜åŒ–è°ƒç”¨æ–¹å¼")
        
        results = {}
        total_records = 0
        
        # 1. ä¸‹è½½ä¸šç»©å¿«æŠ¥ï¼ˆæœ€å®¹æ˜“æˆåŠŸçš„ï¼‰
        try:
            records = self.download_fdmt_ee()
            results["FdmtEeGet"] = records
            total_records += records
        except Exception as e:
            logging.error(f"âŒ FdmtEeGet å¤„ç†å¤±è´¥: {str(e)}")
            results["FdmtEeGet"] = 0
        
        # 2. ä¸‹è½½å¯å……æŠµä¿è¯é‡‘è¯åˆ¸
        try:
            records = self.download_margin_sec()
            results["EquMarginSecGet"] = records
            total_records += records
        except Exception as e:
            logging.error(f"âŒ EquMarginSecGet å¤„ç†å¤±è´¥: {str(e)}")
            results["EquMarginSecGet"] = 0
        
        # 3. ä¸‹è½½è¡Œä¸šæˆåˆ†æ¢æ‰‹ç‡æ’å
        try:
            records = self.download_rank_inst_tr()
            results["MktRANKInstTrGet"] = records
            total_records += records
        except Exception as e:
            logging.error(f"âŒ MktRANKInstTrGet å¤„ç†å¤±è´¥: {str(e)}")
            results["MktRANKInstTrGet"] = 0
        
        # æ›´æ–°è¿›åº¦æ–‡ä»¶
        success_count = sum(1 for r in results.values() if r > 0)
        self.update_progress(results, total_records)
        
        logging.info(f"ğŸ‰ ä¿®æ­£ç‰ˆä¸‹è½½å®Œæˆ!")
        logging.info(f"ğŸ“Š ç»“æœæ‘˜è¦: æˆåŠŸ {success_count}/3 ä¸ªAPI, æ€»è®°å½• {total_records} æ¡")
        
        for api_name, records in results.items():
            if records > 0:
                logging.info(f"  âœ… {api_name}: {records:,} æ¡è®°å½•")
            else:
                logging.info(f"  âŒ {api_name}: æœªè·å–åˆ°æ•°æ®")
        
        if success_count == 3:
            logging.info("ğŸŒŸ æ‰€æœ‰ç¼ºå¤±APIä¸‹è½½æˆåŠŸï¼ç°åœ¨æ‹¥æœ‰å®Œæ•´çš„58ä¸ªAPIæ•°æ®ï¼")
        elif success_count > 0:
            logging.info(f"âœ¨ éƒ¨åˆ†APIä¸‹è½½æˆåŠŸï¼Œ{3 - success_count} ä¸ªAPIå¯èƒ½æ— å¯ç”¨æ•°æ®")
        else:
            logging.warning("âš ï¸ æ‰€æœ‰APIä¸‹è½½å¤±è´¥ï¼Œå¯èƒ½æœåŠ¡ä¸å¯ç”¨æˆ–å‚æ•°éœ€è¦è¿›ä¸€æ­¥è°ƒæ•´")
    
    def update_progress(self, results, total_records):
        """æ›´æ–°ä¸»è¿›åº¦æ–‡ä»¶"""
        progress_file = self.data_dir / "download_progress.json"
        
        try:
            with open(progress_file, 'r', encoding='utf-8') as f:
                progress_data = json.load(f)
            
            # æ·»åŠ æˆåŠŸçš„API
            completed_apis = progress_data.get("completed_apis", [])
            for api_name, records in results.items():
                if records > 0:
                    api_key = f"special_trading_{api_name}"
                    if api_key not in completed_apis:
                        completed_apis.append(api_key)
            
            # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
            progress_data["completed_apis"] = completed_apis
            progress_data["statistics"]["success_count"] = len(completed_apis)
            progress_data["statistics"]["total_records"] += total_records
            progress_data["last_update"] = datetime.now().isoformat()
            
            # ä¿å­˜æ›´æ–°åçš„è¿›åº¦
            with open(progress_file, 'w', encoding='utf-8') as f:
                json.dump(progress_data, f, indent=2, ensure_ascii=False)
                
            logging.info(f"ğŸ“Š è¿›åº¦æ–‡ä»¶å·²æ›´æ–°: æ€»APIæ•° {len(completed_apis)}")
            
            if len(completed_apis) >= 58:
                logging.info("ğŸŠ æ­å–œï¼å·²å®Œæˆæ‰€æœ‰58ä¸ªAPIæ¥å£ä¸‹è½½ï¼")
            
        except Exception as e:
            logging.error(f"âŒ æ›´æ–°è¿›åº¦æ–‡ä»¶å¤±è´¥: {str(e)}")

if __name__ == "__main__":
    downloader = CorrectedMissingAPIDownloader()
    downloader.run()