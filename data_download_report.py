#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¼˜çŸ¿æ•°æ®ä¸‹è½½å®ŒæˆæŠ¥å‘Š
===================

åˆ†æå·²ä¸‹è½½æ•°æ®çš„å®Œæ•´æ€§å’Œè´¨é‡
"""

import pandas as pd
from pathlib import Path
import json
from datetime import datetime

def analyze_downloaded_data():
    """åˆ†æå·²ä¸‹è½½çš„æ•°æ®"""
    
    print("ğŸ¯ ä¼˜çŸ¿æ ¸å¿ƒæ•°æ®ä¸‹è½½å®ŒæˆæŠ¥å‘Š")
    print("=" * 60)
    print(f"â° æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.now()}")
    print()
    
    data_path = Path("/Users/jackstudio/QuantTrade/data")
    
    # æ£€æŸ¥å„ä¸ªæ•°æ®ç›®å½•
    data_summary = {
        "basic_info": {
            "description": "è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯",
            "files": list((data_path / "basic_info").glob("*.csv")),
            "importance": "ğŸ”¥ æ ¸å¿ƒå¿…éœ€"
        },
        "daily": {
            "description": "è‚¡ç¥¨æ—¥è¡Œæƒ…",
            "files": list((data_path / "daily").glob("*.csv")),
            "importance": "ğŸ”¥ æ ¸å¿ƒå¿…éœ€"
        },
        "calendar": {
            "description": "äº¤æ˜“æ—¥å†",
            "files": list((data_path / "calendar").glob("*.csv")),
            "importance": "ğŸ”¥ æ ¸å¿ƒå¿…éœ€"
        },
        "capital_flow": {
            "description": "èµ„é‡‘æµå‘",
            "files": list((data_path / "capital_flow").glob("*.csv")),
            "importance": "â­ æƒ…ç»ªé‡è¦"
        },
        "limit_info": {
            "description": "æ¶¨è·Œåœä¿¡æ¯",
            "files": list((data_path / "limit_info").glob("*.csv")),
            "importance": "â­ æƒ…ç»ªé‡è¦"
        },
        "rank_list": {
            "description": "é¾™è™æ¦œæ•°æ®",
            "files": list((data_path / "rank_list").glob("*.csv")),
            "importance": "â­ æƒ…ç»ªé‡è¦"
        }
    }
    
    total_records = 0
    successful_downloads = 0
    
    for category, info in data_summary.items():
        print(f"ğŸ“ {info['description']} ({category})")
        print(f"   {info['importance']}")
        
        if info['files']:
            for file in info['files']:
                try:
                    df = pd.read_csv(file)
                    records = len(df)
                    file_size = file.stat().st_size / (1024*1024)  # MB
                    
                    print(f"   âœ… {file.name}: {records:,} æ¡è®°å½•, {file_size:.1f}MB")
                    
                    # æ˜¾ç¤ºæ•°æ®æ—¶é—´èŒƒå›´
                    if 'tradeDate' in df.columns:
                        date_range = f"{df['tradeDate'].min()} è‡³ {df['tradeDate'].max()}"
                        print(f"      ğŸ“… æ—¶é—´èŒƒå›´: {date_range}")
                    elif 'calendarDate' in df.columns:
                        date_range = f"{df['calendarDate'].min()} è‡³ {df['calendarDate'].max()}"
                        print(f"      ğŸ“… æ—¶é—´èŒƒå›´: {date_range}")
                    
                    # æ˜¾ç¤ºè‚¡ç¥¨æ•°é‡
                    if 'ticker' in df.columns:
                        stock_count = df['ticker'].nunique()
                        print(f"      ğŸ¢ è‚¡ç¥¨æ•°é‡: {stock_count} åª")
                    
                    total_records += records
                    successful_downloads += 1
                    
                except Exception as e:
                    print(f"   âŒ {file.name}: è¯»å–å¤±è´¥ - {e}")
        else:
            print(f"   âŒ æ— æ•°æ®æ–‡ä»¶")
        
        print()
    
    # æ±‡æ€»ç»Ÿè®¡
    print("ğŸ“Š ä¸‹è½½æ±‡æ€»ç»Ÿè®¡")
    print("-" * 30)
    print(f"âœ… æˆåŠŸä¸‹è½½: {successful_downloads} ä¸ªæ–‡ä»¶")
    print(f"ğŸ“‹ æ€»è®°å½•æ•°: {total_records:,} æ¡")
    print(f"ğŸ’¾ æ•°æ®è¦†ç›–: 2024å¹´1æœˆ-8æœˆ (æµ‹è¯•æœŸ)")
    print(f"ğŸ¢ è‚¡ç¥¨èŒƒå›´: å‰100åªAè‚¡ (æµ‹è¯•)")
    
    # è¯„ä¼°æ•°æ®å®Œæ•´æ€§
    print("\nğŸ¯ æ•°æ®å®Œæ•´æ€§è¯„ä¼°")
    print("-" * 30)
    
    core_missing = []
    sentiment_missing = []
    
    if not (data_path / "basic_info").glob("*.csv"):
        core_missing.append("è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯")
    if not (data_path / "daily").glob("*.csv"):
        core_missing.append("è‚¡ç¥¨æ—¥è¡Œæƒ…") 
    if not (data_path / "calendar").glob("*.csv"):
        core_missing.append("äº¤æ˜“æ—¥å†")
        
    if not (data_path / "capital_flow").glob("*.csv"):
        sentiment_missing.append("èµ„é‡‘æµå‘")
    if not (data_path / "limit_info").glob("*.csv"):
        sentiment_missing.append("æ¶¨è·Œåœä¿¡æ¯")
    if not (data_path / "rank_list").glob("*.csv"):
        sentiment_missing.append("é¾™è™æ¦œæ•°æ®")
    
    if not core_missing and not sentiment_missing:
        print("ğŸŠ æ•°æ®å®Œæ•´æ€§: ä¼˜ç§€ - æ‰€æœ‰æ ¸å¿ƒæ•°æ®å·²ä¸‹è½½")
    elif not core_missing:
        print("âœ… æ ¸å¿ƒæ•°æ®: å®Œæ•´ - backtestã€strategyæ¨¡å—å¯æ­£å¸¸è¿è¡Œ")
        if sentiment_missing:
            print(f"âš ï¸  æƒ…ç»ªæ•°æ®: ç¼ºå¤± {len(sentiment_missing)} é¡¹ - {', '.join(sentiment_missing)}")
    else:
        print(f"âŒ æ ¸å¿ƒæ•°æ®ç¼ºå¤±: {', '.join(core_missing)}")
        
    # ä¸‹ä¸€æ­¥å»ºè®®
    print("\nğŸš€ ä¸‹ä¸€æ­¥å»ºè®®")
    print("-" * 30)
    if core_missing:
        print("1. ğŸ”§ ä¿®å¤äº¤æ˜“æ—¥å†APIä¸‹è½½é—®é¢˜")
        print("2. ğŸ“… å®Œæˆæ ¸å¿ƒæ•°æ®ä¸‹è½½")
    else:
        print("1. ğŸ“ˆ æ‰©å±•åˆ°å®Œæ•´è‚¡ç¥¨åˆ—è¡¨ (5507åª)")
        print("2. â° æ‰©å±•åˆ°å®Œæ•´æ—¶é—´èŒƒå›´ (2000-2025)")
        print("3. ğŸ§ª æµ‹è¯•coreæ¨¡å—æ•°æ®åŠ è½½åŠŸèƒ½")
        print("4. ğŸ’° å¢åŠ æ›´å¤šè´¢åŠ¡å’ŒæŠ€æœ¯æŒ‡æ ‡æ•°æ®")

if __name__ == "__main__":
    analyze_downloaded_data()