#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•°æ®æ¸…å•åˆ†æå™¨ - ç»Ÿè®¡ç°æœ‰APIæ¥å£æ•°é‡å’Œæ•°æ®åˆ†å¸ƒ
"""

import pandas as pd
from pathlib import Path
import logging
from datetime import datetime
import os

class DataInventoryAnalyzer:
    """æ•°æ®æ¸…å•åˆ†æå™¨"""
    
    def __init__(self):
        self.base_dir = Path("data/final_comprehensive_download")
        self.setup_logging()
        
    def setup_logging(self):
        """è®¾ç½®æ—¥å¿—"""
        log_file = Path("data_inventory_analysis.log")
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_file, encoding='utf-8'),
                logging.StreamHandler()
            ]
        )
    
    def scan_directory_structure(self):
        """æ‰«æç›®å½•ç»“æ„"""
        logging.info("ğŸ” å¼€å§‹æ‰«ææ•°æ®ç›®å½•ç»“æ„...")
        
        structure = {}
        total_apis = 0
        total_files = 0
        total_size = 0
        
        if not self.base_dir.exists():
            logging.error(f"âŒ æ•°æ®ç›®å½•ä¸å­˜åœ¨: {self.base_dir}")
            return structure
        
        # æ‰«æå„ä¸ªåˆ†ç±»ç›®å½•
        for category_dir in self.base_dir.iterdir():
            if category_dir.is_dir():
                category_name = category_dir.name
                structure[category_name] = {
                    'apis': {},
                    'api_count': 0,
                    'file_count': 0,
                    'total_size': 0
                }
                
                logging.info(f"ğŸ“‚ æ‰«æåˆ†ç±»: {category_name}")
                
                # æ‰«æAPIç›®å½•
                for api_dir in category_dir.iterdir():
                    if api_dir.is_dir():
                        api_name = api_dir.name
                        csv_files = list(api_dir.glob("*.csv"))
                        
                        # è®¡ç®—æ–‡ä»¶å¤§å°
                        api_size = sum(f.stat().st_size for f in csv_files)
                        
                        structure[category_name]['apis'][api_name] = {
                            'file_count': len(csv_files),
                            'size_mb': api_size / (1024 * 1024),
                            'files': [f.name for f in csv_files]
                        }
                        
                        structure[category_name]['api_count'] += 1
                        structure[category_name]['file_count'] += len(csv_files)
                        structure[category_name]['total_size'] += api_size
                        
                        total_apis += 1
                        total_files += len(csv_files)
                        total_size += api_size
                        
                        logging.info(f"  âœ… {api_name}: {len(csv_files)} æ–‡ä»¶, {api_size/(1024*1024):.1f}MB")
        
        # æ€»è®¡ä¿¡æ¯
        structure['_summary'] = {
            'total_categories': len([k for k in structure.keys() if not k.startswith('_')]),
            'total_apis': total_apis,
            'total_files': total_files,
            'total_size_mb': total_size / (1024 * 1024),
            'total_size_gb': total_size / (1024 * 1024 * 1024)
        }
        
        return structure
    
    def analyze_data_coverage(self):
        """åˆ†ææ•°æ®è¦†ç›–æƒ…å†µ"""
        logging.info("ğŸ“Š åˆ†ææ•°æ®è¦†ç›–æƒ…å†µ...")
        
        coverage_analysis = {
            'by_category': {},
            'by_time_range': {},
            'by_data_type': {}
        }
        
        # æŒ‰åˆ†ç±»åˆ†æ
        for category_dir in self.base_dir.iterdir():
            if category_dir.is_dir():
                category_name = category_dir.name
                api_list = []
                
                for api_dir in category_dir.iterdir():
                    if api_dir.is_dir():
                        csv_files = list(api_dir.glob("*.csv"))
                        if csv_files:
                            api_list.append(api_dir.name)
                
                coverage_analysis['by_category'][category_name] = {
                    'api_count': len(api_list),
                    'api_list': sorted(api_list)
                }
        
        return coverage_analysis
    
    def generate_inventory_report(self):
        """ç”Ÿæˆæ•°æ®æ¸…å•æŠ¥å‘Š"""
        logging.info("ğŸ“ ç”Ÿæˆæ•°æ®æ¸…å•æŠ¥å‘Š...")
        
        structure = self.scan_directory_structure()
        coverage = self.analyze_data_coverage()
        
        # è¾“å‡ºæ§åˆ¶å°æŠ¥å‘Š
        self.print_console_report(structure, coverage)
        
        # ç”Ÿæˆè¯¦ç»†CSVæŠ¥å‘Š
        self.generate_csv_reports(structure, coverage)
        
        return structure, coverage
    
    def print_console_report(self, structure, coverage):
        """æ‰“å°æ§åˆ¶å°æŠ¥å‘Š"""
        print("\n" + "="*80)
        print("ğŸ¯ **QuantTrade æ•°æ®æ¸…å•ç»Ÿè®¡æŠ¥å‘Š**")
        print("="*80)
        
        # æ€»ä½“ç»Ÿè®¡
        summary = structure.get('_summary', {})
        print(f"\nğŸ“Š **æ€»ä½“ç»Ÿè®¡**:")
        print(f"  ğŸ“ æ•°æ®åˆ†ç±»: {summary.get('total_categories', 0)} ä¸ª")
        print(f"  ğŸ”Œ APIæ¥å£: {summary.get('total_apis', 0)} ä¸ª")
        print(f"  ğŸ“„ æ•°æ®æ–‡ä»¶: {summary.get('total_files', 0)} ä¸ª")
        print(f"  ğŸ’¾ æ•°æ®å¤§å°: {summary.get('total_size_gb', 0):.2f} GB ({summary.get('total_size_mb', 0):.1f} MB)")
        
        # æŒ‰åˆ†ç±»ç»Ÿè®¡
        print(f"\nğŸ“‚ **æŒ‰åˆ†ç±»ç»Ÿè®¡**:")
        for category, info in structure.items():
            if not category.startswith('_'):
                print(f"  ğŸ·ï¸  {category}:")
                print(f"     - APIæ•°é‡: {info['api_count']} ä¸ª")
                print(f"     - æ–‡ä»¶æ•°é‡: {info['file_count']} ä¸ª")
                print(f"     - æ•°æ®å¤§å°: {info['total_size']/(1024*1024):.1f} MB")
        
        # APIè¯¦ç»†ä¿¡æ¯
        print(f"\nğŸ” **APIè¯¦ç»†ä¿¡æ¯**:")
        for category, info in structure.items():
            if not category.startswith('_') and info['apis']:
                print(f"\n  ğŸ“ {category} ({info['api_count']} APIs):")
                for api_name, api_info in info['apis'].items():
                    print(f"    âœ… {api_name}: {api_info['file_count']} æ–‡ä»¶, {api_info['size_mb']:.1f}MB")
    
    def generate_csv_reports(self, structure, coverage):
        """ç”ŸæˆCSVè¯¦ç»†æŠ¥å‘Š"""
        
        # 1. APIæ¸…å•æŠ¥å‘Š
        api_inventory = []
        for category, info in structure.items():
            if not category.startswith('_'):
                for api_name, api_info in info['apis'].items():
                    api_inventory.append({
                        'category': category,
                        'api_name': api_name,
                        'file_count': api_info['file_count'],
                        'size_mb': api_info['size_mb'],
                        'files': '; '.join(api_info['files'][:5]) + ('...' if len(api_info['files']) > 5 else '')
                    })
        
        df_inventory = pd.DataFrame(api_inventory)
        df_inventory.to_csv('data_api_inventory.csv', index=False, encoding='utf-8')
        logging.info("âœ… ç”ŸæˆAPIæ¸…å•æŠ¥å‘Š: data_api_inventory.csv")
        
        # 2. åˆ†ç±»æ±‡æ€»æŠ¥å‘Š
        category_summary = []
        for category, info in structure.items():
            if not category.startswith('_'):
                category_summary.append({
                    'category': category,
                    'api_count': info['api_count'],
                    'file_count': info['file_count'],
                    'size_mb': info['total_size'] / (1024 * 1024),
                    'completeness': f"{info['api_count']}/{info['api_count']}" if info['api_count'] > 0 else "0/0"
                })
        
        df_summary = pd.DataFrame(category_summary)
        df_summary.to_csv('data_category_summary.csv', index=False, encoding='utf-8')
        logging.info("âœ… ç”Ÿæˆåˆ†ç±»æ±‡æ€»æŠ¥å‘Š: data_category_summary.csv")

if __name__ == "__main__":
    analyzer = DataInventoryAnalyzer()
    structure, coverage = analyzer.generate_inventory_report()