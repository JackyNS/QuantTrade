#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
QuantTradeæ¡†æ¶æ•°æ®ç›®å½•ç»“æ„æŸ¥çœ‹å™¨
==============================

å±•ç¤ºå®Œæ•´çš„æ•°æ®ç›®å½•ç»„ç»‡ç»“æ„å’Œæ–‡ä»¶ç»Ÿè®¡
"""

import pandas as pd
from pathlib import Path
from datetime import datetime
import os

def show_data_structure():
    """å±•ç¤ºæ•°æ®ç›®å½•ç»“æ„"""
    
    print("ğŸ“ QuantTradeæ¡†æ¶æ•°æ®ç›®å½•ç»“æ„")
    print("=" * 70)
    print(f"â° æŸ¥çœ‹æ—¶é—´: {datetime.now()}")
    print(f"ğŸ“ æ•°æ®è·¯å¾„: /Users/jackstudio/QuantTrade/data")
    print()
    
    data_path = Path("/Users/jackstudio/QuantTrade/data")
    
    if not data_path.exists():
        print("âŒ æ•°æ®ç›®å½•ä¸å­˜åœ¨")
        return
    
    # è·å–æ‰€æœ‰å­ç›®å½•
    subdirs = sorted([d for d in data_path.iterdir() if d.is_dir()])
    
    # APIæ˜ å°„
    api_mapping = {
        "basic_info": {"api": "EquGet", "desc": "è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯", "icon": "ğŸ¢"},
        "calendar": {"api": "TradeCalGet", "desc": "äº¤æ˜“æ—¥å†", "icon": "ğŸ“…"}, 
        "daily": {"api": "MktEqudGet", "desc": "è‚¡ç¥¨æ—¥è¡Œæƒ…", "icon": "ğŸ“ˆ"},
        "adjustment": {"api": "MktAdjfGet", "desc": "å¤æƒå› å­", "icon": "ğŸ”§"},
        "dividend": {"api": "EquDivGet", "desc": "è‚¡ç¥¨åˆ†çº¢", "icon": "ğŸ’"},
        "financial": {"api": "FdmtBs2018Getç­‰", "desc": "è´¢åŠ¡æ•°æ®", "icon": "ğŸ’°"},
        "capital_flow": {"api": "MktEquFlowGet", "desc": "èµ„é‡‘æµå‘", "icon": "ğŸ’¸"},
        "limit_info": {"api": "MktLimitGet", "desc": "æ¶¨è·Œåœä¿¡æ¯", "icon": "âš ï¸"},
        "rank_list": {"api": "MktRankListStocksGet", "desc": "é¾™è™æ¦œæ•°æ®", "icon": "ğŸ”¥"}
    }
    
    total_files = 0
    total_size_mb = 0
    total_records = 0
    
    print("ğŸ“Š æ•°æ®ç›®å½•è¯¦ç»†ç»“æ„:")
    print("=" * 70)
    
    for subdir in subdirs:
        dir_name = subdir.name
        mapping = api_mapping.get(dir_name, {"api": "Unknown", "desc": "æœªçŸ¥æ•°æ®", "icon": "ğŸ“‚"})
        
        print(f"\n{mapping['icon']} {dir_name}/ - {mapping['desc']}")
        print(f"   ğŸ“¡ API: {mapping['api']}")
        
        # è·å–ç›®å½•ä¸­çš„æ‰€æœ‰CSVæ–‡ä»¶
        csv_files = list(subdir.glob("*.csv"))
        
        if csv_files:
            dir_size = 0
            dir_records = 0
            
            print(f"   ğŸ“„ æ–‡ä»¶åˆ—è¡¨:")
            
            # æŒ‰æ–‡ä»¶åæ’åºï¼Œç°ä»£æ•°æ®åœ¨å‰ï¼Œå†å²æ•°æ®åœ¨å
            modern_files = [f for f in csv_files if "2000_2009" not in f.name]
            historical_files = [f for f in csv_files if "2000_2009" in f.name]
            
            # æ˜¾ç¤ºç°ä»£æ•°æ®æ–‡ä»¶
            if modern_files:
                print(f"      ğŸ“ˆ 2010-2025å¹´æ•°æ®:")
                for file in sorted(modern_files):
                    file_size = file.stat().st_size / (1024*1024)
                    dir_size += file_size
                    
                    try:
                        df = pd.read_csv(file)
                        records = len(df)
                        dir_records += records
                        
                        # æ˜¾ç¤ºæ—¶é—´èŒƒå›´
                        time_info = ""
                        if 'tradeDate' in df.columns:
                            time_range = f"{df['tradeDate'].min()} ~ {df['tradeDate'].max()}"
                            time_info = f" ({time_range})"
                        elif 'endDate' in df.columns:
                            time_range = f"{df['endDate'].min()} ~ {df['endDate'].max()}"
                            time_info = f" ({time_range})"
                        elif 'calendarDate' in df.columns:
                            time_range = f"{df['calendarDate'].min()} ~ {df['calendarDate'].max()}"
                            time_info = f" ({time_range})"
                        
                        print(f"         ğŸ“„ {file.name}: {records:,}æ¡ | {file_size:.1f}MB{time_info}")
                        
                    except Exception as e:
                        print(f"         âŒ {file.name}: {file_size:.1f}MB (è¯»å–å¤±è´¥)")
                        dir_size += file_size
            
            # æ˜¾ç¤ºå†å²æ•°æ®æ–‡ä»¶
            if historical_files:
                print(f"      ğŸ“œ 2000-2009å¹´å†å²æ•°æ®:")
                for file in sorted(historical_files):
                    file_size = file.stat().st_size / (1024*1024)
                    dir_size += file_size
                    
                    try:
                        df = pd.read_csv(file)
                        records = len(df)
                        dir_records += records
                        
                        # æ˜¾ç¤ºæ—¶é—´èŒƒå›´
                        time_info = ""
                        if 'tradeDate' in df.columns:
                            time_range = f"{df['tradeDate'].min()} ~ {df['tradeDate'].max()}"
                            time_info = f" ({time_range})"
                        elif 'endDate' in df.columns:
                            time_range = f"{df['endDate'].min()} ~ {df['endDate'].max()}"
                            time_info = f" ({time_range})"
                            
                        print(f"         ğŸ“„ {file.name}: {records:,}æ¡ | {file_size:.1f}MB{time_info}")
                        
                    except Exception as e:
                        print(f"         âŒ {file.name}: {file_size:.1f}MB (è¯»å–å¤±è´¥)")
                        dir_size += file_size
            
            # ç›®å½•ç»Ÿè®¡
            coverage_status = "ğŸŠ 25å¹´" if modern_files and historical_files else "â³ éƒ¨åˆ†"
            print(f"   ğŸ“Š ç›®å½•ç»Ÿè®¡: {len(csv_files)}æ–‡ä»¶ | {dir_records:,}æ¡è®°å½• | {dir_size:.1f}MB | {coverage_status}")
            
            total_files += len(csv_files)
            total_size_mb += dir_size  
            total_records += dir_records
            
        else:
            print(f"   ğŸ“‚ ç›®å½•ä¸ºç©º")
    
    # æ˜¾ç¤ºæ€»ä½“ç»Ÿè®¡
    print(f"\nğŸ“Š æ•°æ®æ€»ä½“ç»Ÿè®¡:")
    print("=" * 50)
    print(f"ğŸ“ æ•°æ®ç›®å½•: {len(subdirs)} ä¸ª")
    print(f"ğŸ“„ CSVæ–‡ä»¶: {total_files} ä¸ª")
    print(f"ğŸ“‹ æ€»è®°å½•æ•°: {total_records:,} æ¡")
    print(f"ğŸ’¾ æ€»å¤§å°: {total_size_mb:.1f}MB ({total_size_mb/1024:.2f}GB)")
    
    # æ˜¾ç¤ºç›®å½•æ ‘ç»“æ„
    print(f"\nğŸŒ³ ç›®å½•æ ‘ç»“æ„:")
    print("=" * 50)
    print("data/")
    
    for subdir in subdirs:
        mapping = api_mapping.get(subdir.name, {"icon": "ğŸ“‚"})
        csv_count = len(list(subdir.glob("*.csv")))
        
        if subdir == subdirs[-1]:
            print(f"â””â”€â”€ {mapping['icon']} {subdir.name}/ ({csv_count} files)")
        else:
            print(f"â”œâ”€â”€ {mapping['icon']} {subdir.name}/ ({csv_count} files)")
            
        # æ˜¾ç¤ºæ–‡ä»¶
        csv_files = sorted(list(subdir.glob("*.csv")))
        for i, file in enumerate(csv_files):
            if subdir == subdirs[-1]:
                prefix = "    "
            else:
                prefix = "â”‚   "
                
            if i == len(csv_files) - 1:
                print(f"{prefix}â””â”€â”€ ğŸ“„ {file.name}")
            else:
                print(f"{prefix}â”œâ”€â”€ ğŸ“„ {file.name}")
    
    # æ•°æ®è´¨é‡è¯„ä¼°
    print(f"\nğŸ¯ æ•°æ®è´¨é‡è¯„ä¼°:")
    print("=" * 50)
    
    if total_size_mb > 1000:
        quality = "ğŸš€ å¤§å‹æ•°æ®é›†"
        capability = "æ”¯æŒé«˜é¢‘ç­–ç•¥ã€é•¿å‘¨æœŸå›æµ‹ã€å¤šå› å­æ¨¡å‹"
    elif total_size_mb > 100:
        quality = "ğŸ“ˆ ä¸­å‹æ•°æ®é›†" 
        capability = "æ”¯æŒä¸­é¢‘ç­–ç•¥ã€æŠ€æœ¯åˆ†æã€åŸºç¡€å›æµ‹"
    else:
        quality = "ğŸ“Š å°å‹æ•°æ®é›†"
        capability = "æ”¯æŒåŸºç¡€ç­–ç•¥ã€çŸ­æœŸåˆ†æ"
    
    print(f"{quality} ({total_size_mb/1024:.2f}GB)")
    print(f"ğŸ’¡ {capability}")
    
    # æ¡†æ¶å°±ç»ªçŠ¶æ€
    core_dirs = ['basic_info', 'calendar', 'daily']
    tech_dirs = ['adjustment', 'dividend', 'financial'] 
    emotion_dirs = ['capital_flow', 'limit_info', 'rank_list']
    
    core_ready = sum(1 for d in core_dirs if (data_path / d).exists() and list((data_path / d).glob("*.csv")))
    tech_ready = sum(1 for d in tech_dirs if (data_path / d).exists() and list((data_path / d).glob("*.csv")))
    emotion_ready = sum(1 for d in emotion_dirs if (data_path / d).exists() and list((data_path / d).glob("*.csv")))
    
    print(f"\nğŸš€ æ¡†æ¶åŠŸèƒ½å°±ç»ªçŠ¶æ€:")
    print(f"ğŸ”¥ æ ¸å¿ƒäº¤æ˜“: {core_ready}/{len(core_dirs)} ({'âœ…' if core_ready >= 2 else 'â³'})")
    print(f"ğŸ’° æŠ€æœ¯åˆ†æ: {tech_ready}/{len(tech_dirs)} ({'âœ…' if tech_ready >= 2 else 'â³'})")
    print(f"ğŸ§  æƒ…ç»ªåˆ†æ: {emotion_ready}/{len(emotion_dirs)} ({'âœ…' if emotion_ready >= 1 else 'â³'})")

if __name__ == "__main__":
    show_data_structure()