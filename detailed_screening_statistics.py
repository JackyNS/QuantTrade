#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è¯¦ç»†ç­›æŸ¥ç»Ÿè®¡å·¥å…·
å±•ç¤ºå…·ä½“çš„æ•°æ®ç­›æŸ¥ç»Ÿè®¡æƒ…å†µï¼Œä¸åšç»“è®º
"""

import pandas as pd
import numpy as np
from pathlib import Path
from datetime import datetime
import warnings
from collections import defaultdict, Counter
warnings.filterwarnings('ignore')

class DetailedScreeningStatistics:
    """è¯¦ç»†ç­›æŸ¥ç»Ÿè®¡"""
    
    def __init__(self):
        """åˆå§‹åŒ–"""
        self.base_path = Path("/Users/jackstudio/QuantTrade/data")
        self.screening_data = {}
    
    def screen_individual_stock_files(self, sample_size=500):
        """ç­›æŸ¥ä¸ªè‚¡æ–‡ä»¶çš„å…·ä½“æƒ…å†µ"""
        print("ğŸ” ä¸ªè‚¡æ–‡ä»¶è¯¦ç»†ç­›æŸ¥")
        print(f"ğŸ“Š ç­›æŸ¥æ ·æœ¬æ•°: {sample_size}")
        print("=" * 120)
        
        csv_daily_path = self.base_path / "csv_complete/daily"
        if not csv_daily_path.exists():
            print("âŒ ç›®å½•ä¸å­˜åœ¨")
            return
        
        stock_files = list(csv_daily_path.rglob("*.csv"))
        print(f"ğŸ“ˆ æ€»æ–‡ä»¶æ•°: {len(stock_files):,}")
        
        # é€‰æ‹©ç­›æŸ¥æ ·æœ¬
        step = max(1, len(stock_files) // sample_size)
        sample_files = stock_files[::step][:sample_size]
        
        screening_results = []
        
        print("\\nğŸ“‹ é€ä¸ªç­›æŸ¥ç»“æœ:")
        print("-" * 120)
        print(f"{'åºå·':<4} {'è‚¡ç¥¨ä»£ç ':<12} {'å¼€å§‹æ—¥æœŸ':<12} {'ç»“æŸæ—¥æœŸ':<12} {'è®°å½•æ•°':<8} {'å¹´æ•°':<6} {'çŠ¶æ€'}")
        print("-" * 120)
        
        for i, file_path in enumerate(sample_files, 1):
            try:
                stock_id = file_path.stem.replace('_', '.')
                df = pd.read_csv(file_path)
                
                if len(df) == 0 or 'tradeDate' not in df.columns:
                    result = {
                        'index': i,
                        'stock_id': stock_id,
                        'start_date': 'N/A',
                        'end_date': 'N/A', 
                        'records': 0,
                        'years': 0,
                        'status': 'æ— æœ‰æ•ˆæ•°æ®'
                    }
                else:
                    df['tradeDate'] = pd.to_datetime(df['tradeDate'])
                    start_date = df['tradeDate'].min()
                    end_date = df['tradeDate'].max()
                    records = len(df)
                    years = round((end_date - start_date).days / 365.25, 1)
                    
                    # ç®€å•çŠ¶æ€åˆ¤æ–­
                    if start_date.year <= 2001 and end_date.year >= 2024:
                        status = 'é•¿æœŸæ•°æ®'
                    elif start_date.year <= 2010 and end_date.year >= 2020:
                        status = 'ä¸­æœŸæ•°æ®'
                    elif years >= 3:
                        status = 'çŸ­æœŸæ•°æ®'
                    else:
                        status = 'æ•°æ®è¾ƒå°‘'
                    
                    result = {
                        'index': i,
                        'stock_id': stock_id,
                        'start_date': start_date.strftime('%Y-%m-%d'),
                        'end_date': end_date.strftime('%Y-%m-%d'),
                        'records': records,
                        'years': years,
                        'status': status
                    }
                
                screening_results.append(result)
                
                # æ˜¾ç¤ºç­›æŸ¥ç»“æœ
                print(f"{result['index']:<4} {result['stock_id']:<12} {result['start_date']:<12} {result['end_date']:<12} {result['records']:<8} {result['years']:<6} {result['status']}")
                
            except Exception as e:
                result = {
                    'index': i,
                    'stock_id': file_path.stem,
                    'start_date': 'ERROR',
                    'end_date': 'ERROR',
                    'records': 0,
                    'years': 0,
                    'status': 'è¯»å–å¤±è´¥'
                }
                screening_results.append(result)
                print(f"{result['index']:<4} {result['stock_id']:<12} {'ERROR':<12} {'ERROR':<12} {0:<8} {0:<6} è¯»å–å¤±è´¥")
        
        self.screening_data['individual_files'] = screening_results
        return screening_results
    
    def analyze_screening_distribution(self, screening_results):
        """åˆ†æç­›æŸ¥ç»“æœåˆ†å¸ƒ"""
        print("\\nğŸ“Š ç­›æŸ¥ç»“æœåˆ†å¸ƒç»Ÿè®¡")
        print("=" * 80)
        
        # æŒ‰çŠ¶æ€åˆ†ç±»ç»Ÿè®¡
        status_counts = Counter([r['status'] for r in screening_results])
        print("\\nğŸ“‹ æŒ‰çŠ¶æ€åˆ†ç±»:")
        for status, count in status_counts.items():
            percentage = count / len(screening_results) * 100
            print(f"   {status}: {count} åª ({percentage:.1f}%)")
        
        # æŒ‰å¼€å§‹å¹´ä»½åˆ†ç±»ç»Ÿè®¡  
        start_years = []
        end_years = []
        valid_results = [r for r in screening_results if r['start_date'] != 'N/A' and r['start_date'] != 'ERROR']
        
        for result in valid_results:
            try:
                start_years.append(int(result['start_date'][:4]))
                end_years.append(int(result['end_date'][:4]))
            except:
                continue
        
        if start_years:
            start_year_counts = Counter(start_years)
            end_year_counts = Counter(end_years)
            
            print("\\nğŸ“… æŒ‰å¼€å§‹å¹´ä»½åˆ†å¸ƒ:")
            for year in sorted(start_year_counts.keys()):
                count = start_year_counts[year]
                percentage = count / len(valid_results) * 100
                print(f"   {year}: {count} åª ({percentage:.1f}%)")
            
            print("\\nğŸ“… æŒ‰ç»“æŸå¹´ä»½åˆ†å¸ƒ:")
            for year in sorted(end_year_counts.keys()):
                count = end_year_counts[year]
                percentage = count / len(valid_results) * 100
                print(f"   {year}: {count} åª ({percentage:.1f}%)")
        
        # æŒ‰æ•°æ®å¹´æ•°åˆ†ç±»ç»Ÿè®¡
        years_ranges = {
            '0-1å¹´': 0,
            '1-3å¹´': 0, 
            '3-5å¹´': 0,
            '5-10å¹´': 0,
            '10-15å¹´': 0,
            '15-20å¹´': 0,
            '20å¹´ä»¥ä¸Š': 0
        }
        
        for result in valid_results:
            years = result['years']
            if years <= 1:
                years_ranges['0-1å¹´'] += 1
            elif years <= 3:
                years_ranges['1-3å¹´'] += 1
            elif years <= 5:
                years_ranges['3-5å¹´'] += 1
            elif years <= 10:
                years_ranges['5-10å¹´'] += 1
            elif years <= 15:
                years_ranges['10-15å¹´'] += 1
            elif years <= 20:
                years_ranges['15-20å¹´'] += 1
            else:
                years_ranges['20å¹´ä»¥ä¸Š'] += 1
        
        print("\\nğŸ“Š æŒ‰æ•°æ®å¹´æ•°åˆ†å¸ƒ:")
        for range_name, count in years_ranges.items():
            percentage = count / len(valid_results) * 100 if valid_results else 0
            print(f"   {range_name}: {count} åª ({percentage:.1f}%)")
        
        # è®°å½•æ•°åˆ†å¸ƒç»Ÿè®¡
        record_ranges = {
            '0-100': 0,
            '100-500': 0,
            '500-1000': 0,
            '1000-3000': 0,
            '3000-5000': 0,
            '5000ä»¥ä¸Š': 0
        }
        
        for result in valid_results:
            records = result['records']
            if records <= 100:
                record_ranges['0-100'] += 1
            elif records <= 500:
                record_ranges['100-500'] += 1
            elif records <= 1000:
                record_ranges['500-1000'] += 1
            elif records <= 3000:
                record_ranges['1000-3000'] += 1
            elif records <= 5000:
                record_ranges['3000-5000'] += 1
            else:
                record_ranges['5000ä»¥ä¸Š'] += 1
        
        print("\\nğŸ“ˆ æŒ‰è®°å½•æ•°åˆ†å¸ƒ:")
        for range_name, count in record_ranges.items():
            percentage = count / len(valid_results) * 100 if valid_results else 0
            print(f"   {range_name}æ¡: {count} åª ({percentage:.1f}%)")
    
    def screen_batch_files_detail(self):
        """ç­›æŸ¥æ‰¹æ¬¡æ–‡ä»¶çš„è¯¦ç»†æƒ…å†µ"""
        print("\\n\\nğŸ“„ æ‰¹æ¬¡æ–‡ä»¶è¯¦ç»†ç­›æŸ¥")
        print("=" * 100)
        
        daily_path = self.base_path / "priority_download/market_data/daily"
        if not daily_path.exists():
            print("âŒ æ‰¹æ¬¡æ–‡ä»¶ç›®å½•ä¸å­˜åœ¨")
            return
        
        batch_files = list(daily_path.glob("*.csv"))
        print(f"ğŸ“Š æ‰¹æ¬¡æ–‡ä»¶æ€»æ•°: {len(batch_files)}")
        
        # æŒ‰å¹´ä»½è¯¦ç»†ç»Ÿè®¡
        year_details = defaultdict(list)
        
        print("\\nğŸ“‹ æ‰¹æ¬¡æ–‡ä»¶è¯¦ç»†ä¿¡æ¯:")
        print("-" * 100)
        print(f"{'æ–‡ä»¶å':<20} {'å¹´ä»½':<6} {'è‚¡ç¥¨æ•°':<8} {'è®°å½•æ•°':<10} {'å¼€å§‹æ—¥æœŸ':<12} {'ç»“æŸæ—¥æœŸ':<12}")
        print("-" * 100)
        
        # æŠ½æ ·æ£€æŸ¥æ¯å¹´çš„ä»£è¡¨æ–‡ä»¶
        year_files = defaultdict(list)
        for file_path in batch_files:
            try:
                year = file_path.stem.split('_')[0]
                year_files[year].append(file_path)
            except:
                continue
        
        for year in sorted(year_files.keys()):
            files = year_files[year]
            # æ£€æŸ¥è¯¥å¹´ä»½çš„å‰3ä¸ªæ–‡ä»¶
            for file_path in files[:3]:
                try:
                    df = pd.read_csv(file_path)
                    
                    if 'secID' in df.columns and 'tradeDate' in df.columns:
                        stock_count = len(df['secID'].unique())
                        record_count = len(df)
                        
                        df['tradeDate'] = pd.to_datetime(df['tradeDate'])
                        start_date = df['tradeDate'].min().strftime('%Y-%m-%d')
                        end_date = df['tradeDate'].max().strftime('%Y-%m-%d')
                        
                        print(f"{file_path.name:<20} {year:<6} {stock_count:<8} {record_count:<10} {start_date:<12} {end_date:<12}")
                        
                        year_details[year].append({
                            'file': file_path.name,
                            'stocks': stock_count,
                            'records': record_count,
                            'start': start_date,
                            'end': end_date
                        })
                    else:
                        print(f"{file_path.name:<20} {year:<6} {'ERROR':<8} {'ERROR':<10} {'ERROR':<12} {'ERROR':<12}")
                        
                except Exception as e:
                    print(f"{file_path.name:<20} {year:<6} {'ERROR':<8} {'ERROR':<10} {'ERROR':<12} {'ERROR':<12}")
        
        self.screening_data['batch_files'] = dict(year_details)
    
    def generate_screening_report(self, sample_size=500):
        """ç”Ÿæˆç­›æŸ¥æŠ¥å‘Š"""
        print("ğŸ” Aè‚¡æ•°æ®è¯¦ç»†ç­›æŸ¥ç»Ÿè®¡")
        print("ğŸ“… ç­›æŸ¥æ—¶é—´:", datetime.now().strftime('%Y-%m-%d %H:%M:%S'))
        print("=" * 120)
        
        # ç­›æŸ¥ä¸ªè‚¡æ–‡ä»¶
        screening_results = self.screen_individual_stock_files(sample_size)
        
        # åˆ†æç­›æŸ¥åˆ†å¸ƒ
        self.analyze_screening_distribution(screening_results)
        
        # ç­›æŸ¥æ‰¹æ¬¡æ–‡ä»¶
        self.screen_batch_files_detail()
        
        # è¾“å‡ºåŸå§‹æ•°æ®æ‘˜è¦
        print("\\n\\nğŸ“‹ ç­›æŸ¥æ•°æ®æ‘˜è¦")
        print("=" * 60)
        print(f"ä¸ªè‚¡æ–‡ä»¶ç­›æŸ¥æ ·æœ¬: {len(screening_results)}")
        print(f"æ‰¹æ¬¡æ–‡ä»¶å¹´ä»½è¦†ç›–: {len(self.screening_data.get('batch_files', {}))}")
        print(f"æ€»æ•°æ®æ–‡ä»¶æ•°: 50,658 (ä¸ªè‚¡) + 713 (æ‰¹æ¬¡)")

def main():
    """ä¸»å‡½æ•°"""
    screener = DetailedScreeningStatistics()
    screener.generate_screening_report(sample_size=500)

if __name__ == "__main__":
    main()