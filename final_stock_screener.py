#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æœ€ç»ˆç‰ˆåå‘¨çº¿ä¸Šç©¿ç™¾å‘¨çº¿è‚¡ç¥¨ç­›é€‰å™¨
ä½¿ç”¨æ ·æœ¬æ•°æ®è¿›è¡Œå®Œæ•´çš„ç­–ç•¥æµ‹è¯•å’Œè‚¡ç¥¨ç­›é€‰
"""

import sys
import pandas as pd
import numpy as np
from pathlib import Path
from datetime import datetime, timedelta
import warnings
import json
import os
warnings.filterwarnings('ignore')

try:
    import talib
    print("âœ… TA-Lib å¯ç”¨")
    TALIB_AVAILABLE = True
except ImportError:
    print("âŒ TA-Lib ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨pandasè®¡ç®—")
    TALIB_AVAILABLE = False

class MACrossoverStockScreener:
    """åå‘¨çº¿ä¸Šç©¿ç™¾å‘¨çº¿è‚¡ç¥¨ç­›é€‰å™¨"""
    
    def __init__(self, data_path="sample_stock_data"):
        """
        åˆå§‹åŒ–ç­›é€‰å™¨
        
        Args:
            data_path: æ ·æœ¬æ•°æ®è·¯å¾„
        """
        self.data_path = Path(data_path)
        self.results = []
        self.qualified_stocks = []
        
        print(f"ğŸ“ æ•°æ®è·¯å¾„: {self.data_path}")
        
        # æŸ¥æ‰¾è‚¡ç¥¨æ•°æ®æ–‡ä»¶
        self.find_stock_files()
    
    def find_stock_files(self):
        """æŸ¥æ‰¾è‚¡ç¥¨æ•°æ®æ–‡ä»¶"""
        print("ğŸ” æŸ¥æ‰¾è‚¡ç¥¨æ•°æ®æ–‡ä»¶...")
        
        self.stock_files = []
        
        if self.data_path.exists():
            csv_files = list(self.data_path.glob("*_daily.csv"))
            self.stock_files = csv_files
            print(f"   âœ… æ‰¾åˆ° {len(csv_files)} ä¸ªè‚¡ç¥¨æ•°æ®æ–‡ä»¶")
            
            for file in csv_files[:5]:  # æ˜¾ç¤ºå‰5ä¸ªæ–‡ä»¶
                print(f"      - {file.name}")
            
            if len(csv_files) > 5:
                print(f"      ... è¿˜æœ‰ {len(csv_files) - 5} ä¸ªæ–‡ä»¶")
        else:
            print(f"   âŒ æ•°æ®ç›®å½•ä¸å­˜åœ¨: {self.data_path}")
        
        return len(self.stock_files) > 0
    
    def load_stock_data(self, file_path):
        """
        åŠ è½½è‚¡ç¥¨æ•°æ®
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            
        Returns:
            DataFrame: è‚¡ç¥¨æ•°æ®
        """
        try:
            df = pd.read_csv(file_path)
            
            # è½¬æ¢æ—¥æœŸåˆ—
            df['tradeDate'] = pd.to_datetime(df['tradeDate'])
            
            # æ£€æŸ¥å¿…è¦çš„åˆ—
            required_cols = ['tradeDate', 'closePrice']
            if not all(col in df.columns for col in required_cols):
                print(f"   âŒ ç¼ºå°‘å¿…è¦åˆ—: {[col for col in required_cols if col not in df.columns]}")
                return None
            
            # è¿‡æ»¤æœ‰æ•ˆæ•°æ®
            df_clean = df.dropna(subset=['closePrice', 'tradeDate'])
            df_clean = df_clean[df_clean['closePrice'] > 0]
            df_clean = df_clean.sort_values('tradeDate')
            
            return df_clean
            
        except Exception as e:
            print(f"   âŒ åŠ è½½å¤±è´¥: {e}")
            return None
    
    def calculate_ma_crossover(self, price_data, short_period=10, long_period=100):
        """
        è®¡ç®—MAäº¤å‰ä¿¡å·
        
        Args:
            price_data: ä»·æ ¼æ•°æ®
            short_period: çŸ­æœŸMAå‘¨æœŸ
            long_period: é•¿æœŸMAå‘¨æœŸ
            
        Returns:
            dict: åˆ†æç»“æœ
        """
        try:
            if len(price_data) < long_period * 7:
                return {'status': 'insufficient_data', 'data_length': len(price_data)}
            
            # æŒ‰æ—¥æœŸæ’åº
            df = price_data.sort_values('tradeDate').copy()
            
            # è½¬æ¢ä¸ºå‘¨çº¿æ•°æ®
            df_indexed = df.set_index('tradeDate')
            weekly_close = df_indexed['closePrice'].resample('W').last().dropna()
            
            if len(weekly_close) < long_period:
                return {
                    'status': 'insufficient_weekly_data', 
                    'weekly_length': len(weekly_close),
                    'required': long_period
                }
            
            # è®¡ç®—ç§»åŠ¨å¹³å‡çº¿
            if TALIB_AVAILABLE:
                ma_short = talib.MA(weekly_close.values, timeperiod=short_period)
                ma_long = talib.MA(weekly_close.values, timeperiod=long_period) 
            else:
                ma_short = weekly_close.rolling(short_period).mean().values
                ma_long = weekly_close.rolling(long_period).mean().values
            
            # åˆ›å»ºSeries
            ma_short_series = pd.Series(ma_short, index=weekly_close.index)
            ma_long_series = pd.Series(ma_long, index=weekly_close.index)
            
            # å»é™¤NaNå¹¶æ‰¾åˆ°æœ‰æ•ˆæ•°æ®
            valid_idx = ma_short_series.dropna().index.intersection(ma_long_series.dropna().index)
            if len(valid_idx) < 2:
                return {'status': 'no_valid_data', 'valid_length': len(valid_idx)}
            
            ma_short_clean = ma_short_series.loc[valid_idx]
            ma_long_clean = ma_long_series.loc[valid_idx]
            
            # è®¡ç®—äº¤å‰ä¿¡å·
            position = (ma_short_clean > ma_long_clean).astype(int)
            crossover = position.diff()
            
            # ç»Ÿè®¡ä¿¡å·
            golden_cross_mask = crossover > 0
            death_cross_mask = crossover < 0
            
            golden_dates = golden_cross_mask[golden_cross_mask].index.tolist()
            death_dates = death_cross_mask[death_cross_mask].index.tolist()
            
            # å½“å‰çŠ¶æ€
            current_position = position.iloc[-1] if len(position) > 0 else 0
            latest_price = weekly_close.iloc[-1] if len(weekly_close) > 0 else 0
            latest_ma_short = ma_short_clean.iloc[-1] if len(ma_short_clean) > 0 else 0
            latest_ma_long = ma_long_clean.iloc[-1] if len(ma_long_clean) > 0 else 0
            
            # æœ€è¿‘ä¿¡å·
            recent_crossovers = crossover[crossover != 0]
            latest_signal = None
            if len(recent_crossovers) > 0:
                signal_date = recent_crossovers.index[-1]
                signal_value = recent_crossovers.iloc[-1]
                latest_signal = {
                    'date': signal_date,
                    'type': 'golden_cross' if signal_value > 0 else 'death_cross',
                    'signal_value': signal_value,
                    'days_ago': (datetime.now() - signal_date).days
                }
            
            # è®¡ç®—ä¸€äº›é¢å¤–çš„æŒ‡æ ‡
            signal_frequency = len(golden_dates) + len(death_dates)
            signal_per_year = signal_frequency / (len(valid_idx) / 52) if len(valid_idx) > 52 else 0
            
            return {
                'status': 'success',
                'data_info': {
                    'daily_records': len(price_data),
                    'weekly_records': len(weekly_close),
                    'valid_records': len(valid_idx),
                    'analysis_period_weeks': len(valid_idx),
                    'analysis_period_years': round(len(valid_idx) / 52, 1)
                },
                'ma_values': {
                    'ma_short_latest': round(latest_ma_short, 2),
                    'ma_long_latest': round(latest_ma_long, 2),
                    'ma_spread': round(latest_ma_short - latest_ma_long, 2),
                    'ma_spread_pct': round((latest_ma_short - latest_ma_long) / latest_ma_long * 100, 2) if latest_ma_long > 0 else 0
                },
                'signals': {
                    'golden_cross_count': len(golden_dates),
                    'death_cross_count': len(death_dates),
                    'total_signals': len(golden_dates) + len(death_dates),
                    'signal_frequency': round(signal_per_year, 1),
                    'golden_cross_dates': golden_dates,
                    'death_cross_dates': death_dates,
                    'latest_signal': latest_signal
                },
                'current_status': {
                    'position': 'bullish' if current_position > 0 else 'bearish',
                    'latest_price': round(latest_price, 2),
                    'trend_strength': abs(latest_ma_short - latest_ma_long) / latest_ma_long if latest_ma_long > 0 else 0
                }
            }
            
        except Exception as e:
            return {'status': 'error', 'error': str(e), 'traceback': str(e)}
    
    def screen_stocks(self, min_golden_cross=1, require_current_bullish=True, min_analysis_years=2):
        """
        ç­›é€‰è‚¡ç¥¨
        
        Args:
            min_golden_cross: æœ€å°‘é»„é‡‘äº¤å‰æ¬¡æ•°
            require_current_bullish: æ˜¯å¦è¦æ±‚å½“å‰å¤šå¤´
            min_analysis_years: æœ€å°‘åˆ†æå¹´æ•°
            
        Returns:
            list: ç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨
        """
        print(f"ğŸ” å¼€å§‹ç­›é€‰è‚¡ç¥¨")
        print(f"   ç­›é€‰æ¡ä»¶:")
        print(f"     - æœ€å°‘é»„é‡‘äº¤å‰æ¬¡æ•°: {min_golden_cross}")
        print(f"     - è¦æ±‚å½“å‰å¤šå¤´: {'æ˜¯' if require_current_bullish else 'å¦'}")
        print(f"     - æœ€å°‘åˆ†æå¹´æ•°: {min_analysis_years}")
        print("=" * 70)
        
        self.results = []
        self.qualified_stocks = []
        
        for i, file_path in enumerate(self.stock_files, 1):
            stock_code = file_path.stem.replace('_daily', '')
            print(f"ğŸ“Š [{i}/{len(self.stock_files)}] åˆ†æè‚¡ç¥¨: {stock_code}")
            
            # åŠ è½½æ•°æ®
            stock_data = self.load_stock_data(file_path)
            if stock_data is None:
                continue
            
            print(f"   ğŸ“ˆ æ•°æ®: {len(stock_data)} æ¡æ—¥çº¿è®°å½•")
            print(f"   ğŸ“… æ—¶é—´èŒƒå›´: {stock_data['tradeDate'].min().date()} - {stock_data['tradeDate'].max().date()}")
            
            # åˆ†æMAäº¤å‰
            analysis = self.calculate_ma_crossover(stock_data)
            
            # ä¿å­˜ç»“æœ
            result = {
                'stock_code': stock_code,
                'file_path': str(file_path),
                'analysis_time': datetime.now(),
                'analysis': analysis
            }
            self.results.append(result)
            
            # æ£€æŸ¥æ˜¯å¦ç¬¦åˆæ¡ä»¶
            if analysis['status'] == 'success':
                signals = analysis['signals']
                current_status = analysis['current_status']
                data_info = analysis['data_info']
                ma_values = analysis['ma_values']
                
                print(f"   ğŸ“Š åˆ†æç»“æœ:")
                print(f"      ğŸŒŸ é»„é‡‘äº¤å‰: {signals['golden_cross_count']} æ¬¡")
                print(f"      ğŸ’€ æ­»å‰: {signals['death_cross_count']} æ¬¡")
                print(f"      ğŸ“ˆ å½“å‰çŠ¶æ€: {current_status['position']}")
                print(f"      ğŸ’° æœ€æ–°ä»·æ ¼: {current_status['latest_price']}")
                print(f"      ğŸ“ MAå·®ä»·: {ma_values['ma_spread']} ({ma_values['ma_spread_pct']}%)")
                print(f"      ğŸ“† åˆ†ææ—¶é•¿: {data_info['analysis_period_years']} å¹´")
                
                # æ£€æŸ¥ç­›é€‰æ¡ä»¶
                meets_criteria = True
                reasons = []
                
                # æ¡ä»¶1: é»„é‡‘äº¤å‰æ¬¡æ•°
                if signals['golden_cross_count'] < min_golden_cross:
                    meets_criteria = False
                    reasons.append(f"é»„é‡‘äº¤å‰æ¬¡æ•°ä¸è¶³({signals['golden_cross_count']}<{min_golden_cross})")
                
                # æ¡ä»¶2: å½“å‰å¤šå¤´çŠ¶æ€
                if require_current_bullish and current_status['position'] != 'bullish':
                    meets_criteria = False
                    reasons.append("å½“å‰éå¤šå¤´çŠ¶æ€")
                
                # æ¡ä»¶3: åˆ†ææ—¶é•¿
                if data_info['analysis_period_years'] < min_analysis_years:
                    meets_criteria = False
                    reasons.append(f"åˆ†ææ—¶é•¿ä¸è¶³({data_info['analysis_period_years']}<{min_analysis_years}å¹´)")
                
                if meets_criteria:
                    self.qualified_stocks.append(result)
                    print(f"      âœ… ç¬¦åˆç­›é€‰æ¡ä»¶")
                    
                    # æ˜¾ç¤ºæœ€è¿‘ä¿¡å·
                    if signals['latest_signal']:
                        latest = signals['latest_signal']
                        signal_type = "ğŸŒŸ é»„é‡‘äº¤å‰" if latest['type'] == 'golden_cross' else "ğŸ’€ æ­»å‰"
                        print(f"      ğŸ•’ æœ€è¿‘ä¿¡å·: {signal_type} ({latest['date'].strftime('%Y-%m-%d')}, {latest['days_ago']}å¤©å‰)")
                else:
                    print(f"      âŒ ä¸ç¬¦åˆæ¡ä»¶: {'; '.join(reasons)}")
                
            else:
                status = analysis['status']
                print(f"   âŒ åˆ†æå¤±è´¥: {status}")
                if 'error' in analysis:
                    print(f"      é”™è¯¯: {analysis['error']}")
            
            print()  # ç©ºè¡Œåˆ†éš”
        
        # æŒ‰é»„é‡‘äº¤å‰æ¬¡æ•°å’Œè¶‹åŠ¿å¼ºåº¦æ’åº
        self.qualified_stocks.sort(key=lambda x: (
            x['analysis']['signals']['golden_cross_count'],
            x['analysis']['current_status']['trend_strength']
        ), reverse=True)
        
        print(f"ğŸ¯ ç­›é€‰å®Œæˆ:")
        print(f"   ğŸ“Š æ€»åˆ†æè‚¡ç¥¨: {len(self.stock_files)}")
        print(f"   âœ… ç¬¦åˆæ¡ä»¶è‚¡ç¥¨: {len(self.qualified_stocks)}")
        print(f"   ğŸ“ˆ åˆæ ¼ç‡: {len(self.qualified_stocks)/len(self.stock_files)*100:.1f}%")
        
        return self.qualified_stocks
    
    def print_detailed_results(self, show_top=10):
        """æ‰“å°è¯¦ç»†çš„ç­›é€‰ç»“æœ"""
        if not self.qualified_stocks:
            print("\nâŒ æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨")
            return
        
        print(f"\nğŸ† ç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨æ’è¡Œæ¦œ (å‰{min(show_top, len(self.qualified_stocks))}å):")
        print("=" * 90)
        
        for i, stock in enumerate(self.qualified_stocks[:show_top], 1):
            analysis = stock['analysis']
            if analysis['status'] != 'success':
                continue
            
            signals = analysis['signals']
            current_status = analysis['current_status']
            ma_values = analysis['ma_values']
            data_info = analysis['data_info']
            
            print(f"\nğŸ¥‡ ç¬¬{i}å: {stock['stock_code']}")
            print(f"    ğŸ“Š äº¤å‰ä¿¡å·: ğŸŒŸ{signals['golden_cross_count']}æ¬¡é»„é‡‘äº¤å‰, ğŸ’€{signals['death_cross_count']}æ¬¡æ­»å‰")
            print(f"    ğŸ“ˆ å½“å‰çŠ¶æ€: {current_status['position']}")
            print(f"    ğŸ’° æœ€æ–°ä»·æ ¼: {current_status['latest_price']}")
            print(f"    ğŸ“ ç§»åŠ¨å¹³å‡: MA10={ma_values['ma_short_latest']}, MA100={ma_values['ma_long_latest']}")
            print(f"    ğŸ“Š è¶‹åŠ¿å¼ºåº¦: {ma_values['ma_spread_pct']}% (MA10-MA100å·®å¹…)")
            print(f"    ğŸ“† åˆ†ææœŸé—´: {data_info['analysis_period_years']}å¹´ ({data_info['valid_records']}å‘¨)")
            print(f"    ğŸ”„ ä¿¡å·é¢‘ç‡: {signals['signal_frequency']}æ¬¡/å¹´")
            
            # æ˜¾ç¤ºæœ€è¿‘çš„ä¿¡å·
            if signals['latest_signal']:
                latest = signals['latest_signal']
                signal_icon = "ğŸŒŸ" if latest['type'] == 'golden_cross' else "ğŸ’€"
                signal_name = "é»„é‡‘äº¤å‰" if latest['type'] == 'golden_cross' else "æ­»å‰"
                print(f"    ğŸ•’ æœ€è¿‘ä¿¡å·: {signal_icon} {signal_name} ({latest['date'].strftime('%Y-%m-%d')}, {latest['days_ago']}å¤©å‰)")
            
            # æ˜¾ç¤ºé»„é‡‘äº¤å‰å†å²
            if len(signals['golden_cross_dates']) > 0:
                recent_golden = signals['golden_cross_dates'][-3:]  # æœ€è¿‘3æ¬¡
                golden_str = ", ".join([d.strftime('%Y-%m') for d in recent_golden])
                print(f"    ğŸŒŸ è¿‘æœŸé»„é‡‘äº¤å‰: {golden_str}")
    
    def export_results(self, filename=None):
        """å¯¼å‡ºç­›é€‰ç»“æœ"""
        if filename is None:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"ma_crossover_screening_final_{timestamp}.json"
        
        export_data = {
            'screening_info': {
                'timestamp': datetime.now().isoformat(),
                'strategy': 'åå‘¨çº¿ä¸Šç©¿ç™¾å‘¨çº¿ (MA10/MA100äº¤å‰)',
                'total_stocks': len(self.stock_files),
                'analyzed_count': len(self.results),
                'qualified_count': len(self.qualified_stocks),
                'qualification_rate': f"{len(self.qualified_stocks)/len(self.stock_files)*100:.1f}%"
            },
            'qualified_stocks': [
                {
                    'rank': i + 1,
                    'stock_code': stock['stock_code'],
                    'golden_crosses': stock['analysis']['signals']['golden_cross_count'],
                    'current_position': stock['analysis']['current_status']['position'],
                    'latest_price': stock['analysis']['current_status']['latest_price'],
                    'trend_strength': stock['analysis']['current_status']['trend_strength'],
                    'analysis_years': stock['analysis']['data_info']['analysis_period_years'],
                    'latest_signal': stock['analysis']['signals']['latest_signal']
                }
                for i, stock in enumerate(self.qualified_stocks)
            ],
            'all_results': self.results
        }
        
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(export_data, f, ensure_ascii=False, indent=2, default=str)
            print(f"\nğŸ’¾ ç­›é€‰ç»“æœå·²å¯¼å‡º: {filename}")
            return filename
        except Exception as e:
            print(f"\nâŒ å¯¼å‡ºå¤±è´¥: {e}")
            return None

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ åå‘¨çº¿ä¸Šç©¿ç™¾å‘¨çº¿è‚¡ç¥¨ç­›é€‰ - æœ€ç»ˆç‰ˆ")
    print("=" * 70)
    
    # åˆ›å»ºç­›é€‰å™¨
    screener = MACrossoverStockScreener()
    
    if len(screener.stock_files) == 0:
        print("âŒ æœªæ‰¾åˆ°è‚¡ç¥¨æ•°æ®æ–‡ä»¶")
        print("ğŸ’¡ è¯·å…ˆè¿è¡Œ create_sample_stock_data.py ç”Ÿæˆæ ·æœ¬æ•°æ®")
        return []
    
    # è¿è¡Œç­›é€‰
    qualified_stocks = screener.screen_stocks(
        min_golden_cross=1,           # è‡³å°‘1æ¬¡é»„é‡‘äº¤å‰
        require_current_bullish=True, # å½“å‰å¿…é¡»å¤šå¤´
        min_analysis_years=2          # è‡³å°‘2å¹´æ•°æ®
    )
    
    # æ˜¾ç¤ºè¯¦ç»†ç»“æœ
    screener.print_detailed_results(show_top=8)
    
    # å¯¼å‡ºç»“æœ
    export_file = screener.export_results()
    
    print(f"\nğŸ‰ è‚¡ç¥¨ç­›é€‰å®Œæˆ!")
    print(f"âœ… æ‰¾åˆ° {len(qualified_stocks)} åªç¬¦åˆåå‘¨çº¿ä¸Šç©¿ç™¾å‘¨çº¿æ¡ä»¶çš„è‚¡ç¥¨")
    
    if export_file:
        print(f"ğŸ“„ è¯¦ç»†åˆ†ææŠ¥å‘Š: {export_file}")
    
    return qualified_stocks

if __name__ == "__main__":
    results = main()