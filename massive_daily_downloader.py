#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¤§è§„æ¨¡æ—¥è¡Œæƒ…æ•°æ®ä¸‹è½½å™¨
===================

ä¸“é—¨ä¸‹è½½å…¨å¸‚åœºè‚¡ç¥¨çš„æ—¥è¡Œæƒ…æ•°æ® (2010-2025å¹´)
é‡‡ç”¨åˆ†å¹´åˆ†æ‰¹ç­–ç•¥ï¼Œç¡®ä¿æ•°æ®å®Œæ•´æ€§
"""

import uqer
import pandas as pd
from pathlib import Path
from datetime import datetime
import time

# ä¼˜çŸ¿Token
UQER_TOKEN = "68b9922817ae6273137bda7acba81e293582ba347281dfcc056dcb245b23faf3"

class MassiveDailyDownloader:
    """å¤§è§„æ¨¡æ—¥è¡Œæƒ…ä¸‹è½½å™¨"""
    
    def __init__(self):
        uqer.Client(token=UQER_TOKEN)
        self.client = uqer
        self.base_path = Path("/Users/jackstudio/QuantTrade/data/daily")
        self.base_path.mkdir(exist_ok=True)
        
        print("ğŸ“ˆ å¤§è§„æ¨¡æ—¥è¡Œæƒ…æ•°æ®ä¸‹è½½å™¨")
        print("ğŸ¯ ç›®æ ‡: å…¨å¸‚åœºè‚¡ç¥¨æ—¥è¡Œæƒ… (2010-2025)")
        print("=" * 50)
    
    def get_all_stocks(self):
        """è·å–å…¨éƒ¨è‚¡ç¥¨"""
        try:
            result = self.client.DataAPI.EquGet(
                listStatusCD='L',
                field='secID,ticker',
                pandas='1'
            )
            stocks = result['secID'].unique().tolist()
            print(f"âœ… è·å– {len(stocks)} åªè‚¡ç¥¨")
            return stocks
        except Exception as e:
            print(f"âŒ è·å–è‚¡ç¥¨å¤±è´¥: {e}")
            return []
    
    def download_yearly_data(self, stocks, year):
        """æŒ‰å¹´ä¸‹è½½æ—¥è¡Œæƒ…æ•°æ®"""
        print(f"\nğŸ“Š ä¸‹è½½ {year} å¹´æ•°æ®...")
        
        batch_size = 50  # å°æ‰¹æ¬¡ç¡®ä¿ç¨³å®šæ€§
        all_data = []
        
        for i in range(0, len(stocks), batch_size):
            batch_stocks = stocks[i:i+batch_size]
            batch_tickers = ','.join([s.split('.')[0] for s in batch_stocks])
            
            print(f"  ğŸ”„ æ‰¹æ¬¡ {i//batch_size + 1}/{(len(stocks)-1)//batch_size + 1}: {len(batch_stocks)} åªè‚¡ç¥¨")
            
            try:
                result = self.client.DataAPI.MktEqudGet(
                    secID='',
                    ticker=batch_tickers,
                    beginDate=f'{year}0101',
                    endDate=f'{year}1231',
                    field='secID,ticker,tradeDate,preClosePrice,openPrice,highestPrice,lowestPrice,closePrice,turnoverVol,marketValue',
                    pandas='1'
                )
                
                if isinstance(result, pd.DataFrame) and not result.empty:
                    all_data.append(result)
                    print(f"    âœ… å®Œæˆ: {len(result)} æ¡è®°å½•")
                else:
                    print(f"    âš ï¸ æ— æ•°æ®")
                
                time.sleep(0.5)  # é˜²æ­¢é¢‘ç‡é™åˆ¶
                
            except Exception as e:
                print(f"    âŒ æ‰¹æ¬¡å¤±è´¥: {e}")
                time.sleep(1)
                continue
        
        # ä¿å­˜å¹´åº¦æ•°æ®
        if all_data:
            combined = pd.concat(all_data, ignore_index=True)
            output_file = self.base_path / f"daily_{year}.csv"
            combined.to_csv(output_file, index=False)
            
            print(f"âœ… {year}å¹´å®Œæˆ: {len(combined)} æ¡è®°å½•")
            return len(combined)
        
        return 0
    
    def run_massive_download(self):
        """è¿è¡Œå¤§è§„æ¨¡ä¸‹è½½"""
        start_time = datetime.now()
        
        # è·å–è‚¡ç¥¨åˆ—è¡¨
        stocks = self.get_all_stocks()
        if not stocks:
            return
        
        # åˆ†å¹´ä¸‹è½½ (ä»æœ€è¿‘å¼€å§‹)
        years = [2024, 2023, 2022, 2021, 2020, 2019, 2018, 2017, 2016, 2015]
        total_records = 0
        
        print(f"\nğŸš€ å¼€å§‹å¤§è§„æ¨¡ä¸‹è½½: {len(stocks)} åªè‚¡ç¥¨ x {len(years)} å¹´")
        print("â±ï¸ é¢„è®¡æ—¶é—´: 3-4å°æ—¶")
        
        for year in years:
            year_records = self.download_yearly_data(stocks, year)
            total_records += year_records
            
            print(f"ğŸ“Š ç´¯è®¡ä¸‹è½½: {total_records:,} æ¡è®°å½•")
            time.sleep(2)  # å¹´åº¦é—´ä¼‘æ¯
        
        # æœ€ç»ˆæŠ¥å‘Š
        end_time = datetime.now()
        duration = end_time - start_time
        
        print(f"\nğŸŠ å¤§è§„æ¨¡ä¸‹è½½å®Œæˆ!")
        print(f"â±ï¸ æ€»è€—æ—¶: {duration}")
        print(f"ğŸ“ˆ æ€»è®°å½•: {total_records:,} æ¡")
        
        # æ˜¾ç¤ºæ–‡ä»¶
        files = list(self.base_path.glob("daily_*.csv"))
        total_size = sum(f.stat().st_size for f in files) / (1024*1024*1024)
        print(f"ğŸ“ ç”Ÿæˆæ–‡ä»¶: {len(files)} ä¸ª")
        print(f"ğŸ’¾ æ€»å¤§å°: {total_size:.2f} GB")

def main():
    downloader = MassiveDailyDownloader()
    downloader.run_massive_download()

if __name__ == "__main__":
    main()