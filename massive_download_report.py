#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¤§è§„æ¨¡æ•°æ®ä¸‹è½½å®ŒæˆæŠ¥å‘Š
===================

ç»Ÿè®¡æ‰€æœ‰å·²ä¸‹è½½çš„æ•°æ®æƒ…å†µ
"""

import pandas as pd
from pathlib import Path
from datetime import datetime

def generate_massive_download_report():
    """ç”Ÿæˆå¤§è§„æ¨¡ä¸‹è½½æŠ¥å‘Š"""
    
    print("ğŸŠ ä¼˜çŸ¿å¤§è§„æ¨¡æ•°æ®ä¸‹è½½å®ŒæˆæŠ¥å‘Š")
    print("=" * 70)
    print(f"â° æŠ¥å‘Šæ—¶é—´: {datetime.now()}")
    print()
    
    data_path = Path("/Users/jackstudio/QuantTrade/data")
    
    # æ‰€æœ‰æ•°æ®ç›®å½•
    data_categories = {
        "basic_info": {"name": "è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯", "api": "EquGet", "priority": 1},
        "calendar": {"name": "äº¤æ˜“æ—¥å†", "api": "TradeCalGet", "priority": 1}, 
        "daily": {"name": "è‚¡ç¥¨æ—¥è¡Œæƒ…", "api": "MktEqudGet", "priority": 1},
        "adjustment": {"name": "å¤æƒå› å­", "api": "MktAdjfGet", "priority": 2},
        "dividend": {"name": "è‚¡ç¥¨åˆ†çº¢", "api": "EquDivGet", "priority": 2},
        "financial": {"name": "è´¢åŠ¡æ•°æ®", "api": "FdmtBs2018Getç­‰", "priority": 2},
        "capital_flow": {"name": "èµ„é‡‘æµå‘", "api": "MktEquFlowGet", "priority": 3},
        "limit_info": {"name": "æ¶¨è·Œåœä¿¡æ¯", "api": "MktLimitGet", "priority": 3},
        "rank_list": {"name": "é¾™è™æ¦œæ•°æ®", "api": "MktRankListStocksGet", "priority": 3}
    }
    
    # åˆ†ä¼˜å…ˆçº§ç»Ÿè®¡
    priority_stats = {1: [], 2: [], 3: []}
    total_size_gb = 0
    total_files = 0
    total_records = 0
    
    for category, info in data_categories.items():
        dir_path = data_path / category
        
        print(f"ğŸ“ {info['name']} ({info['api']})")
        
        if dir_path.exists():
            csv_files = list(dir_path.glob("*.csv"))
            
            if csv_files:
                cat_size = 0
                cat_records = 0
                
                for file in csv_files:
                    try:
                        file_size_mb = file.stat().st_size / (1024*1024)
                        cat_size += file_size_mb
                        
                        # è¯»å–è®°å½•æ•°
                        df = pd.read_csv(file)
                        records = len(df)
                        cat_records += records
                        
                        print(f"   ğŸ“„ {file.name}: {records:,} æ¡è®°å½•, {file_size_mb:.1f}MB")
                        
                        # æ˜¾ç¤ºæ—¶é—´èŒƒå›´å’Œè‚¡ç¥¨æ•°é‡
                        if 'tradeDate' in df.columns:
                            date_range = f"{df['tradeDate'].min()} è‡³ {df['tradeDate'].max()}"
                            print(f"      ğŸ“… æ—¶é—´: {date_range}")
                            if 'ticker' in df.columns:
                                stock_count = df['ticker'].nunique()
                                print(f"      ğŸ¢ è‚¡ç¥¨: {stock_count} åª")
                        elif 'endDate' in df.columns:
                            date_range = f"{df['endDate'].min()} è‡³ {df['endDate'].max()}"
                            print(f"      ğŸ“… æ—¶é—´: {date_range}")
                            if 'ticker' in df.columns:
                                stock_count = df['ticker'].nunique()
                                print(f"      ğŸ¢ å…¬å¸: {stock_count} å®¶")
                        elif 'calendarDate' in df.columns:
                            date_range = f"{df['calendarDate'].min()} è‡³ {df['calendarDate'].max()}"
                            print(f"      ğŸ“… æ—¶é—´: {date_range}")
                        elif 'exDivDate' in df.columns:
                            date_range = f"{df['exDivDate'].min()} è‡³ {df['exDivDate'].max()}"
                            print(f"      ğŸ“… æ—¶é—´: {date_range}")
                            if 'ticker' in df.columns:
                                stock_count = df['ticker'].nunique()
                                print(f"      ğŸ¢ è‚¡ç¥¨: {stock_count} åª")
                        
                    except Exception as e:
                        print(f"   âŒ {file.name}: è¯»å–å¤±è´¥ - {e}")
                        cat_size += file.stat().st_size / (1024*1024)
                
                print(f"   ğŸ“Š å­ç›®å½•æ€»è®¡: {len(csv_files)} æ–‡ä»¶, {cat_records:,} è®°å½•, {cat_size:.1f}MB")
                priority_stats[info['priority']].append({
                    'name': info['name'], 
                    'files': len(csv_files),
                    'records': cat_records,
                    'size_mb': cat_size
                })
                
                total_size_gb += cat_size / 1024
                total_files += len(csv_files)
                total_records += cat_records
                
            else:
                print(f"   ğŸ“‚ ç›®å½•å­˜åœ¨ä½†æ— CSVæ–‡ä»¶")
        else:
            print(f"   âŒ ç›®å½•ä¸å­˜åœ¨")
        
        print()
    
    # æŒ‰ä¼˜å…ˆçº§æ±‡æ€»
    print("ğŸ“Š æŒ‰ä¼˜å…ˆçº§æ±‡æ€»ç»Ÿè®¡")
    print("-" * 50)
    
    priority_names = {
        1: "ğŸ”¥ æ ¸å¿ƒäº¤æ˜“æ•°æ®",
        2: "ğŸ’° æŠ€æœ¯åˆ†ææ•°æ®", 
        3: "ğŸ§  æƒ…ç»ªåˆ†ææ•°æ®"
    }
    
    for priority in [1, 2, 3]:
        print(f"{priority_names[priority]}")
        
        if priority_stats[priority]:
            p_files = sum(item['files'] for item in priority_stats[priority])
            p_records = sum(item['records'] for item in priority_stats[priority])
            p_size = sum(item['size_mb'] for item in priority_stats[priority])
            
            print(f"   ğŸ“ æ•°æ®é›†: {len(priority_stats[priority])} ä¸ª")
            print(f"   ğŸ“„ æ–‡ä»¶æ•°: {p_files} ä¸ª")
            print(f"   ğŸ“‹ è®°å½•æ•°: {p_records:,} æ¡")
            print(f"   ğŸ’¾ æ•°æ®é‡: {p_size:.1f}MB")
            
            for item in priority_stats[priority]:
                status = "âœ…" if item['records'] > 0 else "âš ï¸"
                print(f"     {status} {item['name']}: {item['records']:,} æ¡è®°å½•")
        else:
            print(f"   â³ è¯¥ä¼˜å…ˆçº§æš‚æ— æ•°æ®")
        
        print()
    
    # æ€»ä½“ç»Ÿè®¡
    print("ğŸ¯ æ€»ä½“ä¸‹è½½ç»Ÿè®¡")
    print("-" * 40)
    print(f"ğŸ“ æ•°æ®é›†: {len([s for stats in priority_stats.values() for s in stats])} ä¸ª")
    print(f"ğŸ“„ æ–‡ä»¶æ€»æ•°: {total_files} ä¸ª")
    print(f"ğŸ“‹ è®°å½•æ€»æ•°: {total_records:,} æ¡")  
    print(f"ğŸ’¾ æ•°æ®æ€»é‡: {total_size_gb:.2f} GB")
    
    # ä¸‹è½½å®Œæˆåº¦
    expected_datasets = 10  # é¢„æœŸçš„æ•°æ®é›†æ•°é‡
    completed_datasets = len([s for stats in priority_stats.values() for s in stats if s['records'] > 0])
    completion_rate = (completed_datasets / expected_datasets) * 100
    
    print(f"ğŸ“ˆ å®Œæˆåº¦: {completion_rate:.1f}% ({completed_datasets}/{expected_datasets})")
    
    print()
    
    # Frameworkæ”¯æŒè¯„ä¼°
    print("ğŸ¯ QuantTrade Framework æ”¯æŒè¯„ä¼°")  
    print("-" * 50)
    
    core_complete = len(priority_stats[1]) >= 2  # è‡³å°‘éœ€è¦æ—¥è¡Œæƒ…+äº¤æ˜“æ—¥å†
    technical_complete = len(priority_stats[2]) >= 2  # éœ€è¦å¤æƒ+è´¢åŠ¡
    sentiment_complete = len(priority_stats[3]) >= 1  # è‡³å°‘éœ€è¦èµ„é‡‘æµå‘
    
    print(f"ğŸ”¥ æ ¸å¿ƒäº¤æ˜“åŠŸèƒ½: {'âœ… æ”¯æŒ' if core_complete else 'â³ éƒ¨åˆ†æ”¯æŒ'}")
    print(f"ğŸ’° æŠ€æœ¯åˆ†æåŠŸèƒ½: {'âœ… æ”¯æŒ' if technical_complete else 'â³ éƒ¨åˆ†æ”¯æŒ'}")  
    print(f"ğŸ§  æƒ…ç»ªåˆ†æåŠŸèƒ½: {'âœ… æ”¯æŒ' if sentiment_complete else 'â³ éƒ¨åˆ†æ”¯æŒ'}")
    print(f"ğŸ“Š åŸºæœ¬é¢åˆ†æåŠŸèƒ½: {'âœ… æ”¯æŒ' if len([s for s in priority_stats[2] if 'è´¢åŠ¡' in s['name']]) > 0 else 'â³ éƒ¨åˆ†æ”¯æŒ'}")
    
    if core_complete and technical_complete and sentiment_complete:
        print(f"\nğŸŠ Frameworkå®Œæ•´åŠŸèƒ½æ”¯æŒ: âœ… å·²å°±ç»ª!")
        print(f"ğŸš€ å¯å¼€å§‹é‡åŒ–äº¤æ˜“ç­–ç•¥å¼€å‘å’Œå›æµ‹!")
    else:
        print(f"\nâ³ FrameworkåŠŸèƒ½æ”¯æŒ: åŸºç¡€åŠŸèƒ½å¯ç”¨ï¼Œç­‰å¾…æ›´å¤šæ•°æ®è¡¥å……")

if __name__ == "__main__":
    generate_massive_download_report()