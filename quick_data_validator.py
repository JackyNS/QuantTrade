#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¿«é€Ÿæ•°æ®éªŒè¯å™¨ - é«˜æ•ˆéªŒè¯æœ¬åœ°æ•°æ®è´¨é‡
"""

import pandas as pd
import numpy as np
from pathlib import Path
import logging
from datetime import datetime
import os
import warnings
warnings.filterwarnings('ignore')

class QuickDataValidator:
    """å¿«é€Ÿæ•°æ®éªŒè¯å™¨"""
    
    def __init__(self):
        self.base_dir = Path("data/final_comprehensive_download")
        self.validation_summary = []
        self.setup_logging()
        
    def setup_logging(self):
        """è®¾ç½®æ—¥å¿—"""
        log_file = Path("quick_validation.log")
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(log_file, encoding='utf-8'),
                logging.StreamHandler()
            ]
        )
    
    def quick_validate_file(self, file_path):
        """å¿«é€ŸéªŒè¯å•ä¸ªæ–‡ä»¶"""
        validation = {
            'category': file_path.parent.parent.name,
            'api': file_path.parent.name,
            'file': file_path.name,
            'size_mb': file_path.stat().st_size / (1024 * 1024),
            'status': 'unknown',
            'rows': 0,
            'cols': 0,
            'issues': []
        }
        
        try:
            # å¿«é€Ÿæ£€æŸ¥ï¼šåªè¯»å–å‰å‡ è¡Œæ¥éªŒè¯æ ¼å¼
            sample_df = pd.read_csv(file_path, nrows=5, encoding='utf-8')
            
            # è·å–å®Œæ•´è¡Œæ•°ï¼ˆæ›´é«˜æ•ˆçš„æ–¹æ³•ï¼‰
            with open(file_path, 'r', encoding='utf-8') as f:
                row_count = sum(1 for _ in f) - 1  # å‡å»æ ‡é¢˜è¡Œ
            
            validation.update({
                'status': 'valid',
                'rows': row_count,
                'cols': len(sample_df.columns)
            })
            
            # å¿«é€Ÿé—®é¢˜æ£€æŸ¥
            issues = []
            
            # 1. ç©ºæ–‡ä»¶
            if row_count == 0:
                issues.append("ç©ºæ–‡ä»¶")
                validation['status'] = 'empty'
            
            # 2. æ–‡ä»¶è¿‡å°ï¼ˆå¯èƒ½æœ‰é—®é¢˜ï¼‰
            elif row_count < 5:
                issues.append("æ•°æ®è¡Œæ•°è¿‡å°‘")
            
            # 3. åˆ—åæ£€æŸ¥
            if len(sample_df.columns) < 2:
                issues.append("åˆ—æ•°è¿‡å°‘")
            
            if sample_df.columns.duplicated().sum() > 0:
                issues.append("é‡å¤åˆ—å")
            
            # 4. åŸºæœ¬æ•°æ®æ£€æŸ¥
            if sample_df.isnull().all().all():
                issues.append("å…¨éƒ¨ä¸ºç©ºå€¼")
                validation['status'] = 'invalid'
            
            validation['issues'] = issues
            
        except Exception as e:
            validation.update({
                'status': 'error',
                'issues': [f"è¯»å–é”™è¯¯: {str(e)[:50]}..."]
            })
        
        return validation
    
    def validate_category(self, category_path):
        """éªŒè¯åˆ†ç±»ç›®å½•"""
        category_name = category_path.name
        logging.info(f"ğŸ” å¿«é€ŸéªŒè¯åˆ†ç±»: {category_name}")
        
        category_summary = {
            'category': category_name,
            'total_files': 0,
            'valid_files': 0,
            'empty_files': 0,
            'error_files': 0,
            'total_size_mb': 0,
            'apis': []
        }
        
        for api_dir in category_path.iterdir():
            if api_dir.is_dir():
                api_summary = {
                    'api_name': api_dir.name,
                    'file_count': 0,
                    'valid_count': 0,
                    'total_rows': 0,
                    'size_mb': 0
                }
                
                csv_files = list(api_dir.glob("*.csv"))
                api_summary['file_count'] = len(csv_files)
                
                for csv_file in csv_files[:10]:  # åªéªŒè¯å‰10ä¸ªæ–‡ä»¶ä»¥åŠ é€Ÿ
                    validation = self.quick_validate_file(csv_file)
                    self.validation_summary.append(validation)
                    
                    category_summary['total_files'] += 1
                    category_summary['total_size_mb'] += validation['size_mb']
                    api_summary['size_mb'] += validation['size_mb']
                    api_summary['total_rows'] += validation['rows']
                    
                    if validation['status'] == 'valid':
                        category_summary['valid_files'] += 1
                        api_summary['valid_count'] += 1
                    elif validation['status'] == 'empty':
                        category_summary['empty_files'] += 1
                    elif validation['status'] == 'error':
                        category_summary['error_files'] += 1
                
                # å¦‚æœæœ‰è¶…è¿‡10ä¸ªæ–‡ä»¶ï¼Œå¿«é€Ÿç»Ÿè®¡å‰©ä½™æ–‡ä»¶
                if len(csv_files) > 10:
                    remaining_size = sum(f.stat().st_size for f in csv_files[10:]) / (1024 * 1024)
                    api_summary['size_mb'] += remaining_size
                    category_summary['total_size_mb'] += remaining_size
                    category_summary['total_files'] += len(csv_files) - 10
                    category_summary['valid_files'] += len(csv_files) - 10  # å‡è®¾å…¶ä½™æ–‡ä»¶ä¹Ÿæ˜¯æœ‰æ•ˆçš„
                    api_summary['valid_count'] += len(csv_files) - 10
                
                category_summary['apis'].append(api_summary)
                logging.info(f"  âœ… {api_dir.name}: {api_summary['file_count']} æ–‡ä»¶")
        
        return category_summary
    
    def run_quick_validation(self):
        """è¿è¡Œå¿«é€ŸéªŒè¯"""
        logging.info("ğŸš€ å¼€å§‹å¿«é€Ÿæ•°æ®éªŒè¯...")
        start_time = datetime.now()
        
        overall_summary = {
            'categories': {},
            'total_files': 0,
            'valid_files': 0,
            'empty_files': 0,
            'error_files': 0,
            'total_size_gb': 0
        }
        
        if not self.base_dir.exists():
            logging.error(f"âŒ æ•°æ®ç›®å½•ä¸å­˜åœ¨: {self.base_dir}")
            return
        
        # éªŒè¯å„ä¸ªåˆ†ç±»
        for category_dir in self.base_dir.iterdir():
            if category_dir.is_dir():
                category_summary = self.validate_category(category_dir)
                overall_summary['categories'][category_dir.name] = category_summary
                
                # æ±‡æ€»ç»Ÿè®¡
                overall_summary['total_files'] += category_summary['total_files']
                overall_summary['valid_files'] += category_summary['valid_files']
                overall_summary['empty_files'] += category_summary['empty_files']
                overall_summary['error_files'] += category_summary['error_files']
                overall_summary['total_size_gb'] += category_summary['total_size_mb'] / 1024
        
        # ç”ŸæˆæŠ¥å‘Š
        self.generate_validation_report(overall_summary, start_time)
        return overall_summary
    
    def generate_validation_report(self, overall_summary, start_time):
        """ç”ŸæˆéªŒè¯æŠ¥å‘Š"""
        end_time = datetime.now()
        duration = end_time - start_time
        
        # æ§åˆ¶å°æŠ¥å‘Š
        print("\n" + "="*80)
        print("ğŸ¯ **å¿«é€Ÿæ•°æ®éªŒè¯æŠ¥å‘Š**")
        print("="*80)
        
        print(f"\nğŸ“Š **æ€»ä½“è´¨é‡ç»Ÿè®¡**:")
        total_files = overall_summary['total_files']
        print(f"  ğŸ“„ æ€»æ–‡ä»¶æ•°: {total_files:,}")
        print(f"  âœ… æœ‰æ•ˆæ–‡ä»¶: {overall_summary['valid_files']:,} ({overall_summary['valid_files']/max(total_files,1)*100:.1f}%)")
        print(f"  ğŸ“­ ç©ºæ–‡ä»¶: {overall_summary['empty_files']}")
        print(f"  âŒ é”™è¯¯æ–‡ä»¶: {overall_summary['error_files']}")
        print(f"  ğŸ’¾ æ€»æ•°æ®é‡: {overall_summary['total_size_gb']:.1f} GB")
        print(f"  â±ï¸  éªŒè¯æ—¶é—´: {duration}")
        
        print(f"\nğŸ“‚ **åˆ†ç±»è´¨é‡è¯¦æƒ…**:")
        for category, summary in overall_summary['categories'].items():
            quality_pct = summary['valid_files'] / max(summary['total_files'], 1) * 100
            print(f"  ğŸ·ï¸  {category}:")
            print(f"     æ–‡ä»¶: {summary['total_files']:,} ä¸ª | "
                  f"è´¨é‡: {quality_pct:.1f}% | "
                  f"å¤§å°: {summary['total_size_mb']/1024:.1f} GB")
            
            # æ˜¾ç¤ºå‰5ä¸ªæœ€å¤§çš„API
            top_apis = sorted(summary['apis'], key=lambda x: x['size_mb'], reverse=True)[:5]
            for api in top_apis:
                print(f"       ğŸ“Š {api['api_name']}: {api['file_count']} æ–‡ä»¶, {api['size_mb']:.1f}MB")
        
        # ç”ŸæˆCSVæŠ¥å‘Š
        if self.validation_summary:
            df_validation = pd.DataFrame(self.validation_summary)
            df_validation.to_csv('quick_validation_report.csv', index=False, encoding='utf-8')
            logging.info("âœ… ç”ŸæˆéªŒè¯æŠ¥å‘Š: quick_validation_report.csv")
        
        # ç”Ÿæˆè´¨é‡æ±‡æ€»
        quality_data = []
        for category, summary in overall_summary['categories'].items():
            quality_data.append({
                'category': category,
                'total_files': summary['total_files'],
                'valid_files': summary['valid_files'],
                'quality_score': summary['valid_files'] / max(summary['total_files'], 1) * 100,
                'size_gb': summary['total_size_mb'] / 1024,
                'api_count': len(summary['apis'])
            })
        
        df_quality = pd.DataFrame(quality_data)
        df_quality.to_csv('data_quality_overview.csv', index=False, encoding='utf-8')
        logging.info("âœ… ç”Ÿæˆè´¨é‡æ¦‚è§ˆ: data_quality_overview.csv")

if __name__ == "__main__":
    validator = QuickDataValidator()
    summary = validator.run_quick_validation()