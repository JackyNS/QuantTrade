#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åŸºäºä¸Šå¸‚æ—¶é—´çš„ç°å®æ•°æ®å®Œæ•´æ€§æ£€æŸ¥å™¨
è€ƒè™‘è‚¡ç¥¨å®é™…ä¸Šå¸‚æ—¶é—´ï¼Œåˆç†åˆ¤æ–­æ•°æ®å®Œæ•´æ€§
"""

import pandas as pd
import numpy as np
from pathlib import Path
from datetime import datetime
import warnings
from collections import defaultdict
warnings.filterwarnings('ignore')

class RealisticCompletenessChecker:
    """åŸºäºä¸Šå¸‚æ—¶é—´çš„ç°å®å®Œæ•´æ€§æ£€æŸ¥å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–æ£€æŸ¥å™¨"""
        self.base_path = Path("/Users/jackstudio/QuantTrade/data")
        self.analysis_end = pd.Timestamp('2025-08-31')
        self.stock_info = {}
    
    def get_stock_listing_info(self):
        """è·å–è‚¡ç¥¨ä¸Šå¸‚ä¿¡æ¯"""
        print("ğŸ“‹ è·å–è‚¡ç¥¨ä¸Šå¸‚ä¿¡æ¯...")
        
        # å°è¯•ä»basic_infoç›®å½•è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
        basic_info_paths = [
            "final_comprehensive_download/basic_info",
            "optimized_data/basic_info", 
            "raw/basic_info"
        ]
        
        stock_info = {}
        
        for path in basic_info_paths:
            full_path = self.base_path / path
            if full_path.exists():
                info_files = list(full_path.rglob("*.csv"))
                print(f"   ğŸ“ æ£€æŸ¥ {path}: {len(info_files)} ä¸ªæ–‡ä»¶")
                
                for file_path in info_files[:3]:  # æ£€æŸ¥å‰å‡ ä¸ªæ–‡ä»¶
                    try:
                        df = pd.read_csv(file_path)
                        
                        # å¯»æ‰¾ç›¸å…³åˆ—
                        if 'secID' in df.columns:
                            for _, row in df.iterrows():
                                stock_id = row['secID']
                                
                                # å¯»æ‰¾ä¸Šå¸‚æ—¥æœŸåˆ—
                                listing_date = None
                                for col in df.columns:
                                    if any(keyword in col.lower() for keyword in ['list', 'ipo', 'ä¸Šå¸‚', 'date']):
                                        try:
                                            date_val = pd.to_datetime(row[col])
                                            if date_val.year >= 1990 and date_val.year <= 2025:
                                                listing_date = date_val
                                                break
                                        except:
                                            continue
                                
                                if listing_date:
                                    stock_info[stock_id] = {
                                        'listing_date': listing_date,
                                        'source': path
                                    }
                                    
                        if len(stock_info) > 0:
                            print(f"   âœ… ä» {file_path.name} è·å–äº† {len(stock_info)} åªè‚¡ç¥¨ä¿¡æ¯")
                            break
                            
                    except Exception as e:
                        continue
                
                if stock_info:
                    break
        
        self.stock_info = stock_info
        print(f"   ğŸ“Š æ€»å…±è·å–: {len(stock_info)} åªè‚¡ç¥¨çš„ä¸Šå¸‚ä¿¡æ¯")
        return stock_info
    
    def estimate_listing_date_from_data(self, stock_id, stock_data):
        """ä»æ•°æ®æœ¬èº«ä¼°ç®—ä¸Šå¸‚æ—¶é—´"""
        if len(stock_data) == 0:
            return None
        
        # æ•°æ®çš„æœ€æ—©æ—¥æœŸå¯èƒ½å°±æ˜¯ä¸Šå¸‚æ—¥æœŸé™„è¿‘
        earliest_date = stock_data['tradeDate'].min()
        
        # å¦‚æœæ•°æ®å¼€å§‹æ—¶é—´åˆç†ï¼ˆ1990å¹´åï¼‰ï¼Œè®¤ä¸ºæ¥è¿‘ä¸Šå¸‚æ—¶é—´
        if earliest_date.year >= 1990:
            return earliest_date
        
        return None
    
    def check_stock_realistic_completeness(self, stock_id):
        """æ£€æŸ¥å•åªè‚¡ç¥¨çš„ç°å®æ•°æ®å®Œæ•´æ€§"""
        # 1. æ”¶é›†è¯¥è‚¡ç¥¨çš„æ‰€æœ‰æ•°æ®
        daily_path = self.base_path / "priority_download/market_data/daily"
        batch_files = list(daily_path.glob("*.csv"))
        
        all_data = []
        
        for file_path in batch_files:
            try:
                df = pd.read_csv(file_path)
                if 'secID' in df.columns:
                    stock_data = df[df['secID'] == stock_id]
                    if len(stock_data) > 0:
                        all_data.append(stock_data)
            except:
                continue
        
        if not all_data:
            return {
                'has_data': False,
                'status': 'âŒ æ— æ•°æ®'
            }
        
        # åˆå¹¶æ‰€æœ‰æ•°æ®
        combined_df = pd.concat(all_data, ignore_index=True)
        combined_df['tradeDate'] = pd.to_datetime(combined_df['tradeDate'])
        combined_df = combined_df.drop_duplicates(subset=['tradeDate']).sort_values('tradeDate')
        
        data_start = combined_df['tradeDate'].min()
        data_end = combined_df['tradeDate'].max()
        
        # 2. ç¡®å®šæœŸæœ›çš„å¼€å§‹æ—¶é—´
        if stock_id in self.stock_info:
            # æœ‰ä¸Šå¸‚ä¿¡æ¯
            listing_date = self.stock_info[stock_id]['listing_date']
            expected_start = listing_date
            info_source = "ä¸Šå¸‚ä¿¡æ¯"
        else:
            # ä¼°ç®—ä¸Šå¸‚æ—¶é—´
            estimated_listing = self.estimate_listing_date_from_data(stock_id, combined_df)
            if estimated_listing:
                expected_start = estimated_listing
                info_source = "æ•°æ®ä¼°ç®—"
            else:
                expected_start = pd.Timestamp('2000-01-01')  # é»˜è®¤
                info_source = "é»˜è®¤å‡è®¾"
        
        # 3. åˆ¤æ–­å®Œæ•´æ€§
        # å¼€å§‹æ—¶é—´ï¼šå…è®¸ä¸€ä¸ªæœˆçš„è¯¯å·®
        start_coverage = data_start <= expected_start + pd.Timedelta(days=30)
        # ç»“æŸæ—¶é—´ï¼šåº”è¯¥åˆ°2025å¹´8æœˆé™„è¿‘
        end_coverage = data_end >= self.analysis_end - pd.Timedelta(days=60)
        
        if start_coverage and end_coverage:
            status = 'âœ… å®Œæ•´'
        elif start_coverage and not end_coverage:
            status = 'ğŸŸ¡ ç¼ºå°‘è¿‘æœŸæ•°æ®'
        elif not start_coverage and end_coverage:
            status = 'ğŸŸ¡ ç¼ºå°‘æ—©æœŸæ•°æ®'
        else:
            status = 'ğŸ”´ æ•°æ®ä¸è¶³'
        
        return {
            'has_data': True,
            'status': status,
            'data_range': f"{data_start.strftime('%Y-%m-%d')} - {data_end.strftime('%Y-%m-%d')}",
            'expected_start': expected_start.strftime('%Y-%m-%d'),
            'data_start': data_start,
            'data_end': data_end,
            'expected_start_date': expected_start,
            'records': len(combined_df),
            'info_source': info_source,
            'start_coverage': start_coverage,
            'end_coverage': end_coverage
        }
    
    def realistic_completeness_check(self, sample_size=150):
        """è¿›è¡Œç°å®çš„å®Œæ•´æ€§æ£€æŸ¥"""
        print("ğŸ” åŸºäºä¸Šå¸‚æ—¶é—´çš„ç°å®æ•°æ®å®Œæ•´æ€§æ£€æŸ¥")
        print("ğŸ¯ æ£€æŸ¥é€»è¾‘: ä»ä¸Šå¸‚æ—¥æœŸå¼€å§‹åˆ°2025å¹´8æœˆ31æ—¥")
        print("=" * 80)
        
        # è·å–ä¸Šå¸‚ä¿¡æ¯
        self.get_stock_listing_info()
        
        # è·å–è‚¡ç¥¨æ ·æœ¬
        csv_daily_path = self.base_path / "csv_complete/daily"
        if csv_daily_path.exists():
            stock_files = list(csv_daily_path.rglob("*.csv"))
            sample_files = stock_files[:sample_size]
            sample_stocks = [f.stem.replace('_', '.') for f in sample_files]
        else:
            print("âŒ æ— æ³•è·å–è‚¡ç¥¨æ ·æœ¬")
            return
        
        print(f"ğŸ“Š æ£€æŸ¥æ ·æœ¬: {len(sample_stocks)} åªè‚¡ç¥¨")
        print("=" * 80)
        
        results = {
            'complete': [],           # å®Œæ•´æ•°æ®
            'missing_recent': [],     # ç¼ºå°‘è¿‘æœŸæ•°æ®
            'missing_early': [],      # ç¼ºå°‘æ—©æœŸæ•°æ®
            'insufficient': [],       # æ•°æ®ä¸è¶³
            'no_data': []            # æ— æ•°æ®
        }
        
        for i, stock_id in enumerate(sample_stocks, 1):
            result = self.check_stock_realistic_completeness(stock_id)
            
            if not result['has_data']:
                results['no_data'].append(stock_id)
                continue
            
            stock_result = {
                'stock_id': stock_id,
                'status': result['status'],
                'data_range': result['data_range'],
                'expected_start': result['expected_start'],
                'records': result['records'],
                'info_source': result['info_source']
            }
            
            if result['status'] == 'âœ… å®Œæ•´':
                results['complete'].append(stock_result)
            elif result['status'] == 'ğŸŸ¡ ç¼ºå°‘è¿‘æœŸæ•°æ®':
                results['missing_recent'].append(stock_result)
            elif result['status'] == 'ğŸŸ¡ ç¼ºå°‘æ—©æœŸæ•°æ®':
                results['missing_early'].append(stock_result)
            else:
                results['insufficient'].append(stock_result)
            
            # æ˜¾ç¤ºè¿›åº¦
            if i % 30 == 0 or i <= 15:
                expected = result.get('expected_start', 'Unknown')
                print(f"[{i:3}/{len(sample_stocks)}] {stock_id}: {result['status']} (æœŸæœ›:{expected} å®é™…:{result.get('data_range', 'N/A')})")
        
        self.generate_realistic_report(results, len(sample_stocks))
    
    def generate_realistic_report(self, results, total_checked):
        """ç”Ÿæˆç°å®çš„æ£€æŸ¥æŠ¥å‘Š"""
        complete_count = len(results['complete'])
        missing_recent_count = len(results['missing_recent'])
        missing_early_count = len(results['missing_early'])
        insufficient_count = len(results['insufficient'])
        no_data_count = len(results['no_data'])
        
        print("\\nğŸŠ ç°å®æ•°æ®å®Œæ•´æ€§æ£€æŸ¥ç»“æœ:")
        print("=" * 80)
        print(f"ğŸ“Š æ£€æŸ¥æ ·æœ¬: {total_checked}")
        print(f"âœ… å®Œæ•´æ•°æ®: {complete_count} ({complete_count/total_checked*100:.1f}%)")
        print(f"ğŸŸ¡ ç¼ºå°‘è¿‘æœŸ: {missing_recent_count} ({missing_recent_count/total_checked*100:.1f}%)")
        print(f"ğŸŸ¡ ç¼ºå°‘æ—©æœŸ: {missing_early_count} ({missing_early_count/total_checked*100:.1f}%)")
        print(f"ğŸ”´ æ•°æ®ä¸è¶³: {insufficient_count} ({insufficient_count/total_checked*100:.1f}%)")
        print(f"âŒ æ— æ•°æ®: {no_data_count} ({no_data_count/total_checked*100:.1f}%)")
        
        # æ˜¾ç¤ºå®Œæ•´æ•°æ®æ ·æœ¬
        if results['complete']:
            print("\\nâœ… å®Œæ•´æ•°æ®æ ·æœ¬:")
            for stock in results['complete'][:8]:
                print(f"   {stock['stock_id']}: {stock['data_range']} ({stock['records']} æ¡) - {stock['info_source']}")
        
        # æ˜¾ç¤ºæœ‰é—®é¢˜çš„æ ·æœ¬
        if results['missing_recent']:
            print("\\nğŸŸ¡ ç¼ºå°‘è¿‘æœŸæ•°æ®æ ·æœ¬:")
            for stock in results['missing_recent'][:5]:
                print(f"   {stock['stock_id']}: {stock['data_range']} (æœŸæœ›åˆ°2025-08)")
        
        if results['missing_early']:
            print("\\nğŸŸ¡ ç¼ºå°‘æ—©æœŸæ•°æ®æ ·æœ¬:")
            for stock in results['missing_early'][:5]:
                print(f"   {stock['stock_id']}: {stock['data_range']} (æœŸæœ›ä»{stock['expected_start']})")
        
        # è®¡ç®—å¯ç”¨æ€§è¯„ä¼°
        usable_count = complete_count + missing_recent_count  # ç¼ºå°‘è¿‘æœŸçš„ä¹ŸåŸºæœ¬å¯ç”¨
        usable_rate = usable_count / total_checked * 100
        
        print("\\nğŸ’¡ ç°å®è¯„ä¼°:")
        print(f"   ğŸ¯ åŸºæœ¬å¯ç”¨æ•°æ®: {usable_count} ({usable_rate:.1f}%)")
        print(f"   ğŸ“Š ä¼°ç®—50,658åªè‚¡ç¥¨ä¸­å¯ç”¨: ~{int(50658 * usable_rate / 100):,} åª")
        
        if usable_rate >= 80:
            print("   ğŸ† æ•°æ®è´¨é‡è¯„ä¼°: ä¼˜ç§€")
            print("   âœ… å»ºè®®: æ•°æ®å®Œå…¨æ»¡è¶³åˆ†æéœ€æ±‚")
        elif usable_rate >= 60:
            print("   ğŸŸ¡ æ•°æ®è´¨é‡è¯„ä¼°: è‰¯å¥½") 
            print("   ğŸ’¡ å»ºè®®: å¯ä»¥è¿›è¡Œå¤§éƒ¨åˆ†åˆ†æå·¥ä½œ")
        else:
            print("   ğŸ”´ æ•°æ®è´¨é‡è¯„ä¼°: éœ€è¦æ”¹è¿›")
            print("   âš ï¸ å»ºè®®: éœ€è¦è¡¥å……æˆ–ç­›é€‰æ•°æ®")

def main():
    """ä¸»å‡½æ•°"""
    checker = RealisticCompletenessChecker()
    checker.realistic_completeness_check(sample_size=150)

if __name__ == "__main__":
    main()