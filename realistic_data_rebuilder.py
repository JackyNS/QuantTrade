#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç°å®å¯è¡Œçš„Aè‚¡æ•°æ®é‡å»ºå™¨
è°ƒæ•´æ—¶é—´èŒƒå›´åˆ°2024å¹´12æœˆ31æ—¥ï¼Œåˆ†æ‰¹é«˜æ•ˆé‡å»º
"""

import sys
import pandas as pd
import numpy as np
from pathlib import Path
from datetime import datetime, timedelta
import warnings
import json
import time
import os
from io import StringIO
import concurrent.futures
from threading import Lock
warnings.filterwarnings('ignore')

try:
    import uqer
    print("âœ… UQER API å¯ç”¨")
    UQER_AVAILABLE = True
except ImportError:
    print("âŒ UQER API ä¸å¯ç”¨")
    UQER_AVAILABLE = False
    sys.exit(1)

class RealisticDataRebuilder:
    """ç°å®å¯è¡Œçš„æ•°æ®é‡å»ºå™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–é‡å»ºå™¨"""
        self.setup_uqer()
        self.setup_paths()
        self.setup_time_ranges()
        self.stats = {
            'start_time': datetime.now(),
            'total_stocks': 0,
            'successful_stocks': 0,
            'failed_stocks': 0,
            'total_api_calls': 0,
            'total_records': 0
        }
        
    def setup_uqer(self):
        """è®¾ç½®UQERè¿æ¥"""
        try:
            uqer_token = "68b9922817ae6273137bda7acba81e293582ba347281dfcc056dcb245b23faf3"
            uqer.Client(token=uqer_token)
            print("âœ… UQERæé€Ÿç‰ˆè¿æ¥æˆåŠŸ")
            self.uqer_connected = True
        except Exception as e:
            print(f"âŒ UQERè¿æ¥å¤±è´¥: {e}")
            self.uqer_connected = False
            sys.exit(1)
    
    def setup_paths(self):
        """è®¾ç½®è·¯å¾„"""
        # æ–°çš„ç°å®æ•°æ®è·¯å¾„
        self.base_path = Path("/Users/jackstudio/QuantTrade/data/realistic_complete")
        self.base_path.mkdir(exist_ok=True)
        
        # æŒ‰æ•°æ®ç±»å‹ç»„ç»‡
        self.data_types = {
            'daily': 'æ—¥çº¿æ•°æ®',
            'daily_adj': 'å‰å¤æƒæ—¥çº¿',
            'weekly': 'å‘¨çº¿æ•°æ®', 
            'weekly_adj': 'å‰å¤æƒå‘¨çº¿',
            'monthly': 'æœˆçº¿æ•°æ®',
            'monthly_adj': 'å‰å¤æƒæœˆçº¿'
        }
        
        # åˆ›å»ºç›®å½•ç»“æ„
        for data_type in self.data_types:
            type_path = self.base_path / data_type / "stocks"
            type_path.mkdir(parents=True, exist_ok=True)
            
        print(f"ğŸ“ ç°å®æ•°æ®é‡å»ºè·¯å¾„: {self.base_path}")
        
    def setup_time_ranges(self):
        """è®¾ç½®ç°å®çš„æ—¶é—´èŒƒå›´"""
        self.start_date = "20000101"  # 2000å¹´1æœˆ1æ—¥
        self.end_date = "20241231"    # 2024å¹´12æœˆ31æ—¥ (ç°å®å¯è¡Œ)
        
        print(f"ğŸ“… è°ƒæ•´åæ—¶é—´èŒƒå›´: {self.start_date} - {self.end_date}")
        print(f"ğŸ¯ ç›®æ ‡: è·å–å®é™…å­˜åœ¨çš„å†å²æ•°æ®ï¼Œä¸è¿½æ±‚æœªæ¥æ•°æ®")
    
    def get_active_stocks(self):
        """è·å–å½“å‰æ´»è·ƒAè‚¡åˆ—è¡¨"""
        print("ğŸ“‹ è·å–æ´»è·ƒAè‚¡è‚¡ç¥¨åˆ—è¡¨...")
        
        try:
            # è·å–å½“å‰ä¸Šå¸‚çš„Aè‚¡
            result = uqer.DataAPI.EquGet(
                listStatusCD="L",  # ä¸Šå¸‚çŠ¶æ€
                pandas=1
            )
            
            if isinstance(result, str):
                df = pd.read_csv(StringIO(result))
            else:
                df = result
                
            # ç­›é€‰Aè‚¡
            a_stocks = df[df['secID'].str.contains(r'\.(XSHE|XSHG)$', na=False)]
            
            print(f"   ğŸ“ˆ æ´»è·ƒAè‚¡: {len(a_stocks)} åª")
            
            # æŒ‰ä¸Šå¸‚æ—¶é—´æ’åºï¼Œä¼˜å…ˆå¤„ç†è€è‚¡ç¥¨
            if 'listDate' in a_stocks.columns:
                a_stocks['listDate'] = pd.to_datetime(a_stocks['listDate'])
                a_stocks = a_stocks.sort_values('listDate')
            
            return a_stocks['secID'].tolist()
            
        except Exception as e:
            print(f"âŒ è·å–è‚¡ç¥¨åˆ—è¡¨å¤±è´¥: {e}")
            return []
    
    def download_stock_data(self, stock_id, batch_id=1, total_stocks=1):
        """ä¸‹è½½å•åªè‚¡ç¥¨çš„æ‰€æœ‰æ—¶é—´å‘¨æœŸæ•°æ®"""
        
        api_mappings = {
            'daily': uqer.DataAPI.MktEqudGet,
            'daily_adj': uqer.DataAPI.MktEqudAdjGet,
            'weekly': uqer.DataAPI.MktEquwGet,
            'weekly_adj': uqer.DataAPI.MktEquwAdjGet,
            'monthly': uqer.DataAPI.MktEqumGet,
            'monthly_adj': uqer.DataAPI.MktEqumAdjGet
        }
        
        print(f"ğŸ“ˆ [{batch_id}/{total_stocks}] å¤„ç†: {stock_id}")
        
        success_count = 0
        total_records = 0
        
        for data_type, api_func in api_mappings.items():
            try:
                result = api_func(
                    secID=stock_id,
                    beginDate=self.start_date,
                    endDate=self.end_date,
                    pandas=1
                )
                
                self.stats['total_api_calls'] += 1
                
                if result is None:
                    continue
                
                # å¤„ç†APIè¿”å›æ•°æ®
                if isinstance(result, str):
                    df = pd.read_csv(StringIO(result))
                elif isinstance(result, pd.DataFrame):
                    df = result.copy()
                else:
                    continue
                
                if len(df) == 0:
                    continue
                
                # éªŒè¯æ—¶é—´èŒƒå›´ï¼ˆç°å®æ ‡å‡†ï¼‰
                if 'tradeDate' in df.columns:
                    df['tradeDate'] = pd.to_datetime(df['tradeDate'])
                    latest_date = df['tradeDate'].max()
                    
                    # æ”¾å®½æ—¶é—´è¦æ±‚ï¼šåªè¦æœ‰2023å¹´ä»¥åçš„æ•°æ®å°±è®¤ä¸ºæœ‰æ•ˆ
                    if latest_date >= pd.Timestamp('2023-01-01'):
                        # ä¿å­˜æ•°æ®
                        save_path = self.base_path / data_type / "stocks"
                        file_name = f"{stock_id.replace('.', '_')}.csv"
                        file_path = save_path / file_name
                        
                        df.to_csv(file_path, index=False, encoding='utf-8')
                        success_count += 1
                        total_records += len(df)
                        
                        print(f"   âœ… {data_type}: {len(df)} æ¡è®°å½• (åˆ° {latest_date.date()})")
                    else:
                        print(f"   âš ï¸ {data_type}: æ•°æ®è¿‡æ—§ (ä»…åˆ° {latest_date.date()})")
                
                time.sleep(0.1)  # é€‚å½“é™é€Ÿ
                
            except Exception as e:
                print(f"   âŒ {data_type}: ä¸‹è½½å¤±è´¥")
                continue
        
        if success_count > 0:
            print(f"   âœ… æˆåŠŸ: {success_count}/6 ä¸ªæ—¶é—´å‘¨æœŸï¼Œæ€»è®¡ {total_records} æ¡è®°å½•")
            self.stats['successful_stocks'] += 1
            self.stats['total_records'] += total_records
        else:
            print(f"   âŒ å¤±è´¥: 0/6 ä¸ªæ—¶é—´å‘¨æœŸæˆåŠŸ")
            self.stats['failed_stocks'] += 1
        
        return success_count > 0
    
    def rebuild_data_batch(self, stocks_list, batch_size=50):
        """åˆ†æ‰¹é‡å»ºæ•°æ®"""
        print(f"ğŸš€ å¼€å§‹ç°å®æ•°æ®é‡å»º")
        print(f"ğŸ“… æ—¶é—´èŒƒå›´: 2000å¹´1æœˆ1æ—¥ - 2024å¹´12æœˆ31æ—¥")
        print(f"ğŸ“Š è‚¡ç¥¨æ•°é‡: {len(stocks_list)}")
        print(f"ğŸ“¦ æ‰¹æ¬¡å¤§å°: {batch_size}")
        print("=" * 80)
        
        total_stocks = len(stocks_list)
        self.stats['total_stocks'] = total_stocks
        
        # åˆ†æ‰¹å¤„ç†
        for batch_start in range(0, total_stocks, batch_size):
            batch_end = min(batch_start + batch_size, total_stocks)
            batch_stocks = stocks_list[batch_start:batch_end]
            batch_num = batch_start // batch_size + 1
            
            print(f"\nğŸ“¦ ç¬¬{batch_num}æ‰¹: å¤„ç†ç¬¬{batch_start+1}-{batch_end}åªè‚¡ç¥¨")
            print("-" * 60)
            
            # å¤„ç†å½“å‰æ‰¹æ¬¡
            for i, stock_id in enumerate(batch_stocks, 1):
                global_index = batch_start + i
                self.download_stock_data(stock_id, global_index, total_stocks)
                
                # æ¯10åªæ˜¾ç¤ºè¿›åº¦
                if i % 10 == 0 or i == len(batch_stocks):
                    progress = (global_index / total_stocks) * 100
                    print(f"   ğŸ“ˆ æ‰¹æ¬¡è¿›åº¦: {i}/{len(batch_stocks)} | æ€»ä½“è¿›åº¦: {global_index}/{total_stocks} ({progress:.1f}%)")
            
            # æ‰¹æ¬¡é—´ä¼‘æ¯
            if batch_end < total_stocks:
                print(f"â¸ï¸ æ‰¹æ¬¡å®Œæˆï¼Œä¼‘æ¯30ç§’...")
                time.sleep(30)
        
        self.create_summary()
    
    def create_summary(self):
        """åˆ›å»ºé‡å»ºæ€»ç»“"""
        end_time = datetime.now()
        duration = end_time - self.stats['start_time']
        success_rate = (self.stats['successful_stocks'] / self.stats['total_stocks'] * 100) if self.stats['total_stocks'] > 0 else 0
        
        summary = {
            'realistic_rebuild_info': {
                'start_time': self.stats['start_time'].isoformat(),
                'end_time': end_time.isoformat(),
                'duration_minutes': round(duration.total_seconds() / 60, 2),
                'data_range': '2000å¹´1æœˆ1æ—¥ - 2024å¹´12æœˆ31æ—¥',
                'rebuild_strategy': 'ç°å®å¯è¡Œçš„å†å²æ•°æ®é‡å»º'
            },
            'statistics': {
                'total_stocks': self.stats['total_stocks'],
                'successful_stocks': self.stats['successful_stocks'],
                'failed_stocks': self.stats['failed_stocks'],
                'success_rate': f"{success_rate:.1f}%",
                'total_api_calls': self.stats['total_api_calls'],
                'total_records': self.stats['total_records']
            },
            'data_types': self.data_types,
            'file_structure': {
                'base_path': str(self.base_path),
                'organization': 'æŒ‰æ•°æ®ç±»å‹å’Œè‚¡ç¥¨ç»„ç»‡',
                'naming_convention': 'XXXXXX_XXXX.csv'
            }
        }
        
        # ä¿å­˜æ€»ç»“
        summary_file = self.base_path / 'realistic_rebuild_summary.json'
        with open(summary_file, 'w', encoding='utf-8') as f:
            json.dump(summary, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸŠ ç°å®æ•°æ®é‡å»ºå®Œæˆ!")
        print("=" * 80)
        print(f"ğŸ“Š é‡å»ºç»Ÿè®¡:")
        print(f"   ğŸ“ˆ å¤„ç†è‚¡ç¥¨: {summary['statistics']['total_stocks']}")
        print(f"   âœ… æˆåŠŸè‚¡ç¥¨: {summary['statistics']['successful_stocks']}")
        print(f"   âŒ å¤±è´¥è‚¡ç¥¨: {summary['statistics']['failed_stocks']}")
        print(f"   ğŸ¯ æˆåŠŸç‡: {summary['statistics']['success_rate']}")
        print(f"   ğŸ“ APIè°ƒç”¨: {summary['statistics']['total_api_calls']}")
        print(f"   ğŸ“‹ æ€»è®°å½•: {summary['statistics']['total_records']}")
        print(f"   â±ï¸ ç”¨æ—¶: {summary['realistic_rebuild_info']['duration_minutes']} åˆ†é’Ÿ")
        print(f"   ğŸ“ å­˜å‚¨ä½ç½®: {self.base_path}")
        print(f"   ğŸ“„ è¯¦ç»†æŠ¥å‘Š: {summary_file}")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”„ ç°å®å¯è¡Œçš„Aè‚¡æ•°æ®é‡å»ºå™¨")
    print("=" * 80)
    print("ğŸ¯ ç­–ç•¥: è°ƒæ•´æ—¶é—´èŒƒå›´åˆ°ç°å®å¯è¡Œçš„2024å¹´12æœˆ31æ—¥")
    print("ğŸ“¡ æ•°æ®æº: UQERæé€Ÿç‰ˆ (268ä¸ªAPI)")
    print("ğŸ—ï¸ é‡å»ºæ–¹å¼: åˆ†æ‰¹å¤„ç†ï¼Œä¼˜å…ˆæ´»è·ƒè‚¡ç¥¨")
    
    rebuilder = RealisticDataRebuilder()
    
    # è·å–æ´»è·ƒè‚¡ç¥¨åˆ—è¡¨
    stocks = rebuilder.get_active_stocks()
    
    if not stocks:
        print("âŒ æ— æ³•è·å–è‚¡ç¥¨åˆ—è¡¨")
        return
    
    # å¼€å§‹é‡å»º
    rebuilder.rebuild_data_batch(stocks, batch_size=50)

if __name__ == "__main__":
    main()