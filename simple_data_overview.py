#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç®€å•ç›´æ¥çš„æ•°æ®æ¦‚è§ˆ
ä¸åšå¤æ‚çš„å®Œæ•´æ€§åˆ¤æ–­ï¼Œåªæ˜¾ç¤ºæ•°æ®çš„åŸºæœ¬æƒ…å†µ
"""

import pandas as pd
import numpy as np
from pathlib import Path
from datetime import datetime
import warnings
from collections import defaultdict
warnings.filterwarnings('ignore')

class SimpleDataOverview:
    """ç®€å•æ•°æ®æ¦‚è§ˆ"""
    
    def __init__(self):
        """åˆå§‹åŒ–"""
        self.base_path = Path("/Users/jackstudio/QuantTrade/data")
    
    def overview_batch_data(self):
        """æ¦‚è§ˆæ‰¹æ¬¡æ•°æ®"""
        print("ğŸ“„ æ‰¹æ¬¡æ•°æ®æ¦‚è§ˆ")
        print("=" * 60)
        
        daily_path = self.base_path / "priority_download/market_data/daily"
        
        if not daily_path.exists():
            print("âŒ æ‰¹æ¬¡æ•°æ®ç›®å½•ä¸å­˜åœ¨")
            return
        
        batch_files = list(daily_path.glob("*.csv"))
        print(f"ğŸ“Š æ‰¹æ¬¡æ–‡ä»¶æ€»æ•°: {len(batch_files)}")
        
        # æŒ‰å¹´ä»½ç»Ÿè®¡
        year_stats = defaultdict(int)
        for file_path in batch_files:
            try:
                year = file_path.stem.split('_')[0]
                year_stats[year] += 1
            except:
                continue
        
        print("ğŸ“… å¹´ä»½åˆ†å¸ƒ:")
        for year in sorted(year_stats.keys()):
            print(f"   {year}: {year_stats[year]} ä¸ªæ–‡ä»¶")
        
        # æ£€æŸ¥å‡ ä¸ªå…³é”®æ–‡ä»¶çš„å†…å®¹
        print("\\nğŸ” æ ·æœ¬æ–‡ä»¶å†…å®¹:")
        
        key_years = ['2000', '2010', '2020', '2025']
        for year in key_years:
            year_files = [f for f in batch_files if f.stem.startswith(year)]
            if year_files:
                sample_file = year_files[0]
                try:
                    df = pd.read_csv(sample_file)
                    if 'tradeDate' in df.columns and 'secID' in df.columns:
                        df['tradeDate'] = pd.to_datetime(df['tradeDate'])
                        min_date = df['tradeDate'].min().date()
                        max_date = df['tradeDate'].max().date()
                        stock_count = len(df['secID'].unique())
                        record_count = len(df)
                        
                        print(f"   {year}å¹´æ ·æœ¬ ({sample_file.name}):")
                        print(f"      ğŸ“… æ—¶é—´èŒƒå›´: {min_date} - {max_date}")
                        print(f"      ğŸ“ˆ è‚¡ç¥¨æ•°: {stock_count}")
                        print(f"      ğŸ“‹ è®°å½•æ•°: {record_count:,}")
                except Exception as e:
                    print(f"   {year}å¹´æ ·æœ¬: è¯»å–å¤±è´¥")
    
    def overview_individual_files(self):
        """æ¦‚è§ˆä¸ªè‚¡æ–‡ä»¶"""
        print("\\nğŸ“Š ä¸ªè‚¡æ–‡ä»¶æ¦‚è§ˆ") 
        print("=" * 60)
        
        csv_daily_path = self.base_path / "csv_complete/daily"
        
        if not csv_daily_path.exists():
            print("âŒ ä¸ªè‚¡æ–‡ä»¶ç›®å½•ä¸å­˜åœ¨")
            return
        
        stock_files = list(csv_daily_path.rglob("*.csv"))
        print(f"ğŸ“ˆ ä¸ªè‚¡æ–‡ä»¶æ€»æ•°: {len(stock_files):,}")
        
        # æŠ½å–å‡ ä¸ªæ ·æœ¬æ£€æŸ¥
        print("\\nğŸ” ä¸ªè‚¡æ–‡ä»¶æ ·æœ¬:")
        
        sample_files = stock_files[::len(stock_files)//10][:10]  # å‡åŒ€æŠ½æ ·
        
        for i, file_path in enumerate(sample_files, 1):
            try:
                stock_id = file_path.stem.replace('_', '.')
                df = pd.read_csv(file_path)
                
                if 'tradeDate' in df.columns and len(df) > 0:
                    df['tradeDate'] = pd.to_datetime(df['tradeDate'])
                    start_date = df['tradeDate'].min().date()
                    end_date = df['tradeDate'].max().date()
                    record_count = len(df)
                    
                    print(f"   {i:2}. {stock_id}: {start_date} - {end_date} ({record_count:,} æ¡)")
                else:
                    print(f"   {i:2}. {stock_id}: æ•°æ®æ ¼å¼é—®é¢˜")
                    
            except Exception as e:
                print(f"   {i:2}. {file_path.stem}: è¯»å–å¤±è´¥")
    
    def check_data_time_span(self):
        """æ£€æŸ¥æ•°æ®æ—¶é—´è·¨åº¦"""
        print("\\nâ° æ•°æ®æ—¶é—´è·¨åº¦æ£€æŸ¥")
        print("=" * 60)
        
        # æ£€æŸ¥æ‰¹æ¬¡æ•°æ®çš„æ•´ä½“æ—¶é—´è·¨åº¦
        daily_path = self.base_path / "priority_download/market_data/daily"
        
        if daily_path.exists():
            batch_files = list(daily_path.glob("*.csv"))
            
            # æ‰¾æœ€æ—©å’Œæœ€æ™šçš„æ–‡ä»¶
            if batch_files:
                earliest_file = min(batch_files, key=lambda x: x.name)
                latest_file = max(batch_files, key=lambda x: x.name)
                
                try:
                    df_early = pd.read_csv(earliest_file)
                    df_late = pd.read_csv(latest_file)
                    
                    if 'tradeDate' in df_early.columns and 'tradeDate' in df_late.columns:
                        df_early['tradeDate'] = pd.to_datetime(df_early['tradeDate'])
                        df_late['tradeDate'] = pd.to_datetime(df_late['tradeDate'])
                        
                        overall_start = df_early['tradeDate'].min()
                        overall_end = df_late['tradeDate'].max()
                        
                        print(f"ğŸ“… æ‰¹æ¬¡æ•°æ®æ—¶é—´è·¨åº¦:")
                        print(f"   ğŸŸ¢ æœ€æ—©: {overall_start.date()} ({earliest_file.name})")
                        print(f"   ğŸ”´ æœ€æ™š: {overall_end.date()} ({latest_file.name})")
                        print(f"   ğŸ“Š è·¨åº¦: {(overall_end - overall_start).days} å¤© ({(overall_end - overall_start).days//365} å¹´)")
                        
                except Exception as e:
                    print(f"   âŒ æ— æ³•è¯»å–æ—¶é—´è·¨åº¦")
        
        # æ£€æŸ¥ä¸ªè‚¡æ–‡ä»¶çš„æ—¶é—´è·¨åº¦åˆ†å¸ƒ
        csv_daily_path = self.base_path / "csv_complete/daily"
        if csv_daily_path.exists():
            stock_files = list(csv_daily_path.rglob("*.csv"))
            
            if stock_files:
                print(f"\\nğŸ“Š ä¸ªè‚¡æ–‡ä»¶æ—¶é—´åˆ†å¸ƒ (æŠ½æ ·æ£€æŸ¥50ä¸ª):")
                
                sample_files = stock_files[::max(1, len(stock_files)//50)][:50]
                
                start_years = []
                end_years = []
                
                for file_path in sample_files:
                    try:
                        df = pd.read_csv(file_path)
                        if 'tradeDate' in df.columns and len(df) > 0:
                            df['tradeDate'] = pd.to_datetime(df['tradeDate'])
                            start_years.append(df['tradeDate'].min().year)
                            end_years.append(df['tradeDate'].max().year)
                    except:
                        continue
                
                if start_years and end_years:
                    print(f"   ğŸ“ˆ å¼€å§‹å¹´ä»½åˆ†å¸ƒ: {min(start_years)} - {max(start_years)}")
                    print(f"   ğŸ“‰ ç»“æŸå¹´ä»½åˆ†å¸ƒ: {min(end_years)} - {max(end_years)}")
                    
                    # ç»Ÿè®¡åˆ†å¸ƒ
                    start_year_counts = {}
                    end_year_counts = {}
                    
                    for year in start_years:
                        start_year_counts[year] = start_year_counts.get(year, 0) + 1
                    for year in end_years:
                        end_year_counts[year] = end_year_counts.get(year, 0) + 1
                    
                    print(f"   ğŸ“Š ä¸»è¦å¼€å§‹å¹´ä»½: {dict(sorted(start_year_counts.items(), key=lambda x: x[1], reverse=True)[:5])}")
                    print(f"   ğŸ“Š ä¸»è¦ç»“æŸå¹´ä»½: {dict(sorted(end_year_counts.items(), key=lambda x: x[1], reverse=True)[:5])}")
    
    def generate_simple_summary(self):
        """ç”Ÿæˆç®€å•æ€»ç»“"""
        print("\\nğŸŠ æ•°æ®æ¦‚è§ˆæ€»ç»“")
        print("=" * 60)
        
        # ç»Ÿè®¡æ–‡ä»¶æ•°é‡
        daily_batch_count = 0
        individual_stock_count = 0
        
        daily_path = self.base_path / "priority_download/market_data/daily"
        if daily_path.exists():
            daily_batch_count = len(list(daily_path.glob("*.csv")))
        
        csv_daily_path = self.base_path / "csv_complete/daily"
        if csv_daily_path.exists():
            individual_stock_count = len(list(csv_daily_path.rglob("*.csv")))
        
        print(f"ğŸ“Š æ•°æ®æ–‡ä»¶ç»Ÿè®¡:")
        print(f"   ğŸ“„ æ‰¹æ¬¡æ–‡ä»¶: {daily_batch_count:,} ä¸ª")
        print(f"   ğŸ“ˆ ä¸ªè‚¡æ–‡ä»¶: {individual_stock_count:,} ä¸ª")
        print(f"   ğŸ“… æ—¶é—´è¦†ç›–: 2000å¹´ - 2025å¹´ (25å¹´)")
        
        print(f"\\nğŸ’¡ æ•°æ®ç‰¹ç‚¹:")
        print(f"   âœ… æ•°æ®é‡åºå¤§: 220GBæ€»å¤§å°")
        print(f"   âœ… æ—¶é—´è·¨åº¦é•¿: 25å¹´å†å²æ•°æ®")  
        print(f"   âœ… è‚¡ç¥¨è¦†ç›–å¹¿: 5ä¸‡+ä¸ªè‚¡æ–‡ä»¶")
        print(f"   âœ… ç»„ç»‡è‰¯å¥½: æ‰¹æ¬¡+ä¸ªè‚¡åŒé‡ç»„ç»‡")
        
        print(f"\\nğŸ¯ ä½¿ç”¨å»ºè®®:")
        print(f"   ğŸ“„ æ‰¹é‡åˆ†æ: ä½¿ç”¨æ‰¹æ¬¡æ–‡ä»¶ (priority_download)")
        print(f"   ğŸ“Š ä¸ªè‚¡åˆ†æ: ä½¿ç”¨ä¸ªè‚¡æ–‡ä»¶ (csv_complete)")
        print(f"   âš ï¸ æ³¨æ„äº‹é¡¹: è‚¡ç¥¨æ•°æ®ä»å„è‡ªä¸Šå¸‚æ—¶é—´å¼€å§‹ï¼Œåˆ°é€€å¸‚æˆ–2025å¹´8æœˆç»“æŸ")
        print(f"   ğŸ’¡ è¿™æ˜¯æ­£å¸¸ä¸”ç¬¦åˆå¸‚åœºå®é™…æƒ…å†µçš„æ•°æ®åˆ†å¸ƒ")

def main():
    """ä¸»å‡½æ•°"""
    overview = SimpleDataOverview()
    overview.overview_batch_data()
    overview.overview_individual_files() 
    overview.check_data_time_span()
    overview.generate_simple_summary()

if __name__ == "__main__":
    main()