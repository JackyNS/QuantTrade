#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç®€å•æ•°æ®ä¸‹è½½ç¤ºä¾‹
==============

æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨ç»Ÿä¸€æ•°æ®æ¶æ„ä¸‹è½½æ•°æ®çš„æœ€ç®€å•æ–¹æ³•
"""

import pandas as pd
import numpy as np
from pathlib import Path

def test_direct_component_usage():
    """ç›´æ¥ä½¿ç”¨ç»„ä»¶è¿›è¡Œæ•°æ®ä¸‹è½½æµ‹è¯•"""
    print("ğŸš€ ç›´æ¥ç»„ä»¶ä½¿ç”¨æµ‹è¯•")
    print("=" * 40)
    
    try:
        # ç›´æ¥å¯¼å…¥ä¸‹è½½å™¨ï¼Œé¿å…å¤æ‚åˆå§‹åŒ–
        from core.data.downloaders.a_shares_downloader import ASharesDownloader
        
        print("âœ… Aè‚¡ä¸‹è½½å™¨å¯¼å…¥æˆåŠŸ")
        
        # ç®€å•é…ç½®
        config = {
            'data_dir': './data',
            'batch_size': 10,
            'delay': 0.1,
            'max_retry': 2
        }
        
        # åˆ›å»ºä¸‹è½½å™¨å®ä¾‹
        downloader = ASharesDownloader(config)
        print("âœ… Aè‚¡ä¸‹è½½å™¨åˆ›å»ºæˆåŠŸ")
        
        # æ£€æŸ¥æ•°æ®ç›®å½•
        data_dir = Path('./data')
        if not data_dir.exists():
            data_dir.mkdir(parents=True, exist_ok=True)
            print("ğŸ“ åˆ›å»ºæ•°æ®ç›®å½•")
        
        existing_files = list(data_dir.glob('*.csv'))
        print(f"ğŸ“Š ç°æœ‰CSVæ–‡ä»¶æ•°é‡: {len(existing_files)}")
        
        if len(existing_files) > 0:
            print("ğŸ“„ éƒ¨åˆ†ç°æœ‰æ–‡ä»¶:")
            for i, file in enumerate(existing_files[:5]):
                size = file.stat().st_size / 1024  # KB
                print(f"   {file.name} ({size:.1f} KB)")
            if len(existing_files) > 5:
                print(f"   ... è¿˜æœ‰ {len(existing_files) - 5} ä¸ªæ–‡ä»¶")
        
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        return False

def test_data_processing():
    """æµ‹è¯•æ•°æ®å¤„ç†åŠŸèƒ½"""
    print("\nğŸ”§ æ•°æ®å¤„ç†åŠŸèƒ½æµ‹è¯•")
    print("=" * 40)
    
    try:
        from core.data.processors.data_processor import DataProcessor
        from core.data.processors.data_cleaner import DataCleaner
        from core.data.processors.data_transformer import DataTransformer
        
        print("âœ… å¤„ç†å™¨å¯¼å…¥æˆåŠŸ")
        
        # åˆ›å»ºç¤ºä¾‹æ•°æ®
        sample_data = pd.DataFrame({
            'date': pd.date_range('2024-01-01', periods=10),
            'open': np.random.uniform(10, 20, 10),
            'high': np.random.uniform(15, 25, 10), 
            'low': np.random.uniform(8, 18, 10),
            'close': np.random.uniform(10, 20, 10),
            'volume': np.random.randint(1000, 10000, 10)
        })
        
        print(f"ğŸ“Š åˆ›å»ºç¤ºä¾‹æ•°æ®: {sample_data.shape}")
        
        # æµ‹è¯•æ•°æ®æ¸…æ´—
        cleaner = DataCleaner()
        cleaned_data = cleaner.clean_price_data(sample_data)
        print(f"ğŸ§¹ æ•°æ®æ¸…æ´—å®Œæˆ: {cleaned_data.shape}")
        
        # æµ‹è¯•æ•°æ®è½¬æ¢
        transformer = DataTransformer()
        transformed_data = transformer.standardize_columns(sample_data)
        print(f"ğŸ”„ æ•°æ®è½¬æ¢å®Œæˆ: {list(transformed_data.columns)}")
        
        # æµ‹è¯•ç»Ÿä¸€å¤„ç†å™¨
        processor = DataProcessor()
        processed_data = processor.process_price_data(sample_data, symbol='TEST')
        print(f"âš™ï¸ ç»Ÿä¸€å¤„ç†å®Œæˆ: {processed_data.shape}")
        
        return True
        
    except Exception as e:
        print(f"âŒ æ•°æ®å¤„ç†æµ‹è¯•å¤±è´¥: {e}")
        return False

def show_next_steps():
    """æ˜¾ç¤ºåç»­æ­¥éª¤"""
    print("""
ğŸ¯ åç»­ä½¿ç”¨æ­¥éª¤
==============

1. ğŸ“¥ æ•°æ®ä¸‹è½½æ–¹å¼:

   æ–¹å¼ä¸€ - ä½¿ç”¨ç»Ÿä¸€ç®¡ç†å™¨:
   ```python
   from core.data.enhanced_data_manager import EnhancedDataManager
   
   config = {'data_dir': './data'}
   dm = EnhancedDataManager(config)
   
   # ä¸‹è½½Aè‚¡æ•°æ®
   result = dm.download_a_shares_data(['000001.SZ', '000002.SZ'])
   ```

   æ–¹å¼äºŒ - ç›´æ¥ä½¿ç”¨ä¸‹è½½å™¨:
   ```python
   from core.data.downloaders.a_shares_downloader import ASharesDownloader
   
   downloader = ASharesDownloader(config)
   result = downloader.download_batch(['000001.SZ', '000002.SZ'])
   ```

2. ğŸ”§ æ•°æ®å¤„ç†:
   ```python
   from core.data.processors import DataProcessor
   
   processor = DataProcessor()
   clean_data = processor.process_price_data(raw_data, 'symbol')
   ```

3. ğŸ“Š è·å–æ•°æ®:
   ```python
   # å¦‚æœæ‚¨å·²æœ‰æ•°æ®æ–‡ä»¶ï¼Œå¯ä»¥ç›´æ¥è¯»å–
   import pandas as pd
   data = pd.read_csv('./data/000001.SZ.csv')
   ```

4. âš™ï¸ é…ç½®APIå¯†é’¥ (å¯é€‰ï¼Œç”¨äºè‡ªåŠ¨ä¸‹è½½):
   - Tushare: https://tushare.pro/
   - ä¼˜çŸ¿: https://uqer.datayes.com/
   
   é…ç½®ç¤ºä¾‹:
   ```python
   config = {
       'tushare': {'token': 'your_token_here'},
       'uqer': {'token': 'your_token_here'}
   }
   ```

5. ğŸ“ˆ å¼€å§‹é‡åŒ–äº¤æ˜“:
   æœ‰äº†æ•°æ®åï¼Œæ‚¨å¯ä»¥å¼€å§‹ç­–ç•¥å¼€å‘ã€å›æµ‹ç­‰å·¥ä½œ

ğŸ“– è¯¦ç»†æ–‡æ¡£: core/data/UNIFIED_DATA_USAGE.md
""")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ ç®€å•æ•°æ®ä¸‹è½½ç¤ºä¾‹")
    print("=" * 50)
    
    success_count = 0
    
    # æµ‹è¯•ç›´æ¥ç»„ä»¶ä½¿ç”¨
    if test_direct_component_usage():
        success_count += 1
    
    # æµ‹è¯•æ•°æ®å¤„ç†
    if test_data_processing():
        success_count += 1
    
    print("\n" + "=" * 50)
    print(f"ğŸ“Š æµ‹è¯•ç»“æœ: {success_count}/2 é¡¹æµ‹è¯•é€šè¿‡")
    
    if success_count >= 1:
        print("ğŸ‰ åŸºç¡€åŠŸèƒ½å¯ä»¥æ­£å¸¸ä½¿ç”¨ï¼")
        show_next_steps()
    else:
        print("âš ï¸ éœ€è¦æ£€æŸ¥é…ç½®æˆ–ä¾èµ–")
    
    print("=" * 50)

if __name__ == "__main__":
    main()