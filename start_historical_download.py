#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¯åŠ¨å†å²æ•°æ®ä¸‹è½½ - ä»2000å¹´è‡³ä»Š
"""

import uqer
import pandas as pd
from datetime import datetime, date
from pathlib import Path
import time
import logging
import json

# é…ç½®
UQER_TOKEN = "68b9922817ae6273137bda7acba81e293582ba347281dfcc056dcb245b23faf3"
DATA_DIR = Path("data/historical_download")
DATA_DIR.mkdir(parents=True, exist_ok=True)

# æ—¥å¿—é…ç½®
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler(DATA_DIR / 'download.log'),
        logging.StreamHandler()
    ]
)

class HistoricalDataDownloader:
    """å†å²æ•°æ®ä¸‹è½½å™¨"""
    
    def __init__(self):
        self.client = uqer.Client(token=UQER_TOKEN)
        self.start_date = "20000101"
        self.end_date = datetime.now().strftime('%Y%m%d')
        
        logging.info(f"ğŸš€ åˆå§‹åŒ–å†å²æ•°æ®ä¸‹è½½å™¨")
        logging.info(f"ğŸ“… ä¸‹è½½æ—¶é—´èŒƒå›´: {self.start_date} - {self.end_date}")
    
    def get_active_stocks(self):
        """è·å–æ´»è·ƒè‚¡ç¥¨åˆ—è¡¨"""
        logging.info("ğŸ“‹ è·å–è‚¡ç¥¨åˆ—è¡¨...")
        
        try:
            stocks = uqer.DataAPI.EquGet(
                field='secID,ticker,secShortName,exchangeCD,listStatusCD,listDate'
            )
            
            if stocks is not None and not stocks.empty:
                # è¿‡æ»¤Aè‚¡
                a_stocks = stocks[stocks['listStatusCD'] == 'L'].copy()
                
                # æŒ‰äº¤æ˜“æ‰€åˆ†ç±»
                sh_stocks = a_stocks[a_stocks['exchangeCD'] == 'XSHG']
                sz_stocks = a_stocks[a_stocks['exchangeCD'] == 'XSHE'] 
                
                logging.info(f"âœ… è·å–è‚¡ç¥¨åˆ—è¡¨æˆåŠŸ:")
                logging.info(f"   ğŸ“ˆ æ²ªå¸‚: {len(sh_stocks)} åª")
                logging.info(f"   ğŸ“Š æ·±å¸‚: {len(sz_stocks)} åª")
                logging.info(f"   ğŸ“¦ æ€»è®¡: {len(a_stocks)} åª")
                
                # ä¿å­˜è‚¡ç¥¨åˆ—è¡¨
                stock_file = DATA_DIR / "stock_universe.csv"
                a_stocks.to_csv(stock_file, index=False)
                
                return a_stocks
            else:
                logging.error("âŒ è·å–è‚¡ç¥¨åˆ—è¡¨å¤±è´¥")
                return None
                
        except Exception as e:
            logging.error(f"âŒ è·å–è‚¡ç¥¨åˆ—è¡¨å¼‚å¸¸: {e}")
            return None
    
    def test_market_data_download(self):
        """æµ‹è¯•å¸‚åœºæ•°æ®ä¸‹è½½"""
        logging.info("ğŸ§ª æµ‹è¯•å¸‚åœºæ•°æ®ä¸‹è½½...")
        
        try:
            # æµ‹è¯•ä¸‹è½½æœ€è¿‘çš„äº¤æ˜“æ—¥æ•°æ®
            test_start = "20240830"
            test_end = "20240830"
            
            # é€‰æ‹©å‡ åªä»£è¡¨æ€§è‚¡ç¥¨æµ‹è¯•
            test_tickers = "000001.XSHE,600000.XSHG,000002.XSHE,600036.XSHG"
            
            logging.info(f"ğŸ“Š æµ‹è¯•ä¸‹è½½: {test_start} - {test_end}")
            logging.info(f"ğŸ¯ æµ‹è¯•è‚¡ç¥¨: {test_tickers}")
            
            # è°ƒç”¨API
            data = uqer.DataAPI.MktEqudGet(
                secID='',
                ticker=test_tickers,
                beginDate=test_start,
                endDate=test_end,
                field='secID,ticker,tradeDate,preClosePrice,openPrice,highestPrice,lowestPrice,closePrice,turnoverVol,marketValue,dealAmount,turnoverRate'
            )
            
            if data is not None and not data.empty:
                logging.info(f"âœ… æµ‹è¯•ä¸‹è½½æˆåŠŸ!")
                logging.info(f"   ğŸ“Š æ•°æ®é‡: {len(data)} æ¡è®°å½•")
                logging.info(f"   ğŸ“… æ—¥æœŸèŒƒå›´: {data['tradeDate'].min()} - {data['tradeDate'].max()}")
                logging.info(f"   ğŸ¯ è‚¡ç¥¨æ•°: {data['ticker'].nunique()} åª")
                
                # ä¿å­˜æµ‹è¯•æ•°æ®
                test_file = DATA_DIR / "test_download.csv"
                data.to_csv(test_file, index=False)
                
                # æ˜¾ç¤ºæ ·æœ¬æ•°æ®
                logging.info("ğŸ“„ æ ·æœ¬æ•°æ®:")
                print(data.head().to_string(index=False))
                
                return True
            else:
                logging.warning("âš ï¸ æµ‹è¯•ä¸‹è½½æ•°æ®ä¸ºç©º")
                return False
                
        except Exception as e:
            logging.error(f"âŒ æµ‹è¯•ä¸‹è½½å¤±è´¥: {e}")
            return False
    
    def download_stock_basics(self):
        """ä¸‹è½½è‚¡ç¥¨åŸºç¡€ä¿¡æ¯"""
        logging.info("ğŸ“‹ ä¸‹è½½è‚¡ç¥¨åŸºç¡€ä¿¡æ¯...")
        
        basics_dir = DATA_DIR / "basics"
        basics_dir.mkdir(exist_ok=True)
        
        basic_apis = {
            "EquGet": "è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯",
            "EquIPOGet": "IPOä¿¡æ¯", 
            "EquIndustryGet": "è¡Œä¸šåˆ†ç±»",
            "EquDivGet": "åˆ†çº¢ä¿¡æ¯"
        }
        
        results = {}
        
        for api_name, description in basic_apis.items():
            try:
                logging.info(f"ğŸ“¥ ä¸‹è½½ {description}...")
                
                api_func = getattr(uqer.DataAPI, api_name, None)
                if not api_func:
                    logging.warning(f"âš ï¸ API {api_name} ä¸å­˜åœ¨")
                    continue
                
                # è°ƒç”¨API
                if api_name == "EquIndustryGet":
                    # è¡Œä¸šåˆ†ç±»éœ€è¦æ—¥æœŸå‚æ•°
                    data = api_func(
                        intoDate=self.end_date,
                        field=''
                    )
                elif api_name == "EquDivGet":
                    # åˆ†çº¢ä¿¡æ¯éœ€è¦æ—¥æœŸèŒƒå›´
                    data = api_func(
                        beginDate=self.start_date,
                        endDate=self.end_date
                    )
                else:
                    data = api_func()
                
                if data is not None and not data.empty:
                    # ä¿å­˜æ•°æ®
                    file_path = basics_dir / f"{api_name}.csv"
                    data.to_csv(file_path, index=False)
                    
                    logging.info(f"âœ… {description}: {len(data)} æ¡è®°å½•")
                    results[api_name] = len(data)
                else:
                    logging.warning(f"âš ï¸ {description}: æ•°æ®ä¸ºç©º")
                    results[api_name] = 0
                
                # APIé™åˆ¶å»¶è¿Ÿ
                time.sleep(0.5)
                
            except Exception as e:
                logging.error(f"âŒ {description} ä¸‹è½½å¤±è´¥: {e}")
                results[api_name] = -1
                continue
        
        logging.info(f"ğŸ“Š åŸºç¡€ä¿¡æ¯ä¸‹è½½å®Œæˆ: {results}")
        return results
    
    def start_batch_historical_download(self):
        """å¼€å§‹æ‰¹é‡å†å²æ•°æ®ä¸‹è½½"""
        logging.info("ğŸš€ å¼€å§‹æ‰¹é‡å†å²æ•°æ®ä¸‹è½½...")
        
        # 1. è·å–è‚¡ç¥¨åˆ—è¡¨
        stocks = self.get_active_stocks()
        if stocks is None:
            logging.error("âŒ æ— æ³•è·å–è‚¡ç¥¨åˆ—è¡¨ï¼Œç»ˆæ­¢ä¸‹è½½")
            return False
        
        # 2. æµ‹è¯•ä¸‹è½½ï¼ˆå¦‚æœæµ‹è¯•å¤±è´¥ä¹Ÿç»§ç»­ï¼Œå› ä¸ºå¯èƒ½æ˜¯æ—¥æœŸé—®é¢˜ï¼‰
        test_result = self.test_market_data_download()
        if test_result:
            logging.info("âœ… æµ‹è¯•ä¸‹è½½æˆåŠŸï¼Œå¼€å§‹æ­£å¼ä¸‹è½½")
        else:
            logging.warning("âš ï¸ æµ‹è¯•ä¸‹è½½å¤±è´¥ï¼Œä½†ç»§ç»­å°è¯•æ­£å¼ä¸‹è½½ï¼ˆå¯èƒ½æ˜¯æ—¥æœŸé—®é¢˜ï¼‰")
        
        # 3. ä¸‹è½½åŸºç¡€ä¿¡æ¯
        basics_result = self.download_stock_basics()
        
        # 4. å¼€å§‹å†å²è¡Œæƒ…ä¸‹è½½
        return self._download_historical_market_data(stocks)
    
    def _download_historical_market_data(self, stocks):
        """ä¸‹è½½å†å²å¸‚åœºæ•°æ®"""
        logging.info("ğŸ“ˆ å¼€å§‹ä¸‹è½½å†å²å¸‚åœºæ•°æ®...")
        
        # åˆ›å»ºå¸‚åœºæ•°æ®ç›®å½•
        market_dir = DATA_DIR / "market_data"
        market_dir.mkdir(exist_ok=True)
        
        # åˆ†å¹´åº¦ä¸‹è½½ï¼Œé¿å…å•æ¬¡è¯·æ±‚æ•°æ®è¿‡å¤§
        start_year = 2000
        end_year = datetime.now().year
        
        total_success = 0
        total_failed = 0
        
        for year in range(start_year, end_year + 1):
            year_start = f"{year}0101"
            year_end = f"{year}1231"
            
            logging.info(f"ğŸ“… ä¸‹è½½ {year} å¹´æ•°æ®...")
            
            success, failed = self._download_year_data(stocks, year_start, year_end, market_dir)
            total_success += success
            total_failed += failed
            
            # å¹´åº¦é—´éš”
            time.sleep(1)
        
        logging.info(f"ğŸ“Š å†å²æ•°æ®ä¸‹è½½å®Œæˆ:")
        logging.info(f"   âœ… æˆåŠŸ: {total_success} æ‰¹æ¬¡")
        logging.info(f"   âŒ å¤±è´¥: {total_failed} æ‰¹æ¬¡")
        
        return total_success > 0
    
    def _download_year_data(self, stocks, start_date, end_date, market_dir):
        """ä¸‹è½½å¹´åº¦æ•°æ®"""
        year = start_date[:4]
        year_dir = market_dir / f"year_{year}"
        year_dir.mkdir(exist_ok=True)
        
        # åˆ†æ‰¹å¤„ç†è‚¡ç¥¨ï¼Œæ¯æ‰¹50åª
        batch_size = 50
        batches = [stocks[i:i+batch_size] for i in range(0, len(stocks), batch_size)]
        
        success_count = 0
        failed_count = 0
        
        for batch_idx, batch_stocks in enumerate(batches):
            batch_file = year_dir / f"batch_{batch_idx+1:03d}.csv"
            
            # å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ï¼Œè·³è¿‡
            if batch_file.exists():
                logging.info(f"ğŸ“‚ {year} æ‰¹æ¬¡ {batch_idx+1} å·²å­˜åœ¨ï¼Œè·³è¿‡")
                success_count += 1
                continue
            
            try:
                # æ„å»ºtickeråˆ—è¡¨
                tickers = ','.join(batch_stocks['ticker'].tolist())
                
                logging.info(f"ğŸ“¥ {year} æ‰¹æ¬¡ {batch_idx+1}/{len(batches)}: {len(batch_stocks)} åªè‚¡ç¥¨")
                
                # ä¸‹è½½æ•°æ®
                data = uqer.DataAPI.MktEqudGet(
                    secID='',
                    ticker=tickers,
                    beginDate=start_date,
                    endDate=end_date,
                    field='secID,ticker,tradeDate,preClosePrice,openPrice,highestPrice,lowestPrice,closePrice,turnoverVol,marketValue,dealAmount,turnoverRate'
                )
                
                if data is not None and not data.empty:
                    # ä¿å­˜æ•°æ®
                    data.to_csv(batch_file, index=False)
                    
                    logging.info(f"âœ… {year} æ‰¹æ¬¡ {batch_idx+1}: {len(data)} æ¡è®°å½•")
                    success_count += 1
                else:
                    logging.warning(f"âš ï¸ {year} æ‰¹æ¬¡ {batch_idx+1}: æ•°æ®ä¸ºç©º")
                    failed_count += 1
                
                # APIé™åˆ¶å»¶è¿Ÿ
                time.sleep(0.3)
                
            except Exception as e:
                logging.error(f"âŒ {year} æ‰¹æ¬¡ {batch_idx+1} å¤±è´¥: {e}")
                failed_count += 1
                time.sleep(1)  # é”™è¯¯æ—¶å»¶é•¿ç­‰å¾…
                continue
        
        logging.info(f"ğŸ“Š {year} å¹´å®Œæˆ: æˆåŠŸ {success_count}, å¤±è´¥ {failed_count}")
        return success_count, failed_count

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹ä»2000å¹´è‡³ä»Šçš„å†å²æ•°æ®ä¸‹è½½")
    print("=" * 60)
    
    # åˆ›å»ºä¸‹è½½å™¨
    downloader = HistoricalDataDownloader()
    
    # å¼€å§‹ä¸‹è½½
    success = downloader.start_batch_historical_download()
    
    if success:
        print("\nğŸ‰ å†å²æ•°æ®ä¸‹è½½å¯åŠ¨æˆåŠŸ!")
        print(f"ğŸ“ æ•°æ®ä¿å­˜ç›®å½•: {DATA_DIR}")
        print(f"ğŸ“‹ æŸ¥çœ‹æ—¥å¿—: {DATA_DIR}/download.log")
    else:
        print("\nâŒ å†å²æ•°æ®ä¸‹è½½å¯åŠ¨å¤±è´¥")
    
    return success

if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)