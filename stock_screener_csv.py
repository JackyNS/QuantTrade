#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åŸºäºCSVæ•°æ®çš„åå‘¨çº¿ä¸Šç©¿ç™¾å‘¨çº¿è‚¡ç¥¨ç­›é€‰å™¨
ä½¿ç”¨æœ¬åœ°CSVè‚¡ç¥¨æ•°æ®è¿›è¡Œç­›é€‰åˆ†æ
"""

import sys
import pandas as pd
import numpy as np
from pathlib import Path
from datetime import datetime, timedelta
import warnings
import json
import os
warnings.filterwarnings('ignore')

try:
    import talib
    print("âœ… TA-Lib å¯ç”¨")
except ImportError:
    print("âŒ TA-Lib ä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨pandasè®¡ç®—")
    talib = None

class CSVStockScreener:
    """åŸºäºCSVæ•°æ®çš„è‚¡ç¥¨ç­›é€‰å™¨"""
    
    def __init__(self, data_root_path="/Users/jackstudio/QuantTrade/data"):
        """
        åˆå§‹åŒ–ç­›é€‰å™¨
        
        Args:
            data_root_path: æ•°æ®æ ¹ç›®å½•
        """
        self.data_root = Path(data_root_path)
        self.results = []
        
        print(f"ğŸ“ æ•°æ®æ ¹ç›®å½•: {self.data_root}")
        
        # æŸ¥æ‰¾è‚¡ç¥¨ç›¸å…³çš„CSVæ•°æ®
        self.find_stock_csv_files()
    
    def find_stock_csv_files(self):
        """æŸ¥æ‰¾è‚¡ç¥¨CSVæ•°æ®æ–‡ä»¶"""
        print("ğŸ” æŸ¥æ‰¾è‚¡ç¥¨CSVæ•°æ®æ–‡ä»¶...")
        
        # æŸ¥æ‰¾åŒ…å«è‚¡ç¥¨æ•°æ®çš„ç›®å½•
        stock_patterns = ['*mktequd*', '*equity*', '*stock*', '*market*']
        
        self.stock_files = []
        
        for pattern in stock_patterns:
            matching_dirs = list(self.data_root.glob(f"**/{pattern}"))
            for dir_path in matching_dirs:
                if dir_path.is_dir():
                    csv_files = list(dir_path.glob("*.csv"))
                    if csv_files:
                        self.stock_files.extend(csv_files)
                        print(f"   ğŸ“‚ {dir_path.name}: {len(csv_files)} CSVæ–‡ä»¶")
        
        # å»é‡
        self.stock_files = list(set(self.stock_files))
        print(f"âœ… æ€»å…±æ‰¾åˆ° {len(self.stock_files)} ä¸ªè‚¡ç¥¨CSVæ–‡ä»¶")
        
        return len(self.stock_files) > 0
    
    def load_csv_data(self, file_path, limit_rows=None):
        """
        åŠ è½½CSVè‚¡ç¥¨æ•°æ®
        
        Args:
            file_path: CSVæ–‡ä»¶è·¯å¾„
            limit_rows: é™åˆ¶è¡Œæ•°
            
        Returns:
            DataFrame: è‚¡ç¥¨æ•°æ®
        """
        try:
            # è¯»å–CSVæ–‡ä»¶
            df = pd.read_csv(file_path)
            
            if limit_rows:
                df = df.tail(limit_rows)  # å–æœ€æ–°çš„æ•°æ®
            
            # å°è¯•æ ‡å‡†åŒ–åˆ—å
            column_mapping = {
                'tradedate': 'tradeDate',
                'trade_date': 'tradeDate', 
                'closeprice': 'closePrice',
                'close_price': 'closePrice',
                'close': 'closePrice',
                'openprice': 'openPrice',
                'open_price': 'openPrice', 
                'open': 'openPrice',
                'highprice': 'highPrice',
                'high_price': 'highPrice',
                'high': 'highPrice',
                'lowprice': 'lowPrice',
                'low_price': 'lowPrice',
                'low': 'lowPrice',
                'vol': 'volume',
                'turnover_vol': 'volume'
            }
            
            # åº”ç”¨åˆ—åæ˜ å°„
            df_renamed = df.rename(columns=column_mapping)
            
            # ç¡®ä¿æœ‰æ—¥æœŸåˆ—
            date_candidates = ['tradeDate', 'date', 'Date', 'trade_date']
            date_col = None
            for col in date_candidates:
                if col in df_renamed.columns:
                    date_col = col
                    break
            
            if date_col:
                try:
                    df_renamed['tradeDate'] = pd.to_datetime(df_renamed[date_col])
                except:
                    print(f"   âš ï¸ æ—¥æœŸè½¬æ¢å¤±è´¥: {date_col}")
                    return None
            
            # ç¡®ä¿æœ‰ä»·æ ¼åˆ—
            price_candidates = ['closePrice', 'close', 'Close', 'price']
            price_col = None
            for col in price_candidates:
                if col in df_renamed.columns:
                    price_col = col
                    if col != 'closePrice':
                        df_renamed['closePrice'] = df_renamed[col]
                    break
            
            # æ£€æŸ¥å¿…è¦çš„åˆ—
            required_cols = ['closePrice', 'tradeDate']
            missing_cols = [col for col in required_cols if col not in df_renamed.columns]
            if missing_cols:
                print(f"   âš ï¸ ç¼ºå°‘å¿…è¦åˆ—: {missing_cols}")
                print(f"   ğŸ“‹ å¯ç”¨åˆ—: {list(df_renamed.columns)}")
                return None
            
            # è¿‡æ»¤æœ‰æ•ˆæ•°æ®
            df_clean = df_renamed.dropna(subset=['closePrice', 'tradeDate'])
            df_clean = df_clean[df_clean['closePrice'] > 0]  # ä»·æ ¼å¿…é¡»å¤§äº0
            
            if len(df_clean) == 0:
                print(f"   âš ï¸ è¿‡æ»¤åæ— æœ‰æ•ˆæ•°æ®")
                return None
            
            return df_clean
            
        except Exception as e:
            print(f"   âŒ åŠ è½½CSVå¤±è´¥: {e}")
            return None
    
    def calculate_ma_crossover(self, prices_data, short_period=10, long_period=100):
        """
        è®¡ç®—MAäº¤å‰ä¿¡å·
        
        Args:
            prices_data: ä»·æ ¼æ•°æ® (DataFrame) 
            short_period: çŸ­æœŸMAå‘¨æœŸ
            long_period: é•¿æœŸMAå‘¨æœŸ
            
        Returns:
            dict: åˆ†æç»“æœ
        """
        try:
            # ç¡®ä¿æœ‰è¶³å¤Ÿçš„æ•°æ®
            if len(prices_data) < long_period * 7:  # è‡³å°‘éœ€è¦long_periodå‘¨çš„æ—¥çº¿æ•°æ®
                return {'status': 'insufficient_data', 'data_length': len(prices_data)}
            
            # æŒ‰æ—¥æœŸæ’åº
            df = prices_data.sort_values('tradeDate').copy()
            
            # è½¬æ¢ä¸ºå‘¨çº¿æ•°æ® (æ¯å‘¨çš„æœ€åä¸€ä¸ªäº¤æ˜“æ—¥)
            df_indexed = df.set_index('tradeDate')
            weekly_close = df_indexed['closePrice'].resample('W').last().dropna()
            
            if len(weekly_close) < long_period:
                return {'status': 'insufficient_weekly_data', 'weekly_length': len(weekly_close)}
            
            # è®¡ç®—ç§»åŠ¨å¹³å‡çº¿
            if talib and isinstance(weekly_close.values, np.ndarray):
                ma_short = talib.MA(weekly_close.values, timeperiod=short_period)
                ma_long = talib.MA(weekly_close.values, timeperiod=long_period)
            else:
                ma_short = weekly_close.rolling(short_period).mean().values
                ma_long = weekly_close.rolling(long_period).mean().values
            
            # åˆ›å»ºå¯¹é½çš„Series
            ma_short_series = pd.Series(ma_short, index=weekly_close.index)
            ma_long_series = pd.Series(ma_long, index=weekly_close.index)
            
            # å»é™¤NaNå€¼
            valid_idx = ma_short_series.dropna().index.intersection(ma_long_series.dropna().index)
            if len(valid_idx) < 2:
                return {'status': 'no_valid_data', 'valid_length': len(valid_idx)}
            
            ma_short_clean = ma_short_series.loc[valid_idx]
            ma_long_clean = ma_long_series.loc[valid_idx]
            
            # è®¡ç®—äº¤å‰ä¿¡å·
            position = (ma_short_clean > ma_long_clean).astype(int)
            crossover = position.diff()
            
            # ç»Ÿè®¡ä¿¡å·
            golden_cross = crossover > 0
            death_cross = crossover < 0
            
            golden_dates = golden_cross[golden_cross].index.tolist()
            death_dates = death_cross[death_cross].index.tolist()
            
            # å½“å‰çŠ¶æ€
            current_position = position.iloc[-1] if len(position) > 0 else 0
            latest_price = weekly_close.iloc[-1] if len(weekly_close) > 0 else 0
            
            # æœ€è¿‘ä¿¡å·
            recent_crossovers = crossover[crossover != 0]
            latest_signal = None
            if len(recent_crossovers) > 0:
                latest_signal = {
                    'date': recent_crossovers.index[-1],
                    'type': 'golden_cross' if recent_crossovers.iloc[-1] > 0 else 'death_cross',
                    'signal_value': recent_crossovers.iloc[-1]
                }
            
            return {
                'status': 'success',
                'data_period': {
                    'start': weekly_close.index.min(),
                    'end': weekly_close.index.max(),
                    'daily_count': len(prices_data),
                    'weekly_count': len(weekly_close),
                    'valid_count': len(valid_idx)
                },
                'indicators': {
                    'ma_short_period': short_period,
                    'ma_long_period': long_period,
                    'current_position': 'bullish' if current_position > 0 else 'bearish',
                    'latest_price': latest_price
                },
                'signals': {
                    'golden_cross_count': len(golden_dates),
                    'death_cross_count': len(death_dates), 
                    'golden_cross_dates': golden_dates,
                    'death_cross_dates': death_dates,
                    'latest_signal': latest_signal
                }
            }
            
        except Exception as e:
            return {'status': 'error', 'error': str(e)}
    
    def screen_stocks(self, max_stocks=10, min_golden_cross=1):
        """
        ç­›é€‰è‚¡ç¥¨
        
        Args:
            max_stocks: æœ€å¤§åˆ†æè‚¡ç¥¨æ•°
            min_golden_cross: æœ€å°‘é»„é‡‘äº¤å‰æ¬¡æ•°
            
        Returns:
            list: ç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨
        """
        print(f"ğŸ” å¼€å§‹ç­›é€‰è‚¡ç¥¨ (æœ€å¤šåˆ†æ {max_stocks} åª)")
        print(f"   ç­›é€‰æ¡ä»¶: è‡³å°‘ {min_golden_cross} æ¬¡é»„é‡‘äº¤å‰ + å½“å‰å¤šå¤´")
        print("=" * 70)
        
        self.results = []
        qualified_stocks = []
        
        # é€‰æ‹©æ–‡ä»¶è¿›è¡Œåˆ†æ
        files_to_analyze = self.stock_files[:max_stocks]
        
        for i, file_path in enumerate(files_to_analyze, 1):
            print(f"ğŸ“Š [{i}/{len(files_to_analyze)}] åˆ†æ: {file_path.name}")
            
            # åŠ è½½æ•°æ®
            stock_data = self.load_csv_data(file_path, limit_rows=5000)  # æœ€è¿‘5000æ¡è®°å½•
            if stock_data is None:
                print(f"   âŒ æ•°æ®åŠ è½½å¤±è´¥")
                continue
            
            print(f"   ğŸ“ˆ æ•°æ®: {len(stock_data)} æ¡è®°å½•")
            if 'tradeDate' in stock_data.columns:
                print(f"   ğŸ“… èŒƒå›´: {stock_data['tradeDate'].min().date()} - {stock_data['tradeDate'].max().date()}")
            
            # åˆ†æMAäº¤å‰
            analysis = self.calculate_ma_crossover(stock_data)
            
            # ä¿å­˜ç»“æœ
            result = {
                'file_name': file_path.name,
                'file_path': str(file_path),
                'analysis_time': datetime.now(),
                'analysis': analysis
            }
            self.results.append(result)
            
            # æ£€æŸ¥æ˜¯å¦ç¬¦åˆæ¡ä»¶
            if analysis['status'] == 'success':
                signals = analysis['signals']
                golden_count = signals['golden_cross_count']
                current_pos = analysis['indicators']['current_position']
                
                print(f"   ğŸ“Š é»„é‡‘äº¤å‰: {golden_count} æ¬¡")
                print(f"   ğŸ“ˆ å½“å‰çŠ¶æ€: {current_pos}")
                
                # ç­›é€‰æ¡ä»¶: é»„é‡‘äº¤å‰æ¬¡æ•° >= æœ€å°è¦æ±‚ AND å½“å‰å¤šå¤´
                meets_criteria = (
                    golden_count >= min_golden_cross and
                    current_pos == 'bullish'
                )
                
                if meets_criteria:
                    qualified_stocks.append(result)
                    print(f"   âœ… ç¬¦åˆç­›é€‰æ¡ä»¶")
                else:
                    print(f"   âŒ ä¸ç¬¦åˆç­›é€‰æ¡ä»¶")
                
                # æ˜¾ç¤ºæœ€è¿‘ä¿¡å·
                if signals['latest_signal']:
                    latest = signals['latest_signal']
                    signal_type = "ğŸŒŸ é»„é‡‘äº¤å‰" if latest['type'] == 'golden_cross' else "ğŸ’€ æ­»å‰"
                    print(f"   {signal_type}: {latest['date'].strftime('%Y-%m-%d')}")
                
                # æ˜¾ç¤ºä»·æ ¼ä¿¡æ¯
                latest_price = analysis['indicators']['latest_price']
                if latest_price > 0:
                    print(f"   ğŸ’° æœ€æ–°ä»·æ ¼: {latest_price:.2f}")
                
            else:
                print(f"   âŒ åˆ†æå¤±è´¥: {analysis.get('status', 'unknown')}")
                if 'error' in analysis:
                    print(f"   é”™è¯¯: {analysis['error']}")
            
            print()  # ç©ºè¡Œåˆ†éš”
        
        print(f"ğŸ¯ ç­›é€‰å®Œæˆ:")
        print(f"   æ€»åˆ†æ: {len(files_to_analyze)} åªè‚¡ç¥¨")
        print(f"   ç¬¦åˆæ¡ä»¶: {len(qualified_stocks)} åª")
        if len(files_to_analyze) > 0:
            print(f"   åˆæ ¼ç‡: {len(qualified_stocks)/len(files_to_analyze)*100:.1f}%")
        
        # æ’åº (æŒ‰é»„é‡‘äº¤å‰æ¬¡æ•°é™åº)
        qualified_stocks.sort(
            key=lambda x: x['analysis']['signals']['golden_cross_count'] if x['analysis']['status'] == 'success' else 0,
            reverse=True
        )
        
        return qualified_stocks
    
    def print_results(self, qualified_stocks, show_top=5):
        """æ‰“å°ç­›é€‰ç»“æœ"""
        if not qualified_stocks:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨")
            return
        
        print(f"\nğŸ† ç¬¦åˆæ¡ä»¶çš„è‚¡ç¥¨ (å‰{min(show_top, len(qualified_stocks))}åª):")
        print("=" * 80)
        
        for i, stock in enumerate(qualified_stocks[:show_top], 1):
            analysis = stock['analysis']
            if analysis['status'] != 'success':
                continue
                
            signals = analysis['signals']
            indicators = analysis['indicators']
            data_period = analysis['data_period']
            
            print(f"{i}. ğŸ“Š {stock['file_name']}")
            print(f"   ğŸŒŸ é»„é‡‘äº¤å‰: {signals['golden_cross_count']} æ¬¡")
            print(f"   ğŸ’€ æ­»å‰: {signals['death_cross_count']} æ¬¡") 
            print(f"   ğŸ“ˆ å½“å‰çŠ¶æ€: {indicators['current_position']}")
            print(f"   ğŸ’° æœ€æ–°ä»·æ ¼: {indicators['latest_price']:.2f}")
            
            # æ˜¾ç¤ºæœ€è¿‘çš„äº¤å‰ä¿¡å·
            if signals['latest_signal']:
                latest = signals['latest_signal']
                signal_name = "é»„é‡‘äº¤å‰" if latest['type'] == 'golden_cross' else "æ­»å‰"
                print(f"   ğŸ•’ æœ€è¿‘ä¿¡å·: {signal_name} ({latest['date'].strftime('%Y-%m-%d')})")
            
            print(f"   ğŸ“… åˆ†ææœŸé—´: {data_period['start'].strftime('%Y-%m-%d')} - {data_period['end'].strftime('%Y-%m-%d')}")
            print(f"   ğŸ“Š æ•°æ®ç‚¹: æ—¥çº¿{data_period['daily_count']}, å‘¨çº¿{data_period['weekly_count']}, æœ‰æ•ˆ{data_period['valid_count']}")
            print()
    
    def export_results(self, filename=None):
        """å¯¼å‡ºç­›é€‰ç»“æœ"""
        if filename is None:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"csv_ma_crossover_screening_{timestamp}.json"
        
        export_data = {
            'screening_info': {
                'timestamp': datetime.now().isoformat(),
                'total_files_found': len(self.stock_files),
                'analyzed_count': len(self.results),
                'qualified_count': len([r for r in self.results 
                                       if r['analysis']['status'] == 'success' 
                                       and r['analysis']['signals']['golden_cross_count'] >= 1
                                       and r['analysis']['indicators']['current_position'] == 'bullish'])
            },
            'results': self.results
        }
        
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(export_data, f, ensure_ascii=False, indent=2, default=str)
            print(f"ğŸ’¾ ç»“æœå·²å¯¼å‡º: {filename}")
            return filename
        except Exception as e:
            print(f"âŒ å¯¼å‡ºå¤±è´¥: {e}")
            return None

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ åŸºäºCSVæ•°æ®çš„åå‘¨çº¿ä¸Šç©¿ç™¾å‘¨çº¿è‚¡ç¥¨ç­›é€‰")
    print("=" * 70)
    
    # åˆ›å»ºç­›é€‰å™¨
    screener = CSVStockScreener()
    
    if len(screener.stock_files) == 0:
        print("âŒ æœªæ‰¾åˆ°è‚¡ç¥¨CSVæ•°æ®æ–‡ä»¶")
        print("ğŸ’¡ è¯·ç¡®ä¿æ•°æ®ç›®å½•ä¸‹æœ‰åŒ…å«è‚¡ç¥¨æ•°æ®çš„CSVæ–‡ä»¶")
        return []
    
    # è¿è¡Œç­›é€‰ 
    qualified_stocks = screener.screen_stocks(max_stocks=15, min_golden_cross=1)
    
    # æ˜¾ç¤ºç»“æœ
    screener.print_results(qualified_stocks, show_top=8)
    
    # å¯¼å‡ºç»“æœ
    export_file = screener.export_results()
    
    print(f"\nğŸ‰ ç­›é€‰å®Œæˆ!")
    if export_file:
        print(f"ğŸ“„ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {export_file}")
    
    return qualified_stocks

if __name__ == "__main__":
    results = main()