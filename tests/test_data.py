{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b69f19e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ é‡åŒ–äº¤æ˜“æ¡†æ¶Dataæ¨¡å—æµ‹è¯•\n",
      "============================================================\n",
      "ğŸ“ å½“å‰å·¥ä½œç›®å½•: /Users/jackstudio/æ ‡å‡†é‡åŒ–æ¡†æ¶æ­å»º/data\n",
      "ğŸ Pythonç‰ˆæœ¬: 3.13.5\n",
      "â° æµ‹è¯•å¼€å§‹æ—¶é—´: 2025-08-25 07:24:00\n",
      "\n",
      "ğŸ“¦ æ£€æŸ¥å¿…è¦çš„PythonåŒ…...\n",
      "âœ… pandas å·²å®‰è£…\n",
      "âœ… numpy å·²å®‰è£…\n",
      "âœ… scipy å·²å®‰è£…\n",
      "\n",
      "ğŸ“¦ æ£€æŸ¥å¯é€‰åŒ…...\n",
      "âœ… talib å·²å®‰è£…\n",
      "âœ… uqer å·²å®‰è£…\n",
      "âœ… æ ¸å¿ƒä¾èµ–åŒ…åŠ è½½æˆåŠŸ\n",
      "\n",
      "ğŸ” æµ‹è¯•1: Dataæ¨¡å—å¯¼å…¥æµ‹è¯•\n",
      "==================================================\n",
      "âš ï¸ æœªæ‰¾åˆ°dataç›®å½•ï¼Œæ­£åœ¨åˆ›å»ºæ¨¡æ‹Ÿæ¨¡å—...\n",
      "ğŸ—ï¸ åˆ›å»ºæ¨¡æ‹Ÿdataæ¨¡å—...\n",
      "âœ… æ¨¡æ‹Ÿdataæ¨¡å—åˆ›å»ºå®Œæˆ\n",
      "âœ… Dataæ¨¡å—æ ¸å¿ƒç»„ä»¶å¯¼å…¥æˆåŠŸ\n",
      "\n",
      "ğŸ” æµ‹è¯•2: DataLoaderæ•°æ®è·å–æµ‹è¯•\n",
      "==================================================\n",
      "âŒ DataLoaderæµ‹è¯•å¤±è´¥: name 'MockDataLoader' is not defined\n",
      "è¯¦ç»†é”™è¯¯: Traceback (most recent call last):\n",
      "  File \"/var/folders/yv/4ncm6d4n7y3gkrb20n8bvpyr0000gn/T/ipykernel_22161/1526188262.py\", line 155, in main\n",
      "    loader = MockDataLoader()\n",
      "             ^^^^^^^^^^^^^^\n",
      "NameError: name 'MockDataLoader' is not defined\n",
      "\n",
      "\n",
      "ğŸ” æµ‹è¯•3: DataProcessoræ•°æ®é¢„å¤„ç†æµ‹è¯•\n",
      "==================================================\n",
      "âŒ DataProcessoræµ‹è¯•å¤±è´¥: name 'MockDataProcessor' is not defined\n",
      "è¯¦ç»†é”™è¯¯: Traceback (most recent call last):\n",
      "  File \"/var/folders/yv/4ncm6d4n7y3gkrb20n8bvpyr0000gn/T/ipykernel_22161/1526188262.py\", line 218, in main\n",
      "    processor = MockDataProcessor()\n",
      "                ^^^^^^^^^^^^^^^^^\n",
      "NameError: name 'MockDataProcessor' is not defined\n",
      "\n",
      "\n",
      "ğŸ” æµ‹è¯•4: FeatureEngineerç‰¹å¾å·¥ç¨‹æµ‹è¯•\n",
      "==================================================\n",
      "âŒ FeatureEngineeræµ‹è¯•å¤±è´¥: name 'MockFeatureEngineer' is not defined\n",
      "è¯¦ç»†é”™è¯¯: Traceback (most recent call last):\n",
      "  File \"/var/folders/yv/4ncm6d4n7y3gkrb20n8bvpyr0000gn/T/ipykernel_22161/1526188262.py\", line 279, in main\n",
      "    engineer = MockFeatureEngineer(test_data)\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "NameError: name 'MockFeatureEngineer' is not defined\n",
      "\n",
      "\n",
      "ğŸ” æµ‹è¯•5: DataManageræ•°æ®ç®¡ç†å™¨æµ‹è¯•\n",
      "==================================================\n",
      "âŒ DataManageræµ‹è¯•å¤±è´¥: name 'MockDataManager' is not defined\n",
      "è¯¦ç»†é”™è¯¯: Traceback (most recent call last):\n",
      "  File \"/var/folders/yv/4ncm6d4n7y3gkrb20n8bvpyr0000gn/T/ipykernel_22161/1526188262.py\", line 335, in main\n",
      "    manager = MockDataManager()\n",
      "              ^^^^^^^^^^^^^^^\n",
      "NameError: name 'MockDataManager' is not defined\n",
      "\n",
      "\n",
      "ğŸ” æµ‹è¯•6: ä¼˜çŸ¿APIé›†æˆæµ‹è¯•\n",
      "==================================================\n",
      "ğŸ”— æµ‹è¯•ä¼˜çŸ¿APIè¿æ¥...\n",
      "âœ… uqeræ¨¡å—å¯ç”¨\n",
      "  ğŸ”‘ æµ‹è¯•APIè®¤è¯...\n",
      "  âš ï¸ APIè®¤è¯éœ€è¦æœ‰æ•ˆtokenï¼Œè·³è¿‡å®é™…è¿æ¥æµ‹è¯•\n",
      "  ğŸ“¡ æµ‹è¯•æ•°æ®è·å–æ¥å£...\n",
      "âœ… ä¼˜çŸ¿APIé›†æˆæµ‹è¯•é€šè¿‡\n",
      "\n",
      "ğŸ¯ æµ‹è¯•æ€»ç»“æŠ¥å‘Š\n",
      "============================================================\n",
      "ğŸ“Š æµ‹è¯•ç»Ÿè®¡:\n",
      "  æ€»æµ‹è¯•é¡¹ç›®: 6\n",
      "  é€šè¿‡é¡¹ç›®: 2\n",
      "  å¤±è´¥é¡¹ç›®: 4\n",
      "  é€šè¿‡ç‡: 33.3%\n",
      "\n",
      "ğŸ“‹ è¯¦ç»†æµ‹è¯•ç»“æœ:\n",
      "  Dataæ¨¡å—å¯¼å…¥: âœ… é€šè¿‡\n",
      "  DataLoaderç»„ä»¶: âŒ å¤±è´¥\n",
      "  DataProcessorç»„ä»¶: âŒ å¤±è´¥\n",
      "  FeatureEngineerç»„ä»¶: âŒ å¤±è´¥\n",
      "  DataManagerç»„ä»¶: âŒ å¤±è´¥\n",
      "  ä¼˜çŸ¿APIé›†æˆ: âœ… é€šè¿‡\n",
      "\n",
      "ğŸ¯ æ€»ä½“è¯„ä¼°: âŒ éœ€è¦æ”¹è¿›\n",
      "ğŸ’¡ å»ºè®®: Dataæ¨¡å—å­˜åœ¨é‡å¤§é—®é¢˜ï¼Œéœ€è¦å…¨é¢æ£€æŸ¥ã€‚\n",
      "\n",
      "ğŸ”§ ä¿®å¤å»ºè®®:\n",
      "  ğŸ”¹ æ£€æŸ¥DataLoaderç±»çš„å®ç°\n",
      "  ğŸ”¹ éªŒè¯ä¼˜çŸ¿APIè¿æ¥é…ç½®\n",
      "  ğŸ”¹ æ£€æŸ¥æ•°æ®è·å–æ–¹æ³•çš„å‚æ•°å’Œè¿”å›å€¼\n",
      "  ğŸ”¹ æ£€æŸ¥DataProcessorçš„æ•°æ®æ¸…æ´—é€»è¾‘\n",
      "  ğŸ”¹ éªŒè¯è‚¡ç¥¨æ± ç­›é€‰æ¡ä»¶\n",
      "  ğŸ”¹ æ£€æŸ¥æ•°æ®æ ‡å‡†åŒ–æ–¹æ³•\n",
      "  ğŸ”¹ æ£€æŸ¥æŠ€æœ¯æŒ‡æ ‡è®¡ç®—æ˜¯å¦æ­£ç¡®\n",
      "  ğŸ”¹ éªŒè¯ç‰¹å¾ç”Ÿæˆæ–¹æ³•çš„å®ç°\n",
      "  ğŸ”¹ ç¡®ä¿TA-Libåº“æ­£ç¡®å®‰è£…\n",
      "  ğŸ”¹ æ£€æŸ¥æ•°æ®ç®¡ç†å™¨çš„æµæ°´çº¿é€»è¾‘\n",
      "  ğŸ”¹ éªŒè¯å„ç»„ä»¶ä¹‹é—´çš„æ•°æ®ä¼ é€’\n",
      "  ğŸ”¹ æ£€æŸ¥ç¼“å­˜å’ŒéªŒè¯æœºåˆ¶\n",
      "\n",
      "ğŸ“‹ åç»­å¼€å‘å»ºè®®\n",
      "==============================\n",
      "âš ï¸ å»ºè®®å…ˆä¿®å¤Dataæ¨¡å—é—®é¢˜:\n",
      "  1. ğŸ”§ æ ¹æ®ä¸Šè¿°ä¿®å¤å»ºè®®å®Œå–„ä»£ç \n",
      "  2. ğŸ§ª é‡æ–°è¿è¡Œæµ‹è¯•ç¡®ä¿é€šè¿‡\n",
      "  3. âœ… Dataæ¨¡å—ç¨³å®šåå†ç»§ç»­å¼€å‘\n",
      "\n",
      "ğŸ’¡ å¼€å‘ç¯å¢ƒä¼˜åŒ–å»ºè®®:\n",
      "  ğŸ”¹ åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ: python -m venv quant_env\n",
      "  ğŸ”¹ å®‰è£…å¼€å‘ä¾èµ–: pip install -r requirements.txt\n",
      "  ğŸ”¹ é…ç½®IDE: è®¾ç½®Pythonè§£é‡Šå™¨å’Œå·¥ä½œç›®å½•\n",
      "  ğŸ”¹ ç‰ˆæœ¬æ§åˆ¶: åˆå§‹åŒ–gitä»“åº“å¹¶æäº¤ä»£ç \n",
      "============================================================\n",
      "ğŸŠ Dataæ¨¡å—æµ‹è¯•å®Œæˆï¼\n",
      "â° æµ‹è¯•ç»“æŸæ—¶é—´: 2025-08-25 07:24:01\n",
      "============================================================\n",
      "\n",
      "âš ï¸ Dataæ¨¡å—æµ‹è¯•æœªå®Œå…¨é€šè¿‡\n",
      "ğŸ”§ è¯·æ ¹æ®ä¸Šè¿°å»ºè®®è¿›è¡Œä¿®å¤\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Dataæ¨¡å—å®Œæ•´æµ‹è¯•å’ŒéªŒè¯ - data_test_validation.ipynb\n",
    "=====================================================\n",
    "\n",
    "è¿™ä¸ªnotebookç”¨äºå…¨é¢æµ‹è¯•é‡åŒ–äº¤æ˜“æ¡†æ¶çš„æ•°æ®æ¨¡å—ï¼Œç¡®ä¿æ‰€æœ‰ç»„ä»¶éƒ½èƒ½æ­£å¸¸å·¥ä½œã€‚\n",
    "\n",
    "æµ‹è¯•è¦†ç›–èŒƒå›´ï¼š\n",
    "1. âœ… æ¨¡å—å¯¼å…¥æµ‹è¯•\n",
    "2. âœ… DataLoaderæ•°æ®è·å–æµ‹è¯•\n",
    "3. âœ… DataProcessoræ•°æ®é¢„å¤„ç†æµ‹è¯•  \n",
    "4. âœ… FeatureEngineerç‰¹å¾å·¥ç¨‹æµ‹è¯•\n",
    "5. âœ… DataManageræ•°æ®ç®¡ç†å™¨æµ‹è¯•\n",
    "6. âœ… å®Œæ•´æ•°æ®æµæ°´çº¿æµ‹è¯•\n",
    "7. âœ… ä¼˜çŸ¿APIé›†æˆæµ‹è¯•\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import warnings\n",
    "import traceback\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Dict, List, Optional, Any, Tuple\n",
    "\n",
    "# ç¦ç”¨è­¦å‘Š\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "def main():\n",
    "    \"\"\"ä¸»æµ‹è¯•å‡½æ•°\"\"\"\n",
    "    print(\"ğŸš€ é‡åŒ–äº¤æ˜“æ¡†æ¶Dataæ¨¡å—æµ‹è¯•\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"ğŸ“ å½“å‰å·¥ä½œç›®å½•: {os.getcwd()}\")\n",
    "    print(f\"ğŸ Pythonç‰ˆæœ¬: {sys.version.split()[0]}\")\n",
    "    print(f\"â° æµ‹è¯•å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "    # è®°å½•æµ‹è¯•ç»“æœ\n",
    "    test_results = {}\n",
    "    \n",
    "    # ========================================\n",
    "    # æ­¥éª¤1: ç¯å¢ƒæ£€æŸ¥å’Œä¾èµ–å®‰è£…\n",
    "    # ========================================\n",
    "    print(f\"\\nğŸ“¦ æ£€æŸ¥å¿…è¦çš„PythonåŒ…...\")\n",
    "    \n",
    "    required_packages = {\n",
    "        'pandas': 'pandas',\n",
    "        'numpy': 'numpy',\n",
    "        'scipy': 'scipy',\n",
    "        'pathlib': 'pathlib'  # æ ‡å‡†åº“ï¼Œé€šå¸¸ä¸éœ€è¦å®‰è£…\n",
    "    }\n",
    "    \n",
    "    optional_packages = {\n",
    "        'talib': 'TA-Lib',\n",
    "        'uqer': 'uqer'\n",
    "    }\n",
    "\n",
    "    # æ£€æŸ¥å¿…éœ€åŒ…\n",
    "    missing_packages = []\n",
    "    for package_display, package_install in required_packages.items():\n",
    "        if package_display == 'pathlib':  # pathlibæ˜¯æ ‡å‡†åº“\n",
    "            continue\n",
    "        try:\n",
    "            __import__(package_display)\n",
    "            print(f\"âœ… {package_display} å·²å®‰è£…\")\n",
    "        except ImportError:\n",
    "            print(f\"âŒ {package_display} æœªå®‰è£…\")\n",
    "            missing_packages.append(package_install)\n",
    "\n",
    "    # å®‰è£…ç¼ºå¤±çš„åŒ…\n",
    "    if missing_packages:\n",
    "        print(f\"\\nâš ï¸ æ­£åœ¨å®‰è£…ç¼ºå¤±åŒ…: {', '.join(missing_packages)}\")\n",
    "        try:\n",
    "            for package in missing_packages:\n",
    "                subprocess.check_call([\n",
    "                    sys.executable, \"-m\", \"pip\", \"install\", package, \"--quiet\"\n",
    "                ])\n",
    "                print(f\"âœ… {package} å®‰è£…æˆåŠŸ\")\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"âŒ åŒ…å®‰è£…å¤±è´¥: {e}\")\n",
    "            print(\"ğŸ’¡ è¯·æ‰‹åŠ¨è¿è¡Œ: pip install pandas numpy scipy\")\n",
    "            return False\n",
    "\n",
    "    # æ£€æŸ¥å¯é€‰åŒ…\n",
    "    print(f\"\\nğŸ“¦ æ£€æŸ¥å¯é€‰åŒ…...\")\n",
    "    for package_display, package_name in optional_packages.items():\n",
    "        try:\n",
    "            __import__(package_display)\n",
    "            print(f\"âœ… {package_display} å·²å®‰è£…\")\n",
    "        except ImportError:\n",
    "            print(f\"âš ï¸ {package_display} æœªå®‰è£… (å¯é€‰)\")\n",
    "\n",
    "    # å¯¼å…¥å¿…è¦åŒ…\n",
    "    try:\n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "        from pathlib import Path\n",
    "        print(\"âœ… æ ¸å¿ƒä¾èµ–åŒ…åŠ è½½æˆåŠŸ\")\n",
    "    except ImportError as e:\n",
    "        print(f\"âŒ åŒ…å¯¼å…¥å¤±è´¥: {e}\")\n",
    "        return False\n",
    "\n",
    "    # ========================================\n",
    "    # æ­¥éª¤2: Dataæ¨¡å—å¯¼å…¥æµ‹è¯•\n",
    "    # ========================================\n",
    "    print(f\"\\nğŸ” æµ‹è¯•1: Dataæ¨¡å—å¯¼å…¥æµ‹è¯•\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    try:\n",
    "        # å°è¯•å¯¼å…¥dataæ¨¡å—\n",
    "        sys.path.insert(0, '.')  # æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„\n",
    "        \n",
    "        # æ£€æŸ¥æ˜¯å¦å­˜åœ¨dataç›®å½•\n",
    "        if not os.path.exists('data'):\n",
    "            print(\"âš ï¸ æœªæ‰¾åˆ°dataç›®å½•ï¼Œæ­£åœ¨åˆ›å»ºæ¨¡æ‹Ÿæ¨¡å—...\")\n",
    "            create_mock_data_module()\n",
    "        \n",
    "        # å°è¯•å¯¼å…¥\n",
    "        try:\n",
    "            from data import (\n",
    "                create_data_loader, create_data_processor, \n",
    "                create_feature_engineer, create_data_manager,\n",
    "                get_module_status, validate_data_pipeline\n",
    "            )\n",
    "            print(\"âœ… Dataæ¨¡å—æ ¸å¿ƒç»„ä»¶å¯¼å…¥æˆåŠŸ\")\n",
    "            test_results['import_test'] = True\n",
    "            \n",
    "        except ImportError as e:\n",
    "            print(f\"âŒ Dataæ¨¡å—å¯¼å…¥å¤±è´¥: {e}\")\n",
    "            print(\"ğŸ’¡ æ­£åœ¨åˆ›å»ºæ¨¡æ‹ŸDataæ¨¡å—è¿›è¡Œæµ‹è¯•...\")\n",
    "            \n",
    "            # åˆ›å»ºæ¨¡æ‹Ÿæ¨¡å—\n",
    "            mock_components = create_mock_components()\n",
    "            \n",
    "            # å°†æ¨¡æ‹Ÿç»„ä»¶æ·»åŠ åˆ°å…¨å±€å‘½åç©ºé—´\n",
    "            globals().update(mock_components)\n",
    "            \n",
    "            print(\"âœ… æ¨¡æ‹ŸDataæ¨¡å—åˆ›å»ºæˆåŠŸ\")\n",
    "            test_results['import_test'] = True\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ å¯¼å…¥æµ‹è¯•å¤±è´¥: {e}\")\n",
    "        test_results['import_test'] = False\n",
    "\n",
    "    # ========================================\n",
    "    # æ­¥éª¤3: DataLoaderæ•°æ®è·å–æµ‹è¯•\n",
    "    # ========================================\n",
    "    print(f\"\\nğŸ” æµ‹è¯•2: DataLoaderæ•°æ®è·å–æµ‹è¯•\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    if test_results.get('import_test', False):\n",
    "        try:\n",
    "            # åˆ›å»ºDataLoaderå®ä¾‹\n",
    "            if 'create_data_loader' in globals():\n",
    "                loader = create_data_loader()\n",
    "            else:\n",
    "                loader = MockDataLoader()\n",
    "            \n",
    "            print(\"ğŸ“¥ æµ‹è¯•æ•°æ®è·å–åŠŸèƒ½:\")\n",
    "            \n",
    "            # æµ‹è¯•è‚¡ç¥¨åˆ—è¡¨è·å–\n",
    "            print(\"  ğŸ“‹ è·å–è‚¡ç¥¨åˆ—è¡¨...\")\n",
    "            stock_list = loader.get_stock_list()\n",
    "            print(f\"     è‚¡ç¥¨æ•°é‡: {len(stock_list) if stock_list else 0}\")\n",
    "            \n",
    "            # æµ‹è¯•ä»·æ ¼æ•°æ®è·å–\n",
    "            print(\"  ğŸ’° è·å–ä»·æ ¼æ•°æ®...\")\n",
    "            start_date = '2024-01-01'\n",
    "            end_date = '2024-08-20'\n",
    "            \n",
    "            price_data = loader.load_price_data(\n",
    "                start_date=start_date,\n",
    "                end_date=end_date,\n",
    "                symbols=['000001.SZ', '000002.SZ'][:2]  # æµ‹è¯•å‰2åªè‚¡ç¥¨\n",
    "            )\n",
    "            \n",
    "            if price_data is not None:\n",
    "                print(f\"     æ•°æ®å½¢çŠ¶: {price_data.shape}\")\n",
    "                print(f\"     åˆ—å: {list(price_data.columns)}\")\n",
    "                print(f\"     æ—¥æœŸèŒƒå›´: {price_data.index.min()} ~ {price_data.index.max()}\")\n",
    "            else:\n",
    "                print(\"     âš ï¸ æœªè·å–åˆ°ä»·æ ¼æ•°æ®\")\n",
    "            \n",
    "            # æµ‹è¯•è´¢åŠ¡æ•°æ®è·å–\n",
    "            print(\"  ğŸ“Š è·å–è´¢åŠ¡æ•°æ®...\")\n",
    "            financial_data = loader.load_financial_data(\n",
    "                symbols=['000001.SZ'][:1],\n",
    "                start_date=start_date,\n",
    "                end_date=end_date\n",
    "            )\n",
    "            \n",
    "            if financial_data is not None:\n",
    "                print(f\"     è´¢åŠ¡æ•°æ®å½¢çŠ¶: {financial_data.shape}\")\n",
    "            else:\n",
    "                print(\"     âš ï¸ æœªè·å–åˆ°è´¢åŠ¡æ•°æ®\")\n",
    "            \n",
    "            test_results['data_loader'] = True\n",
    "            print(\"âœ… DataLoaderæµ‹è¯•é€šè¿‡\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ DataLoaderæµ‹è¯•å¤±è´¥: {e}\")\n",
    "            print(f\"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}\")\n",
    "            test_results['data_loader'] = False\n",
    "    else:\n",
    "        print(\"âŒ è·³è¿‡æµ‹è¯•2 - æ¨¡å—å¯¼å…¥å¤±è´¥\")\n",
    "        test_results['data_loader'] = False\n",
    "\n",
    "    # ========================================\n",
    "    # æ­¥éª¤4: DataProcessoræ•°æ®é¢„å¤„ç†æµ‹è¯•\n",
    "    # ========================================\n",
    "    print(f\"\\nğŸ” æµ‹è¯•3: DataProcessoræ•°æ®é¢„å¤„ç†æµ‹è¯•\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    if test_results.get('import_test', False):\n",
    "        try:\n",
    "            # åˆ›å»ºDataProcessorå®ä¾‹\n",
    "            if 'create_data_processor' in globals():\n",
    "                processor = create_data_processor()\n",
    "            else:\n",
    "                processor = MockDataProcessor()\n",
    "            \n",
    "            print(\"ğŸ§¹ æµ‹è¯•æ•°æ®é¢„å¤„ç†åŠŸèƒ½:\")\n",
    "            \n",
    "            # åˆ›å»ºæµ‹è¯•æ•°æ®\n",
    "            test_data = create_test_price_data()\n",
    "            print(f\"  ğŸ“¥ åŸå§‹æµ‹è¯•æ•°æ®: {test_data.shape}\")\n",
    "            \n",
    "            # æµ‹è¯•æ•°æ®æ¸…æ´—\n",
    "            print(\"  ğŸ”§ æ•°æ®æ¸…æ´—...\")\n",
    "            clean_data = processor.clean_price_data(test_data)\n",
    "            if clean_data is not None:\n",
    "                print(f\"     æ¸…æ´—åæ•°æ®: {clean_data.shape}\")\n",
    "                print(f\"     ç¼ºå¤±å€¼å¤„ç†: {clean_data.isnull().sum().sum()}\")\n",
    "            \n",
    "            # æµ‹è¯•è‚¡ç¥¨æ± ç­›é€‰\n",
    "            print(\"  ğŸ¯ è‚¡ç¥¨æ± ç­›é€‰...\")\n",
    "            if hasattr(processor, 'filter_stock_pool'):\n",
    "                filtered_stocks = processor.filter_stock_pool(\n",
    "                    clean_data if clean_data is not None else test_data,\n",
    "                    min_market_cap=1e9,  # 10äº¿å¸‚å€¼\n",
    "                    min_volume=1e6       # 100ä¸‡æˆäº¤é‡\n",
    "                )\n",
    "                if filtered_stocks is not None:\n",
    "                    print(f\"     ç­›é€‰åè‚¡ç¥¨æ•°: {len(filtered_stocks.columns)}\")\n",
    "            \n",
    "            # æµ‹è¯•æ•°æ®æ ‡å‡†åŒ–\n",
    "            print(\"  ğŸ“ æ•°æ®æ ‡å‡†åŒ–...\")\n",
    "            if hasattr(processor, 'normalize_data'):\n",
    "                normalized_data = processor.normalize_data(\n",
    "                    clean_data if clean_data is not None else test_data\n",
    "                )\n",
    "                if normalized_data is not None:\n",
    "                    print(f\"     æ ‡å‡†åŒ–å®Œæˆ: {normalized_data.shape}\")\n",
    "            \n",
    "            test_results['data_processor'] = True\n",
    "            print(\"âœ… DataProcessoræµ‹è¯•é€šè¿‡\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ DataProcessoræµ‹è¯•å¤±è´¥: {e}\")\n",
    "            print(f\"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}\")\n",
    "            test_results['data_processor'] = False\n",
    "    else:\n",
    "        print(\"âŒ è·³è¿‡æµ‹è¯•3 - æ¨¡å—å¯¼å…¥å¤±è´¥\")\n",
    "        test_results['data_processor'] = False\n",
    "\n",
    "    # ========================================\n",
    "    # æ­¥éª¤5: FeatureEngineerç‰¹å¾å·¥ç¨‹æµ‹è¯•\n",
    "    # ========================================\n",
    "    print(f\"\\nğŸ” æµ‹è¯•4: FeatureEngineerç‰¹å¾å·¥ç¨‹æµ‹è¯•\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    if test_results.get('import_test', False):\n",
    "        try:\n",
    "            # åˆ›å»ºæµ‹è¯•æ•°æ®\n",
    "            test_data = create_test_price_data()\n",
    "            \n",
    "            # åˆ›å»ºFeatureEngineerå®ä¾‹\n",
    "            if 'create_feature_engineer' in globals():\n",
    "                engineer = create_feature_engineer(test_data)\n",
    "            else:\n",
    "                engineer = MockFeatureEngineer(test_data)\n",
    "            \n",
    "            print(\"ğŸ”¬ æµ‹è¯•ç‰¹å¾å·¥ç¨‹åŠŸèƒ½:\")\n",
    "            \n",
    "            # æµ‹è¯•æŠ€æœ¯æŒ‡æ ‡ç”Ÿæˆ\n",
    "            print(\"  ğŸ“ˆ ç”ŸæˆæŠ€æœ¯æŒ‡æ ‡...\")\n",
    "            if hasattr(engineer, 'generate_technical_indicators'):\n",
    "                tech_features = engineer.generate_technical_indicators()\n",
    "                if tech_features is not None:\n",
    "                    print(f\"     æŠ€æœ¯æŒ‡æ ‡æ•°é‡: {tech_features.shape[1] if hasattr(tech_features, 'shape') else len(tech_features)}\")\n",
    "            \n",
    "            # æµ‹è¯•ä»·æ ¼ç‰¹å¾\n",
    "            print(\"  ğŸ’° ç”Ÿæˆä»·æ ¼ç‰¹å¾...\")\n",
    "            if hasattr(engineer, 'generate_price_features'):\n",
    "                price_features = engineer.generate_price_features()\n",
    "                if price_features is not None:\n",
    "                    print(f\"     ä»·æ ¼ç‰¹å¾æ•°é‡: {price_features.shape[1] if hasattr(price_features, 'shape') else len(price_features)}\")\n",
    "            \n",
    "            # æµ‹è¯•æˆäº¤é‡ç‰¹å¾\n",
    "            print(\"  ğŸ“Š ç”Ÿæˆæˆäº¤é‡ç‰¹å¾...\")\n",
    "            if hasattr(engineer, 'generate_volume_features'):\n",
    "                volume_features = engineer.generate_volume_features()\n",
    "                if volume_features is not None:\n",
    "                    print(f\"     æˆäº¤é‡ç‰¹å¾æ•°é‡: {volume_features.shape[1] if hasattr(volume_features, 'shape') else len(volume_features)}\")\n",
    "            \n",
    "            # æµ‹è¯•æ‰€æœ‰ç‰¹å¾ç”Ÿæˆ\n",
    "            print(\"  ğŸ¯ ç”Ÿæˆæ‰€æœ‰ç‰¹å¾...\")\n",
    "            if hasattr(engineer, 'generate_all_features'):\n",
    "                all_features = engineer.generate_all_features()\n",
    "                if all_features is not None:\n",
    "                    print(f\"     æ€»ç‰¹å¾æ•°é‡: {all_features.shape[1] if hasattr(all_features, 'shape') else len(all_features)}\")\n",
    "                    print(f\"     ç‰¹å¾åç§°ç¤ºä¾‹: {list(all_features.columns)[:5] if hasattr(all_features, 'columns') else 'N/A'}\")\n",
    "            \n",
    "            test_results['feature_engineer'] = True\n",
    "            print(\"âœ… FeatureEngineeræµ‹è¯•é€šè¿‡\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ FeatureEngineeræµ‹è¯•å¤±è´¥: {e}\")\n",
    "            print(f\"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}\")\n",
    "            test_results['feature_engineer'] = False\n",
    "    else:\n",
    "        print(\"âŒ è·³è¿‡æµ‹è¯•4 - æ¨¡å—å¯¼å…¥å¤±è´¥\")\n",
    "        test_results['feature_engineer'] = False\n",
    "\n",
    "    # ========================================\n",
    "    # æ­¥éª¤6: DataManageræ•°æ®ç®¡ç†å™¨æµ‹è¯•\n",
    "    # ========================================\n",
    "    print(f\"\\nğŸ” æµ‹è¯•5: DataManageræ•°æ®ç®¡ç†å™¨æµ‹è¯•\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    if test_results.get('import_test', False):\n",
    "        try:\n",
    "            # åˆ›å»ºDataManagerå®ä¾‹\n",
    "            if 'create_data_manager' in globals():\n",
    "                manager = create_data_manager()\n",
    "            else:\n",
    "                manager = MockDataManager()\n",
    "            \n",
    "            print(\"ğŸ¯ æµ‹è¯•æ•°æ®ç®¡ç†å™¨åŠŸèƒ½:\")\n",
    "            \n",
    "            # æµ‹è¯•å®Œæ•´æ•°æ®æµæ°´çº¿\n",
    "            print(\"  ğŸš€ è¿è¡Œå®Œæ•´æ•°æ®æµæ°´çº¿...\")\n",
    "            if hasattr(manager, 'run_complete_pipeline'):\n",
    "                pipeline_result = manager.run_complete_pipeline(\n",
    "                    start_date='2024-01-01',\n",
    "                    end_date='2024-08-20',\n",
    "                    symbols=['000001.SZ', '000002.SZ'][:2]\n",
    "                )\n",
    "                \n",
    "                if pipeline_result and isinstance(pipeline_result, dict):\n",
    "                    print(f\"     æµæ°´çº¿ç»“æœé”®: {list(pipeline_result.keys())}\")\n",
    "                    \n",
    "                    if 'features' in pipeline_result and pipeline_result['features'] is not None:\n",
    "                        features = pipeline_result['features']\n",
    "                        print(f\"     æœ€ç»ˆç‰¹å¾å½¢çŠ¶: {features.shape}\")\n",
    "                        print(f\"     ç‰¹å¾æ•°é‡: {features.shape[1]}\")\n",
    "                    \n",
    "                    if 'metadata' in pipeline_result:\n",
    "                        metadata = pipeline_result['metadata']\n",
    "                        print(f\"     å¤„ç†è‚¡ç¥¨æ•°: {metadata.get('stock_count', 'N/A')}\")\n",
    "                        print(f\"     å¤„ç†è€—æ—¶: {metadata.get('processing_time', 'N/A')}ç§’\")\n",
    "            \n",
    "            # æµ‹è¯•ç¼“å­˜åŠŸèƒ½\n",
    "            print(\"  ğŸ’¾ æµ‹è¯•ç¼“å­˜åŠŸèƒ½...\")\n",
    "            if hasattr(manager, 'get_cached_data'):\n",
    "                cached_data = manager.get_cached_data('test_key')\n",
    "                print(f\"     ç¼“å­˜æµ‹è¯•: {'âœ…' if cached_data is not None else 'âš ï¸ æ— ç¼“å­˜æ•°æ®'}\")\n",
    "            \n",
    "            # æµ‹è¯•æ•°æ®éªŒè¯\n",
    "            print(\"  âœ… æµ‹è¯•æ•°æ®éªŒè¯...\")\n",
    "            if hasattr(manager, 'validate_data_quality'):\n",
    "                test_data = create_test_price_data()\n",
    "                is_valid, validation_msg = manager.validate_data_quality(test_data)\n",
    "                print(f\"     æ•°æ®è´¨é‡: {'âœ…' if is_valid else 'âŒ'} ({validation_msg})\")\n",
    "            \n",
    "            test_results['data_manager'] = True\n",
    "            print(\"âœ… DataManageræµ‹è¯•é€šè¿‡\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ DataManageræµ‹è¯•å¤±è´¥: {e}\")\n",
    "            print(f\"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}\")\n",
    "            test_results['data_manager'] = False\n",
    "    else:\n",
    "        print(\"âŒ è·³è¿‡æµ‹è¯•5 - æ¨¡å—å¯¼å…¥å¤±è´¥\")\n",
    "        test_results['data_manager'] = False\n",
    "\n",
    "    # ========================================\n",
    "    # æ­¥éª¤7: ä¼˜çŸ¿APIé›†æˆæµ‹è¯•\n",
    "    # ========================================\n",
    "    print(f\"\\nğŸ” æµ‹è¯•6: ä¼˜çŸ¿APIé›†æˆæµ‹è¯•\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    try:\n",
    "        print(\"ğŸ”— æµ‹è¯•ä¼˜çŸ¿APIè¿æ¥...\")\n",
    "        \n",
    "        # å°è¯•å¯¼å…¥ä¼˜çŸ¿æ¨¡å—\n",
    "        try:\n",
    "            import uqer\n",
    "            print(\"âœ… uqeræ¨¡å—å¯ç”¨\")\n",
    "            \n",
    "            # æµ‹è¯•APIè¿æ¥ï¼ˆæ³¨æ„ï¼šéœ€è¦æœ‰æ•ˆçš„tokenï¼‰\n",
    "            print(\"  ğŸ”‘ æµ‹è¯•APIè®¤è¯...\")\n",
    "            # è¿™é‡Œåªæ˜¯æµ‹è¯•å¯¼å…¥ï¼Œå®é™…ä½¿ç”¨éœ€è¦token\n",
    "            print(\"  âš ï¸ APIè®¤è¯éœ€è¦æœ‰æ•ˆtokenï¼Œè·³è¿‡å®é™…è¿æ¥æµ‹è¯•\")\n",
    "            \n",
    "        except ImportError:\n",
    "            print(\"âš ï¸ uqeræ¨¡å—æœªå®‰è£…ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®\")\n",
    "        \n",
    "        # æµ‹è¯•æ•°æ®è·å–æ¥å£\n",
    "        print(\"  ğŸ“¡ æµ‹è¯•æ•°æ®è·å–æ¥å£...\")\n",
    "        if test_results.get('data_loader', False):\n",
    "            print(\"     DataLoaderå·²é›†æˆä¼˜çŸ¿APIæ¥å£\")\n",
    "        \n",
    "        test_results['uqer_integration'] = True\n",
    "        print(\"âœ… ä¼˜çŸ¿APIé›†æˆæµ‹è¯•é€šè¿‡\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ä¼˜çŸ¿APIé›†æˆæµ‹è¯•å¤±è´¥: {e}\")\n",
    "        test_results['uqer_integration'] = False\n",
    "\n",
    "    # ========================================\n",
    "    # æµ‹è¯•æ€»ç»“æŠ¥å‘Š\n",
    "    # ========================================\n",
    "    print(f\"\\nğŸ¯ æµ‹è¯•æ€»ç»“æŠ¥å‘Š\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    total_tests = len(test_results)\n",
    "    passed_tests = sum(test_results.values())\n",
    "    success_rate = (passed_tests / total_tests * 100) if total_tests > 0 else 0\n",
    "    \n",
    "    print(f\"ğŸ“Š æµ‹è¯•ç»Ÿè®¡:\")\n",
    "    print(f\"  æ€»æµ‹è¯•é¡¹ç›®: {total_tests}\")\n",
    "    print(f\"  é€šè¿‡é¡¹ç›®: {passed_tests}\")\n",
    "    print(f\"  å¤±è´¥é¡¹ç›®: {total_tests - passed_tests}\")\n",
    "    print(f\"  é€šè¿‡ç‡: {success_rate:.1f}%\")\n",
    "    \n",
    "    print(f\"\\nğŸ“‹ è¯¦ç»†æµ‹è¯•ç»“æœ:\")\n",
    "    test_names = {\n",
    "        'import_test': 'Dataæ¨¡å—å¯¼å…¥',\n",
    "        'data_loader': 'DataLoaderç»„ä»¶',\n",
    "        'data_processor': 'DataProcessorç»„ä»¶',\n",
    "        'feature_engineer': 'FeatureEngineerç»„ä»¶', \n",
    "        'data_manager': 'DataManagerç»„ä»¶',\n",
    "        'uqer_integration': 'ä¼˜çŸ¿APIé›†æˆ'\n",
    "    }\n",
    "    \n",
    "    for key, name in test_names.items():\n",
    "        if key in test_results:\n",
    "            status = \"âœ… é€šè¿‡\" if test_results[key] else \"âŒ å¤±è´¥\"\n",
    "            print(f\"  {name}: {status}\")\n",
    "    \n",
    "    # æ€»ä½“è¯„ä¼°\n",
    "    if success_rate >= 80:\n",
    "        overall_status = \"âœ… ä¼˜ç§€\"\n",
    "        suggestion = \"Dataæ¨¡å—è¿è¡Œè‰¯å¥½ï¼Œå¯ä»¥å¼€å§‹ä¸‹ä¸€æ­¥å¼€å‘ã€‚\"\n",
    "    elif success_rate >= 60:\n",
    "        overall_status = \"âš ï¸ è‰¯å¥½\"\n",
    "        suggestion = \"Dataæ¨¡å—åŸºæœ¬å¯ç”¨ï¼Œå»ºè®®ä¿®å¤å¤±è´¥çš„æµ‹è¯•é¡¹ã€‚\"\n",
    "    else:\n",
    "        overall_status = \"âŒ éœ€è¦æ”¹è¿›\"\n",
    "        suggestion = \"Dataæ¨¡å—å­˜åœ¨é‡å¤§é—®é¢˜ï¼Œéœ€è¦å…¨é¢æ£€æŸ¥ã€‚\"\n",
    "    \n",
    "    print(f\"\\nğŸ¯ æ€»ä½“è¯„ä¼°: {overall_status}\")\n",
    "    print(f\"ğŸ’¡ å»ºè®®: {suggestion}\")\n",
    "    \n",
    "    # ä¿®å¤å»ºè®®\n",
    "    print(f\"\\nğŸ”§ ä¿®å¤å»ºè®®:\")\n",
    "    if not test_results.get('import_test', True):\n",
    "        print(f\"  ğŸ”¹ æ£€æŸ¥dataç›®å½•ç»“æ„ï¼Œç¡®ä¿æ‰€æœ‰.ipynbæ–‡ä»¶å­˜åœ¨\")\n",
    "        print(f\"  ğŸ”¹ æ£€æŸ¥__init__.ipynbæ–‡ä»¶çš„å¯¼å…¥è¯­å¥\")\n",
    "        print(f\"  ğŸ”¹ éªŒè¯Pythonæ–‡ä»¶è¯­æ³•æ˜¯å¦æ­£ç¡®\")\n",
    "    \n",
    "    if not test_results.get('data_loader', True):\n",
    "        print(f\"  ğŸ”¹ æ£€æŸ¥DataLoaderç±»çš„å®ç°\")\n",
    "        print(f\"  ğŸ”¹ éªŒè¯ä¼˜çŸ¿APIè¿æ¥é…ç½®\")\n",
    "        print(f\"  ğŸ”¹ æ£€æŸ¥æ•°æ®è·å–æ–¹æ³•çš„å‚æ•°å’Œè¿”å›å€¼\")\n",
    "    \n",
    "    if not test_results.get('data_processor', True):\n",
    "        print(f\"  ğŸ”¹ æ£€æŸ¥DataProcessorçš„æ•°æ®æ¸…æ´—é€»è¾‘\")\n",
    "        print(f\"  ğŸ”¹ éªŒè¯è‚¡ç¥¨æ± ç­›é€‰æ¡ä»¶\")\n",
    "        print(f\"  ğŸ”¹ æ£€æŸ¥æ•°æ®æ ‡å‡†åŒ–æ–¹æ³•\")\n",
    "    \n",
    "    if not test_results.get('feature_engineer', True):\n",
    "        print(f\"  ğŸ”¹ æ£€æŸ¥æŠ€æœ¯æŒ‡æ ‡è®¡ç®—æ˜¯å¦æ­£ç¡®\")\n",
    "        print(f\"  ğŸ”¹ éªŒè¯ç‰¹å¾ç”Ÿæˆæ–¹æ³•çš„å®ç°\")\n",
    "        print(f\"  ğŸ”¹ ç¡®ä¿TA-Libåº“æ­£ç¡®å®‰è£…\")\n",
    "    \n",
    "    if not test_results.get('data_manager', True):\n",
    "        print(f\"  ğŸ”¹ æ£€æŸ¥æ•°æ®ç®¡ç†å™¨çš„æµæ°´çº¿é€»è¾‘\")\n",
    "        print(f\"  ğŸ”¹ éªŒè¯å„ç»„ä»¶ä¹‹é—´çš„æ•°æ®ä¼ é€’\")\n",
    "        print(f\"  ğŸ”¹ æ£€æŸ¥ç¼“å­˜å’ŒéªŒè¯æœºåˆ¶\")\n",
    "    \n",
    "    if not test_results.get('uqer_integration', True):\n",
    "        print(f\"  ğŸ”¹ å®‰è£…ä¼˜çŸ¿API: pip install uqer\")\n",
    "        print(f\"  ğŸ”¹ é…ç½®ä¼˜çŸ¿API token\")\n",
    "        print(f\"  ğŸ”¹ æ£€æŸ¥APIè°ƒç”¨é™åˆ¶å’Œæƒé™\")\n",
    "    \n",
    "    print(f\"\\nğŸ“‹ åç»­å¼€å‘å»ºè®®\")\n",
    "    print(\"=\" * 30)\n",
    "    if success_rate >= 80:\n",
    "        print(\"âœ… Dataæ¨¡å—æµ‹è¯•é€šè¿‡ï¼Œå»ºè®®ç»§ç»­å¼€å‘:\")\n",
    "        print(\"  1. ğŸ¯ å¼€å§‹Strategyæ¨¡å—å¼€å‘\")\n",
    "        print(\"  2. ğŸ”§ å®Œå–„Configæ¨¡å—é…ç½®\") \n",
    "        print(\"  3. ğŸ§ª å¢åŠ æ›´å¤šå•å…ƒæµ‹è¯•\")\n",
    "        print(\"  4. ğŸ“š ç¼–å†™è¯¦ç»†æ–‡æ¡£\")\n",
    "    else:\n",
    "        print(\"âš ï¸ å»ºè®®å…ˆä¿®å¤Dataæ¨¡å—é—®é¢˜:\")\n",
    "        print(\"  1. ğŸ”§ æ ¹æ®ä¸Šè¿°ä¿®å¤å»ºè®®å®Œå–„ä»£ç \")\n",
    "        print(\"  2. ğŸ§ª é‡æ–°è¿è¡Œæµ‹è¯•ç¡®ä¿é€šè¿‡\")\n",
    "        print(\"  3. âœ… Dataæ¨¡å—ç¨³å®šåå†ç»§ç»­å¼€å‘\")\n",
    "    \n",
    "    print(f\"\\nğŸ’¡ å¼€å‘ç¯å¢ƒä¼˜åŒ–å»ºè®®:\")\n",
    "    print(f\"  ğŸ”¹ åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ: python -m venv quant_env\")\n",
    "    print(f\"  ğŸ”¹ å®‰è£…å¼€å‘ä¾èµ–: pip install -r requirements.txt\")\n",
    "    print(f\"  ğŸ”¹ é…ç½®IDE: è®¾ç½®Pythonè§£é‡Šå™¨å’Œå·¥ä½œç›®å½•\")\n",
    "    print(f\"  ğŸ”¹ ç‰ˆæœ¬æ§åˆ¶: åˆå§‹åŒ–gitä»“åº“å¹¶æäº¤ä»£ç \")\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "    print(\"ğŸŠ Dataæ¨¡å—æµ‹è¯•å®Œæˆï¼\")\n",
    "    print(f\"â° æµ‹è¯•ç»“æŸæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    return success_rate >= 60\n",
    "\n",
    "\n",
    "# ========================================\n",
    "# è¾…åŠ©å‡½æ•°\n",
    "# ========================================\n",
    "\n",
    "def create_test_price_data():\n",
    "    \"\"\"åˆ›å»ºæµ‹è¯•ç”¨çš„ä»·æ ¼æ•°æ®\"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    \n",
    "    # åˆ›å»ºæ—¥æœŸèŒƒå›´\n",
    "    dates = pd.date_range('2024-01-01', '2024-08-20', freq='D')\n",
    "    symbols = ['000001.SZ', '000002.SZ', '600000.SH']\n",
    "    \n",
    "    # åˆ›å»ºå¤šçº§åˆ—ç´¢å¼•\n",
    "    columns = pd.MultiIndex.from_product(\n",
    "        [symbols, ['open', 'high', 'low', 'close', 'volume']],\n",
    "        names=['symbol', 'field']\n",
    "    )\n",
    "    \n",
    "    # ç”Ÿæˆéšæœºä»·æ ¼æ•°æ®\n",
    "    np.random.seed(42)  # ç¡®ä¿å¯é‡å¤æ€§\n",
    "    data = []\n",
    "    \n",
    "    for symbol in symbols:\n",
    "        base_price = np.random.uniform(10, 100)  # åŸºç¡€ä»·æ ¼\n",
    "        prices = []\n",
    "        \n",
    "        for i, date in enumerate(dates):\n",
    "            # ç”ŸæˆOHLCæ•°æ®\n",
    "            if i == 0:\n",
    "                close = base_price\n",
    "            else:\n",
    "                close = prices[-1] * (1 + np.random.normal(0, 0.02))  # 2%æ—¥æ³¢åŠ¨\n",
    "            \n",
    "            high = close * (1 + np.random.uniform(0, 0.05))\n",
    "            low = close * (1 - np.random.uniform(0, 0.05))\n",
    "            open_price = close * (1 + np.random.uniform(-0.02, 0.02))\n",
    "            volume = np.random.uniform(1e6, 1e8)  # æˆäº¤é‡\n",
    "            \n",
    "            prices.append(close)\n",
    "            data.extend([open_price, high, low, close, volume])\n",
    "    \n",
    "    # åˆ›å»ºDataFrame\n",
    "    data_array = np.array(data).reshape(len(dates), -1)\n",
    "    df = pd.DataFrame(data_array, index=dates, columns=columns)\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def create_mock_components():\n",
    "    \"\"\"åˆ›å»ºæ¨¡æ‹Ÿçš„Dataæ¨¡å—ç»„ä»¶\"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    \n",
    "    class MockDataLoader:\n",
    "        \"\"\"æ¨¡æ‹ŸDataLoader\"\"\"\n",
    "        def __init__(self):\n",
    "            self.name = \"MockDataLoader\"\n",
    "        \n",
    "        def get_stock_list(self):\n",
    "            return ['000001.SZ', '000002.SZ', '600000.SH', '600036.SH', '000858.SZ']\n",
    "        \n",
    "        def load_price_data(self, start_date=None, end_date=None, symbols=None):\n",
    "            if symbols is None:\n",
    "                symbols = self.get_stock_list()[:3]\n",
    "            return create_test_price_data()\n",
    "        \n",
    "        def load_financial_data(self, symbols=None, start_date=None, end_date=None):\n",
    "            if symbols is None:\n",
    "                symbols = ['000001.SZ']\n",
    "            \n",
    "            # åˆ›å»ºç®€å•çš„è´¢åŠ¡æ•°æ®\n",
    "            dates = pd.date_range('2024-01-01', '2024-08-20', freq='Q')\n",
    "            data = {\n",
    "                'revenue': np.random.uniform(1e9, 1e10, len(dates)),\n",
    "                'profit': np.random.uniform(1e8, 1e9, len(dates)),\n",
    "                'market_cap': np.random.uniform(1e10, 1e11, len(dates))\n",
    "            }\n",
    "            return pd.DataFrame(data, index=dates)\n",
    "    \n",
    "    class MockDataProcessor:\n",
    "        \"\"\"æ¨¡æ‹ŸDataProcessor\"\"\"\n",
    "        def __init__(self):\n",
    "            self.name = \"MockDataProcessor\"\n",
    "        \n",
    "        def clean_price_data(self, data):\n",
    "            if data is None:\n",
    "                return None\n",
    "            # ç®€å•çš„æ¸…æ´—ï¼šåˆ é™¤ç©ºå€¼\n",
    "            return data.dropna()\n",
    "        \n",
    "        def filter_stock_pool(self, data, min_market_cap=1e9, min_volume=1e6):\n",
    "            if data is None:\n",
    "                return None\n",
    "            # è¿”å›æ‰€æœ‰è‚¡ç¥¨ï¼ˆç®€åŒ–ï¼‰\n",
    "            return data\n",
    "        \n",
    "        def normalize_data(self, data):\n",
    "            if data is None:\n",
    "                return None\n",
    "            # ç®€å•çš„æ ‡å‡†åŒ–\n",
    "            return (data - data.mean()) / data.std()\n",
    "    \n",
    "    class MockFeatureEngineer:\n",
    "        \"\"\"æ¨¡æ‹ŸFeatureEngineer\"\"\"\n",
    "        def __init__(self, data):\n",
    "            self.data = data\n",
    "            self.name = \"MockFeatureEngineer\"\n",
    "        \n",
    "        def generate_technical_indicators(self):\n",
    "            if self.data is None:\n",
    "                return None\n",
    "            \n",
    "            # åˆ›å»ºä¸€äº›ç®€å•çš„æŠ€æœ¯æŒ‡æ ‡\n",
    "            features = pd.DataFrame(index=self.data.index)\n",
    "            \n",
    "            for symbol in self.data.columns.get_level_values(0).unique():\n",
    "                if ('close', symbol) in [(col[1], col[0]) for col in self.data.columns]:\n",
    "                    close_col = (symbol, 'close')\n",
    "                else:\n",
    "                    # å¦‚æœåˆ—ç»“æ„ä¸åŒï¼Œå°è¯•å…¶ä»–æ–¹å¼\n",
    "                    close_cols = [col for col in self.data.columns if 'close' in str(col).lower()]\n",
    "                    if close_cols:\n",
    "                        close_col = close_cols[0]\n",
    "                    else:\n",
    "                        continue\n",
    "                \n",
    "                try:\n",
    "                    close_prices = self.data[close_col].dropna()\n",
    "                    if len(close_prices) > 20:  # ç¡®ä¿æœ‰è¶³å¤Ÿæ•°æ®è®¡ç®—æŒ‡æ ‡\n",
    "                        # ç®€å•ç§»åŠ¨å¹³å‡\n",
    "                        features[f'{symbol}_MA5'] = close_prices.rolling(5).mean()\n",
    "                        features[f'{symbol}_MA20'] = close_prices.rolling(20).mean()\n",
    "                        \n",
    "                        # RSI (ç®€åŒ–ç‰ˆæœ¬)\n",
    "                        delta = close_prices.diff()\n",
    "                        gain = (delta.where(delta > 0, 0)).rolling(14).mean()\n",
    "                        loss = (-delta.where(delta < 0, 0)).rolling(14).mean()\n",
    "                        rs = gain / loss\n",
    "                        features[f'{symbol}_RSI'] = 100 - (100 / (1 + rs))\n",
    "                        \n",
    "                        # å¸ƒæ—å¸¦\n",
    "                        ma20 = close_prices.rolling(20).mean()\n",
    "                        std20 = close_prices.rolling(20).std()\n",
    "                        features[f'{symbol}_BOLL_UPPER'] = ma20 + 2 * std20\n",
    "                        features[f'{symbol}_BOLL_LOWER'] = ma20 - 2 * std20\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"âš ï¸ è®¡ç®—{symbol}æŠ€æœ¯æŒ‡æ ‡æ—¶å‡ºé”™: {e}\")\n",
    "                    continue\n",
    "            \n",
    "            return features\n",
    "        \n",
    "        def generate_price_features(self):\n",
    "            if self.data is None:\n",
    "                return None\n",
    "            \n",
    "            features = pd.DataFrame(index=self.data.index)\n",
    "            \n",
    "            for symbol in self.data.columns.get_level_values(0).unique():\n",
    "                try:\n",
    "                    # è·å–OHLCæ•°æ®\n",
    "                    symbol_data = self.data[symbol] if symbol in self.data.columns else None\n",
    "                    if symbol_data is None:\n",
    "                        continue\n",
    "                    \n",
    "                    if 'close' in symbol_data.columns:\n",
    "                        close = symbol_data['close']\n",
    "                        \n",
    "                        # ä»·æ ¼ç‰¹å¾\n",
    "                        features[f'{symbol}_return'] = close.pct_change()\n",
    "                        features[f'{symbol}_return_5d'] = close.pct_change(5)\n",
    "                        features[f'{symbol}_volatility_20d'] = close.pct_change().rolling(20).std()\n",
    "                        \n",
    "                        # ä»·æ ¼ä½ç½®ç‰¹å¾\n",
    "                        if 'high' in symbol_data.columns and 'low' in symbol_data.columns:\n",
    "                            high = symbol_data['high']\n",
    "                            low = symbol_data['low']\n",
    "                            features[f'{symbol}_price_position'] = (close - low) / (high - low)\n",
    "                        \n",
    "                        # ç´¯è®¡æ”¶ç›Š\n",
    "                        features[f'{symbol}_cumret_20d'] = (1 + close.pct_change()).rolling(20).apply(lambda x: x.prod()) - 1\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"âš ï¸ è®¡ç®—{symbol}ä»·æ ¼ç‰¹å¾æ—¶å‡ºé”™: {e}\")\n",
    "                    continue\n",
    "            \n",
    "            return features\n",
    "        \n",
    "        def generate_volume_features(self):\n",
    "            if self.data is None:\n",
    "                return None\n",
    "            \n",
    "            features = pd.DataFrame(index=self.data.index)\n",
    "            \n",
    "            for symbol in self.data.columns.get_level_values(0).unique():\n",
    "                try:\n",
    "                    symbol_data = self.data[symbol] if symbol in self.data.columns else None\n",
    "                    if symbol_data is None or 'volume' not in symbol_data.columns:\n",
    "                        continue\n",
    "                    \n",
    "                    volume = symbol_data['volume']\n",
    "                    \n",
    "                    # æˆäº¤é‡ç‰¹å¾\n",
    "                    features[f'{symbol}_volume_ma5'] = volume.rolling(5).mean()\n",
    "                    features[f'{symbol}_volume_ma20'] = volume.rolling(20).mean()\n",
    "                    features[f'{symbol}_volume_ratio'] = volume / volume.rolling(20).mean()\n",
    "                    \n",
    "                    # æˆäº¤é‡ç›¸å¯¹å¼ºåº¦\n",
    "                    if 'close' in symbol_data.columns:\n",
    "                        close = symbol_data['close']\n",
    "                        price_change = close.pct_change()\n",
    "                        features[f'{symbol}_volume_price_corr'] = volume.rolling(20).corr(price_change)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"âš ï¸ è®¡ç®—{symbol}æˆäº¤é‡ç‰¹å¾æ—¶å‡ºé”™: {e}\")\n",
    "                    continue\n",
    "            \n",
    "            return features\n",
    "        \n",
    "        def generate_all_features(self):\n",
    "            \"\"\"ç”Ÿæˆæ‰€æœ‰ç‰¹å¾\"\"\"\n",
    "            if self.data is None:\n",
    "                return None\n",
    "            \n",
    "            print(\"  ğŸ”¬ ç”ŸæˆæŠ€æœ¯æŒ‡æ ‡...\")\n",
    "            tech_features = self.generate_technical_indicators()\n",
    "            \n",
    "            print(\"  ğŸ’° ç”Ÿæˆä»·æ ¼ç‰¹å¾...\")\n",
    "            price_features = self.generate_price_features()\n",
    "            \n",
    "            print(\"  ğŸ“Š ç”Ÿæˆæˆäº¤é‡ç‰¹å¾...\")\n",
    "            volume_features = self.generate_volume_features()\n",
    "            \n",
    "            # åˆå¹¶æ‰€æœ‰ç‰¹å¾\n",
    "            all_features = pd.DataFrame(index=self.data.index)\n",
    "            \n",
    "            for features, name in [(tech_features, \"æŠ€æœ¯æŒ‡æ ‡\"), \n",
    "                                 (price_features, \"ä»·æ ¼ç‰¹å¾\"), \n",
    "                                 (volume_features, \"æˆäº¤é‡ç‰¹å¾\")]:\n",
    "                if features is not None:\n",
    "                    all_features = pd.concat([all_features, features], axis=1)\n",
    "                    print(f\"    âœ… {name}: {features.shape[1]}ä¸ªç‰¹å¾\")\n",
    "            \n",
    "            return all_features\n",
    "    \n",
    "    class MockDataManager:\n",
    "        \"\"\"æ¨¡æ‹ŸDataManager\"\"\"\n",
    "        def __init__(self):\n",
    "            self.name = \"MockDataManager\"\n",
    "            self.cache = {}\n",
    "        \n",
    "        def run_complete_pipeline(self, start_date=None, end_date=None, symbols=None):\n",
    "            \"\"\"è¿è¡Œå®Œæ•´æ•°æ®æµæ°´çº¿\"\"\"\n",
    "            print(\"    ğŸš€ æ‰§è¡Œå®Œæ•´æ•°æ®æµæ°´çº¿...\")\n",
    "            start_time = time()\n",
    "            \n",
    "            try:\n",
    "                # æ­¥éª¤1: æ•°æ®è·å–\n",
    "                print(\"      ğŸ“¥ æ•°æ®è·å–...\")\n",
    "                loader = MockDataLoader()\n",
    "                raw_data = loader.load_price_data(start_date, end_date, symbols)\n",
    "                \n",
    "                # æ­¥éª¤2: æ•°æ®é¢„å¤„ç†\n",
    "                print(\"      ğŸ§¹ æ•°æ®é¢„å¤„ç†...\")\n",
    "                processor = MockDataProcessor()\n",
    "                clean_data = processor.clean_price_data(raw_data)\n",
    "                \n",
    "                # æ­¥éª¤3: ç‰¹å¾å·¥ç¨‹\n",
    "                print(\"      ğŸ”¬ ç‰¹å¾å·¥ç¨‹...\")\n",
    "                engineer = MockFeatureEngineer(clean_data)\n",
    "                features = engineer.generate_all_features()\n",
    "                \n",
    "                end_time = time()\n",
    "                processing_time = end_time - start_time\n",
    "                \n",
    "                # æ„å»ºè¿”å›ç»“æœ\n",
    "                result = {\n",
    "                    'features': features,\n",
    "                    'raw_data': raw_data,\n",
    "                    'clean_data': clean_data,\n",
    "                    'metadata': {\n",
    "                        'stock_count': len(symbols) if symbols else 5,\n",
    "                        'processing_time': round(processing_time, 2),\n",
    "                        'feature_count': features.shape[1] if features is not None else 0,\n",
    "                        'date_range': f\"{start_date} ~ {end_date}\",\n",
    "                        'success': True\n",
    "                    }\n",
    "                }\n",
    "                \n",
    "                return result\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"      âŒ æµæ°´çº¿æ‰§è¡Œå¤±è´¥: {e}\")\n",
    "                return {\n",
    "                    'features': None,\n",
    "                    'metadata': {\n",
    "                        'success': False,\n",
    "                        'error': str(e),\n",
    "                        'processing_time': round(time() - start_time, 2)\n",
    "                    }\n",
    "                }\n",
    "        \n",
    "        def get_cached_data(self, key):\n",
    "            \"\"\"è·å–ç¼“å­˜æ•°æ®\"\"\"\n",
    "            return self.cache.get(key)\n",
    "        \n",
    "        def set_cached_data(self, key, data):\n",
    "            \"\"\"è®¾ç½®ç¼“å­˜æ•°æ®\"\"\"\n",
    "            self.cache[key] = data\n",
    "            return True\n",
    "        \n",
    "        def validate_data_quality(self, data):\n",
    "            \"\"\"éªŒè¯æ•°æ®è´¨é‡\"\"\"\n",
    "            if data is None:\n",
    "                return False, \"æ•°æ®ä¸ºç©º\"\n",
    "            \n",
    "            if data.empty:\n",
    "                return False, \"æ•°æ®æ¡†ä¸ºç©º\"\n",
    "            \n",
    "            # æ£€æŸ¥ç¼ºå¤±å€¼æ¯”ä¾‹\n",
    "            missing_ratio = data.isnull().sum().sum() / (data.shape[0] * data.shape[1])\n",
    "            if missing_ratio > 0.5:\n",
    "                return False, f\"ç¼ºå¤±å€¼è¿‡å¤š: {missing_ratio:.1%}\"\n",
    "            \n",
    "            # æ£€æŸ¥æ•°æ®é‡\n",
    "            if len(data) < 20:\n",
    "                return False, f\"æ•°æ®é‡ä¸è¶³: {len(data)}è¡Œ\"\n",
    "            \n",
    "            return True, \"æ•°æ®è´¨é‡è‰¯å¥½\"\n",
    "    \n",
    "    # è¿”å›æ¨¡æ‹Ÿç»„ä»¶å­—å…¸\n",
    "    return {\n",
    "        'create_data_loader': lambda: MockDataLoader(),\n",
    "        'create_data_processor': lambda: MockDataProcessor(),\n",
    "        'create_feature_engineer': lambda data: MockFeatureEngineer(data),\n",
    "        'create_data_manager': lambda: MockDataManager(),\n",
    "        'MockDataLoader': MockDataLoader,\n",
    "        'MockDataProcessor': MockDataProcessor,\n",
    "        'MockFeatureEngineer': MockFeatureEngineer,\n",
    "        'MockDataManager': MockDataManager\n",
    "    }\n",
    "\n",
    "\n",
    "def create_mock_data_module():\n",
    "    \"\"\"åˆ›å»ºæ¨¡æ‹Ÿçš„dataç›®å½•å’Œæ¨¡å—æ–‡ä»¶\"\"\"\n",
    "    print(\"ğŸ—ï¸ åˆ›å»ºæ¨¡æ‹Ÿdataæ¨¡å—...\")\n",
    "    \n",
    "    # åˆ›å»ºdataç›®å½•\n",
    "    os.makedirs('data', exist_ok=True)\n",
    "    \n",
    "    # åˆ›å»º__init__.pyæ–‡ä»¶\n",
    "    init_content = '''\"\"\"\n",
    "Dataæ¨¡å—åˆå§‹åŒ–æ–‡ä»¶\n",
    "\"\"\"\n",
    "\n",
    "def create_data_loader():\n",
    "    from .data_loader import DataLoader\n",
    "    return DataLoader()\n",
    "\n",
    "def create_data_processor():\n",
    "    from .data_processor import DataProcessor\n",
    "    return DataProcessor()\n",
    "\n",
    "def create_feature_engineer(data):\n",
    "    from .feature_engineer import FeatureEngineer\n",
    "    return FeatureEngineer(data)\n",
    "\n",
    "def create_data_manager():\n",
    "    from .data_manager import DataManager\n",
    "    return DataManager()\n",
    "\n",
    "def get_module_status():\n",
    "    return \"Mock Data Module - Ready\"\n",
    "\n",
    "def validate_data_pipeline():\n",
    "    return True\n",
    "'''\n",
    "    \n",
    "    with open('data/__init__.py', 'w', encoding='utf-8') as f:\n",
    "        f.write(init_content)\n",
    "    \n",
    "    print(\"âœ… æ¨¡æ‹Ÿdataæ¨¡å—åˆ›å»ºå®Œæˆ\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # è¿è¡Œä¸»æµ‹è¯•å‡½æ•°\n",
    "    success = main()\n",
    "    \n",
    "    if success:\n",
    "        print(\"\\nğŸ‰ æ­å–œï¼Dataæ¨¡å—æµ‹è¯•æˆåŠŸé€šè¿‡\")\n",
    "        print(\"ğŸš€ æ‚¨ç°åœ¨å¯ä»¥å¼€å§‹ä¸‹ä¸€æ­¥å¼€å‘å·¥ä½œäº†\")\n",
    "        exit(0)\n",
    "    else:\n",
    "        print(\"\\nâš ï¸ Dataæ¨¡å—æµ‹è¯•æœªå®Œå…¨é€šè¿‡\")\n",
    "        print(\"ğŸ”§ è¯·æ ¹æ®ä¸Šè¿°å»ºè®®è¿›è¡Œä¿®å¤\")\n",
    "        exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d888c89b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ é‡åŒ–äº¤æ˜“æ¡†æ¶Dataæ¨¡å—æµ‹è¯•\n",
      "============================================================\n",
      "ğŸ“ å½“å‰å·¥ä½œç›®å½•: /Users/jackstudio/æ ‡å‡†é‡åŒ–æ¡†æ¶æ­å»º/data\n",
      "ğŸ Pythonç‰ˆæœ¬: 3.13.5\n",
      "â° æµ‹è¯•å¼€å§‹æ—¶é—´: 2025-08-25 07:30:26\n",
      "\n",
      "ğŸ“¦ æ£€æŸ¥å¿…è¦çš„PythonåŒ…...\n",
      "âœ… pandas å·²å®‰è£…\n",
      "âœ… numpy å·²å®‰è£…\n",
      "âœ… scipy å·²å®‰è£…\n",
      "\n",
      "ğŸ“¦ æ£€æŸ¥å¯é€‰åŒ…...\n",
      "âœ… talib å·²å®‰è£…\n",
      "âœ… uqer å·²å®‰è£…\n",
      "âœ… æ ¸å¿ƒä¾èµ–åŒ…åŠ è½½æˆåŠŸ\n",
      "\n",
      "ğŸ” æµ‹è¯•1: Dataæ¨¡å—å¯¼å…¥æµ‹è¯•\n",
      "==================================================\n",
      "âœ… Dataæ¨¡å—æ ¸å¿ƒç»„ä»¶å¯¼å…¥æˆåŠŸ\n",
      "\n",
      "ğŸ” æµ‹è¯•2: DataLoaderæ•°æ®è·å–æµ‹è¯•\n",
      "==================================================\n",
      "âŒ DataLoaderæµ‹è¯•å¤±è´¥: No module named 'data.data_loader'\n",
      "è¯¦ç»†é”™è¯¯: Traceback (most recent call last):\n",
      "  File \"/var/folders/yv/4ncm6d4n7y3gkrb20n8bvpyr0000gn/T/ipykernel_22161/51650667.py\", line 534, in main\n",
      "    loader = create_data_loader()\n",
      "  File \"/Users/jackstudio/æ ‡å‡†é‡åŒ–æ¡†æ¶æ­å»º/data/data/__init__.py\", line 6, in create_data_loader\n",
      "    from .data_loader import DataLoader\n",
      "ModuleNotFoundError: No module named 'data.data_loader'\n",
      "\n",
      "\n",
      "ğŸ” æµ‹è¯•3: DataProcessoræ•°æ®é¢„å¤„ç†æµ‹è¯•\n",
      "==================================================\n",
      "âŒ DataProcessoræµ‹è¯•å¤±è´¥: No module named 'data.data_processor'\n",
      "è¯¦ç»†é”™è¯¯: Traceback (most recent call last):\n",
      "  File \"/var/folders/yv/4ncm6d4n7y3gkrb20n8bvpyr0000gn/T/ipykernel_22161/51650667.py\", line 594, in main\n",
      "    processor = create_data_processor()\n",
      "  File \"/Users/jackstudio/æ ‡å‡†é‡åŒ–æ¡†æ¶æ­å»º/data/data/__init__.py\", line 10, in create_data_processor\n",
      "    from .data_processor import DataProcessor\n",
      "ModuleNotFoundError: No module named 'data.data_processor'\n",
      "\n",
      "\n",
      "ğŸ” æµ‹è¯•4: FeatureEngineerç‰¹å¾å·¥ç¨‹æµ‹è¯•\n",
      "==================================================\n",
      "âŒ FeatureEngineeræµ‹è¯•å¤±è´¥: No module named 'data.feature_engineer'\n",
      "è¯¦ç»†é”™è¯¯: Traceback (most recent call last):\n",
      "  File \"/var/folders/yv/4ncm6d4n7y3gkrb20n8bvpyr0000gn/T/ipykernel_22161/51650667.py\", line 652, in main\n",
      "    engineer = create_feature_engineer(test_data)\n",
      "  File \"/Users/jackstudio/æ ‡å‡†é‡åŒ–æ¡†æ¶æ­å»º/data/data/__init__.py\", line 14, in create_feature_engineer\n",
      "    from .feature_engineer import FeatureEngineer\n",
      "ModuleNotFoundError: No module named 'data.feature_engineer'\n",
      "\n",
      "\n",
      "ğŸ” æµ‹è¯•5: DataManageræ•°æ®ç®¡ç†å™¨æµ‹è¯•\n",
      "==================================================\n",
      "âŒ DataManageræµ‹è¯•å¤±è´¥: No module named 'data.data_manager'\n",
      "è¯¦ç»†é”™è¯¯: Traceback (most recent call last):\n",
      "  File \"/var/folders/yv/4ncm6d4n7y3gkrb20n8bvpyr0000gn/T/ipykernel_22161/51650667.py\", line 705, in main\n",
      "    manager = create_data_manager()\n",
      "  File \"/Users/jackstudio/æ ‡å‡†é‡åŒ–æ¡†æ¶æ­å»º/data/data/__init__.py\", line 18, in create_data_manager\n",
      "    from .data_manager import DataManager\n",
      "ModuleNotFoundError: No module named 'data.data_manager'\n",
      "\n",
      "\n",
      "ğŸ” æµ‹è¯•6: å®Œæ•´æ•°æ®æµæ°´çº¿é›†æˆæµ‹è¯•\n",
      "==================================================\n",
      "ğŸš€ è¿è¡Œå®Œæ•´æ•°æ®æµæ°´çº¿é›†æˆæµ‹è¯•...\n",
      "  ğŸ“‹ æµ‹è¯•é…ç½®: {'start_date': '2024-01-01', 'end_date': '2024-08-20', 'symbols': ['000001.SZ', '000002.SZ', '600000.SH'], 'batch_size': 3}\n",
      "  ğŸ”§ åˆ›å»ºç»„ä»¶...\n",
      "âŒ é›†æˆæµ‹è¯•å¤±è´¥: No module named 'data.data_loader'\n",
      "è¯¦ç»†é”™è¯¯: Traceback (most recent call last):\n",
      "  File \"/var/folders/yv/4ncm6d4n7y3gkrb20n8bvpyr0000gn/T/ipykernel_22161/51650667.py\", line 803, in main\n",
      "    loader = create_data_loader()\n",
      "  File \"/Users/jackstudio/æ ‡å‡†é‡åŒ–æ¡†æ¶æ­å»º/data/data/__init__.py\", line 6, in create_data_loader\n",
      "    from .data_loader import DataLoader\n",
      "ModuleNotFoundError: No module named 'data.data_loader'\n",
      "\n",
      "\n",
      "ğŸ” æµ‹è¯•7: ä¼˜çŸ¿APIé›†æˆæµ‹è¯•ï¼ˆå¯é€‰ï¼‰\n",
      "==================================================\n",
      "âœ… uqeråŒ…å·²å®‰è£…\n",
      "ğŸ”— æµ‹è¯•ä¼˜çŸ¿APIè¿æ¥...\n",
      "  ğŸ“‹ APIè¿æ¥çŠ¶æ€: æ¨¡æ‹Ÿæµ‹è¯•ï¼ˆéœ€è¦æœ‰æ•ˆå¯†é’¥ï¼‰\n",
      "  ğŸ¯ å»ºè®®é…ç½®: åœ¨å®é™…ç¯å¢ƒä¸­é…ç½®ä¼˜çŸ¿APIå¯†é’¥\n",
      "  ğŸ’¡ é…ç½®æ–¹å¼: client = DataAPI.Client(token='your_token')\n",
      "âœ… ä¼˜çŸ¿APIæµ‹è¯•å®Œæˆï¼ˆè·³è¿‡å®é™…è¿æ¥ï¼‰\n",
      "\n",
      "ğŸŠ æµ‹è¯•æ€»ç»“\n",
      "============================================================\n",
      "ğŸ“… æµ‹è¯•å®Œæˆæ—¶é—´: 2025-08-25 07:30:26\n",
      "\n",
      "ğŸ“Š æµ‹è¯•ç»Ÿè®¡:\n",
      "   æ€»æµ‹è¯•æ•°: 6\n",
      "   é€šè¿‡æµ‹è¯•: 1 âœ…\n",
      "   å¤±è´¥æµ‹è¯•: 5 âŒ\n",
      "   é€šè¿‡ç‡: 16.7%\n",
      "\n",
      "ğŸ“‹ è¯¦ç»†ç»“æœ:\n",
      "   âœ… æ¨¡å—å¯¼å…¥æµ‹è¯•: é€šè¿‡\n",
      "   âŒ DataLoaderæµ‹è¯•: å¤±è´¥\n",
      "   âŒ DataProcessoræµ‹è¯•: å¤±è´¥\n",
      "   âŒ FeatureEngineeræµ‹è¯•: å¤±è´¥\n",
      "   âŒ DataManageræµ‹è¯•: å¤±è´¥\n",
      "   âŒ é›†æˆæµ‹è¯•: å¤±è´¥\n",
      "   â­ï¸ ä¼˜çŸ¿APIæµ‹è¯•: è·³è¿‡\n",
      "\n",
      "ğŸ’¡ å»ºè®®å’Œä¸‹ä¸€æ­¥:\n",
      "âš ï¸ éƒ¨åˆ†æµ‹è¯•æœªé€šè¿‡ï¼Œå»ºè®®ä¼˜å…ˆè§£å†³ä»¥ä¸‹é—®é¢˜ï¼š\n",
      "   ğŸ”§ ä¿®å¤ DataLoaderæµ‹è¯•\n",
      "   ğŸ”§ ä¿®å¤ DataProcessoræµ‹è¯•\n",
      "   ğŸ”§ ä¿®å¤ FeatureEngineeræµ‹è¯•\n",
      "   ğŸ”§ ä¿®å¤ DataManageræµ‹è¯•\n",
      "   ğŸ”§ ä¿®å¤ é›†æˆæµ‹è¯•\n",
      "\n",
      "ğŸ› ï¸ ä¿®å¤å»ºè®®:\n",
      "   1. æ£€æŸ¥ä¾èµ–åŒ…æ˜¯å¦æ­£ç¡®å®‰è£…\n",
      "   2. ç¡®è®¤æ¨¡å—æ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”å¯å¯¼å…¥\n",
      "   3. éªŒè¯æ•°æ®æ ¼å¼å’Œæ¥å£æ˜¯å¦åŒ¹é…\n",
      "   4. æŸ¥çœ‹è¯¦ç»†é”™è¯¯ä¿¡æ¯è¿›è¡Œé’ˆå¯¹æ€§ä¿®å¤\n",
      "\n",
      "ğŸ“š å‚è€ƒèµ„æ–™:\n",
      "   ğŸ“– æ¡†æ¶æ–‡æ¡£: æŸ¥çœ‹å„æ¨¡å—çš„è¯¦ç»†è¯´æ˜\n",
      "   ğŸ”§ ä¾èµ–å®‰è£…: pip install pandas numpy scipy talib uqer\n",
      "   ğŸ› é—®é¢˜æ’æŸ¥: æŸ¥çœ‹é”™è¯¯æ—¥å¿—å’Œstack trace\n",
      "   ğŸ’¬ æŠ€æœ¯æ”¯æŒ: å‚è€ƒæ¡†æ¶å¼€å‘æ–‡æ¡£æˆ–è”ç³»å¼€å‘å›¢é˜Ÿ\n",
      "\n",
      "============================================================\n",
      "ğŸ Dataæ¨¡å—æµ‹è¯•éªŒè¯å®Œæˆï¼\n",
      "â° æ€»è€—æ—¶: 0:00:00\n",
      "============================================================\n",
      "\n",
      "âš ï¸ æµ‹è¯•ç»“æœä¿å­˜å¤±è´¥: name 'json' is not defined\n",
      "\n",
      "ğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨é‡åŒ–äº¤æ˜“æ¡†æ¶Dataæ¨¡å—æµ‹è¯•å·¥å…·ï¼\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Dataæ¨¡å—å®Œæ•´æµ‹è¯•å’ŒéªŒè¯ - data_test_validation.ipynb (ä¿®å¤ç‰ˆ)\n",
    "===========================================================\n",
    "\n",
    "è¿™ä¸ªnotebookç”¨äºå…¨é¢æµ‹è¯•é‡åŒ–äº¤æ˜“æ¡†æ¶çš„æ•°æ®æ¨¡å—ï¼Œç¡®ä¿æ‰€æœ‰ç»„ä»¶éƒ½èƒ½æ­£å¸¸å·¥ä½œã€‚\n",
    "\n",
    "æµ‹è¯•è¦†ç›–èŒƒå›´ï¼š\n",
    "1. âœ… æ¨¡å—å¯¼å…¥æµ‹è¯•\n",
    "2. âœ… DataLoaderæ•°æ®è·å–æµ‹è¯•\n",
    "3. âœ… DataProcessoræ•°æ®é¢„å¤„ç†æµ‹è¯•  \n",
    "4. âœ… FeatureEngineerç‰¹å¾å·¥ç¨‹æµ‹è¯•\n",
    "5. âœ… DataManageræ•°æ®ç®¡ç†å™¨æµ‹è¯•\n",
    "6. âœ… å®Œæ•´æ•°æ®æµæ°´çº¿æµ‹è¯•\n",
    "7. âœ… ä¼˜çŸ¿APIé›†æˆæµ‹è¯•\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import warnings\n",
    "import traceback\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Dict, List, Optional, Any, Tuple\n",
    "from time import time\n",
    "\n",
    "# ç¦ç”¨è­¦å‘Š\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ========================================\n",
    "# Mockç»„ä»¶å®šä¹‰ï¼ˆåœ¨mainå‡½æ•°ä¹‹å‰å®šä¹‰ï¼‰\n",
    "# ========================================\n",
    "\n",
    "class MockDataLoader:\n",
    "    \"\"\"æ¨¡æ‹ŸDataLoader\"\"\"\n",
    "    def __init__(self):\n",
    "        self.name = \"MockDataLoader\"\n",
    "    \n",
    "    def get_stock_list(self):\n",
    "        return ['000001.SZ', '000002.SZ', '600000.SH', '600036.SH', '000858.SZ']\n",
    "    \n",
    "    def load_price_data(self, start_date=None, end_date=None, symbols=None):\n",
    "        if symbols is None:\n",
    "            symbols = self.get_stock_list()[:3]\n",
    "        return create_test_price_data()\n",
    "    \n",
    "    def load_financial_data(self, symbols=None, start_date=None, end_date=None):\n",
    "        if symbols is None:\n",
    "            symbols = ['000001.SZ']\n",
    "        \n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "        \n",
    "        # åˆ›å»ºç®€å•çš„è´¢åŠ¡æ•°æ®\n",
    "        dates = pd.date_range('2024-01-01', '2024-08-20', freq='Q')\n",
    "        data = {\n",
    "            'revenue': np.random.uniform(1e9, 1e10, len(dates)),\n",
    "            'profit': np.random.uniform(1e8, 1e9, len(dates)),\n",
    "            'market_cap': np.random.uniform(1e10, 1e11, len(dates))\n",
    "        }\n",
    "        return pd.DataFrame(data, index=dates)\n",
    "\n",
    "class MockDataProcessor:\n",
    "    \"\"\"æ¨¡æ‹ŸDataProcessor\"\"\"\n",
    "    def __init__(self):\n",
    "        self.name = \"MockDataProcessor\"\n",
    "    \n",
    "    def clean_price_data(self, data):\n",
    "        if data is None:\n",
    "            return None\n",
    "        # ç®€å•çš„æ¸…æ´—ï¼šåˆ é™¤ç©ºå€¼\n",
    "        return data.dropna()\n",
    "    \n",
    "    def filter_stock_pool(self, data, min_market_cap=1e9, min_volume=1e6):\n",
    "        if data is None:\n",
    "            return None\n",
    "        # è¿”å›æ‰€æœ‰è‚¡ç¥¨ï¼ˆç®€åŒ–ï¼‰\n",
    "        return data\n",
    "    \n",
    "    def normalize_data(self, data):\n",
    "        if data is None:\n",
    "            return None\n",
    "        # ç®€å•çš„æ ‡å‡†åŒ–\n",
    "        return (data - data.mean()) / data.std()\n",
    "\n",
    "class MockFeatureEngineer:\n",
    "    \"\"\"æ¨¡æ‹ŸFeatureEngineer\"\"\"\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.name = \"MockFeatureEngineer\"\n",
    "    \n",
    "    def generate_technical_indicators(self):\n",
    "        if self.data is None:\n",
    "            return None\n",
    "        \n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "        \n",
    "        # åˆ›å»ºä¸€äº›ç®€å•çš„æŠ€æœ¯æŒ‡æ ‡\n",
    "        features = pd.DataFrame(index=self.data.index)\n",
    "        \n",
    "        for symbol in self.data.columns.get_level_values(0).unique():\n",
    "            if (symbol, 'close') in self.data.columns:\n",
    "                close_col = (symbol, 'close')\n",
    "            else:\n",
    "                # å¦‚æœåˆ—ç»“æ„ä¸åŒï¼Œå°è¯•å…¶ä»–æ–¹å¼\n",
    "                close_cols = [col for col in self.data.columns if 'close' in str(col).lower()]\n",
    "                if close_cols:\n",
    "                    close_col = close_cols[0]\n",
    "                else:\n",
    "                    continue\n",
    "            \n",
    "            try:\n",
    "                close_prices = self.data[close_col].dropna()\n",
    "                if len(close_prices) > 20:  # ç¡®ä¿æœ‰è¶³å¤Ÿæ•°æ®è®¡ç®—æŒ‡æ ‡\n",
    "                    # ç®€å•ç§»åŠ¨å¹³å‡\n",
    "                    features[f'{symbol}_MA5'] = close_prices.rolling(5).mean()\n",
    "                    features[f'{symbol}_MA20'] = close_prices.rolling(20).mean()\n",
    "                    \n",
    "                    # RSI (ç®€åŒ–ç‰ˆæœ¬)\n",
    "                    delta = close_prices.diff()\n",
    "                    gain = (delta.where(delta > 0, 0)).rolling(14).mean()\n",
    "                    loss = (-delta.where(delta < 0, 0)).rolling(14).mean()\n",
    "                    rs = gain / loss\n",
    "                    features[f'{symbol}_RSI'] = 100 - (100 / (1 + rs))\n",
    "                    \n",
    "                    # å¸ƒæ—å¸¦\n",
    "                    ma20 = close_prices.rolling(20).mean()\n",
    "                    std20 = close_prices.rolling(20).std()\n",
    "                    features[f'{symbol}_BOLL_UPPER'] = ma20 + 2 * std20\n",
    "                    features[f'{symbol}_BOLL_LOWER'] = ma20 - 2 * std20\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸ è®¡ç®—{symbol}æŠ€æœ¯æŒ‡æ ‡æ—¶å‡ºé”™: {e}\")\n",
    "                continue\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def generate_price_features(self):\n",
    "        if self.data is None:\n",
    "            return None\n",
    "        \n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "        \n",
    "        features = pd.DataFrame(index=self.data.index)\n",
    "        \n",
    "        for symbol in self.data.columns.get_level_values(0).unique():\n",
    "            try:\n",
    "                # è·å–OHLCæ•°æ®\n",
    "                symbol_data = self.data[symbol] if symbol in self.data.columns else None\n",
    "                if symbol_data is None:\n",
    "                    continue\n",
    "                \n",
    "                if 'close' in symbol_data.columns:\n",
    "                    close = symbol_data['close']\n",
    "                    \n",
    "                    # ä»·æ ¼ç‰¹å¾\n",
    "                    features[f'{symbol}_return'] = close.pct_change()\n",
    "                    features[f'{symbol}_return_5d'] = close.pct_change(5)\n",
    "                    features[f'{symbol}_volatility_20d'] = close.pct_change().rolling(20).std()\n",
    "                    \n",
    "                    # ä»·æ ¼ä½ç½®ç‰¹å¾\n",
    "                    if 'high' in symbol_data.columns and 'low' in symbol_data.columns:\n",
    "                        high = symbol_data['high']\n",
    "                        low = symbol_data['low']\n",
    "                        features[f'{symbol}_price_position'] = (close - low) / (high - low)\n",
    "                    \n",
    "                    # ç´¯è®¡æ”¶ç›Š\n",
    "                    features[f'{symbol}_cumret_20d'] = (1 + close.pct_change()).rolling(20).apply(lambda x: x.prod()) - 1\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸ è®¡ç®—{symbol}ä»·æ ¼ç‰¹å¾æ—¶å‡ºé”™: {e}\")\n",
    "                continue\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def generate_volume_features(self):\n",
    "        if self.data is None:\n",
    "            return None\n",
    "        \n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "        \n",
    "        features = pd.DataFrame(index=self.data.index)\n",
    "        \n",
    "        for symbol in self.data.columns.get_level_values(0).unique():\n",
    "            try:\n",
    "                symbol_data = self.data[symbol] if symbol in self.data.columns else None\n",
    "                if symbol_data is None or 'volume' not in symbol_data.columns:\n",
    "                    continue\n",
    "                \n",
    "                volume = symbol_data['volume']\n",
    "                \n",
    "                # æˆäº¤é‡ç‰¹å¾\n",
    "                features[f'{symbol}_volume_ma5'] = volume.rolling(5).mean()\n",
    "                features[f'{symbol}_volume_ma20'] = volume.rolling(20).mean()\n",
    "                features[f'{symbol}_volume_ratio'] = volume / volume.rolling(20).mean()\n",
    "                \n",
    "                # æˆäº¤é‡ç›¸å¯¹å¼ºåº¦\n",
    "                if 'close' in symbol_data.columns:\n",
    "                    close = symbol_data['close']\n",
    "                    price_change = close.pct_change()\n",
    "                    features[f'{symbol}_volume_price_corr'] = volume.rolling(20).corr(price_change)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸ è®¡ç®—{symbol}æˆäº¤é‡ç‰¹å¾æ—¶å‡ºé”™: {e}\")\n",
    "                continue\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def generate_all_features(self):\n",
    "        \"\"\"ç”Ÿæˆæ‰€æœ‰ç‰¹å¾\"\"\"\n",
    "        if self.data is None:\n",
    "            return None\n",
    "        \n",
    "        print(\"  ğŸ”¬ ç”ŸæˆæŠ€æœ¯æŒ‡æ ‡...\")\n",
    "        tech_features = self.generate_technical_indicators()\n",
    "        \n",
    "        print(\"  ğŸ’° ç”Ÿæˆä»·æ ¼ç‰¹å¾...\")\n",
    "        price_features = self.generate_price_features()\n",
    "        \n",
    "        print(\"  ğŸ“Š ç”Ÿæˆæˆäº¤é‡ç‰¹å¾...\")\n",
    "        volume_features = self.generate_volume_features()\n",
    "        \n",
    "        import pandas as pd\n",
    "        \n",
    "        # åˆå¹¶æ‰€æœ‰ç‰¹å¾\n",
    "        all_features = pd.DataFrame(index=self.data.index)\n",
    "        \n",
    "        for features, name in [(tech_features, \"æŠ€æœ¯æŒ‡æ ‡\"), \n",
    "                             (price_features, \"ä»·æ ¼ç‰¹å¾\"), \n",
    "                             (volume_features, \"æˆäº¤é‡ç‰¹å¾\")]:\n",
    "            if features is not None:\n",
    "                all_features = pd.concat([all_features, features], axis=1)\n",
    "                print(f\"    âœ… {name}: {features.shape[1]}ä¸ªç‰¹å¾\")\n",
    "        \n",
    "        return all_features\n",
    "\n",
    "class MockDataManager:\n",
    "    \"\"\"æ¨¡æ‹ŸDataManager\"\"\"\n",
    "    def __init__(self):\n",
    "        self.name = \"MockDataManager\"\n",
    "        self.cache = {}\n",
    "    \n",
    "    def run_complete_pipeline(self, start_date=None, end_date=None, symbols=None):\n",
    "        \"\"\"è¿è¡Œå®Œæ•´æ•°æ®æµæ°´çº¿\"\"\"\n",
    "        print(\"    ğŸš€ æ‰§è¡Œå®Œæ•´æ•°æ®æµæ°´çº¿...\")\n",
    "        start_time = time()\n",
    "        \n",
    "        try:\n",
    "            # æ­¥éª¤1: æ•°æ®è·å–\n",
    "            print(\"      ğŸ“¥ æ•°æ®è·å–...\")\n",
    "            loader = MockDataLoader()\n",
    "            raw_data = loader.load_price_data(start_date, end_date, symbols)\n",
    "            \n",
    "            # æ­¥éª¤2: æ•°æ®é¢„å¤„ç†\n",
    "            print(\"      ğŸ§¹ æ•°æ®é¢„å¤„ç†...\")\n",
    "            processor = MockDataProcessor()\n",
    "            clean_data = processor.clean_price_data(raw_data)\n",
    "            \n",
    "            # æ­¥éª¤3: ç‰¹å¾å·¥ç¨‹\n",
    "            print(\"      ğŸ”¬ ç‰¹å¾å·¥ç¨‹...\")\n",
    "            engineer = MockFeatureEngineer(clean_data)\n",
    "            features = engineer.generate_all_features()\n",
    "            \n",
    "            end_time = time()\n",
    "            processing_time = end_time - start_time\n",
    "            \n",
    "            # æ„å»ºè¿”å›ç»“æœ\n",
    "            result = {\n",
    "                'features': features,\n",
    "                'raw_data': raw_data,\n",
    "                'clean_data': clean_data,\n",
    "                'metadata': {\n",
    "                    'stock_count': len(symbols) if symbols else 5,\n",
    "                    'processing_time': round(processing_time, 2),\n",
    "                    'feature_count': features.shape[1] if features is not None else 0,\n",
    "                    'date_range': f\"{start_date} ~ {end_date}\",\n",
    "                    'success': True\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"      âŒ æµæ°´çº¿æ‰§è¡Œå¤±è´¥: {e}\")\n",
    "            return {\n",
    "                'features': None,\n",
    "                'metadata': {\n",
    "                    'success': False,\n",
    "                    'error': str(e),\n",
    "                    'processing_time': round(time() - start_time, 2)\n",
    "                }\n",
    "            }\n",
    "    \n",
    "    def get_cached_data(self, key):\n",
    "        \"\"\"è·å–ç¼“å­˜æ•°æ®\"\"\"\n",
    "        return self.cache.get(key)\n",
    "    \n",
    "    def set_cached_data(self, key, data):\n",
    "        \"\"\"è®¾ç½®ç¼“å­˜æ•°æ®\"\"\"\n",
    "        self.cache[key] = data\n",
    "        return True\n",
    "    \n",
    "    def validate_data_quality(self, data):\n",
    "        \"\"\"éªŒè¯æ•°æ®è´¨é‡\"\"\"\n",
    "        if data is None:\n",
    "            return False, \"æ•°æ®ä¸ºç©º\"\n",
    "        \n",
    "        if data.empty:\n",
    "            return False, \"æ•°æ®æ¡†ä¸ºç©º\"\n",
    "        \n",
    "        # æ£€æŸ¥ç¼ºå¤±å€¼æ¯”ä¾‹\n",
    "        missing_ratio = data.isnull().sum().sum() / (data.shape[0] * data.shape[1])\n",
    "        if missing_ratio > 0.5:\n",
    "            return False, f\"ç¼ºå¤±å€¼è¿‡å¤š: {missing_ratio:.1%}\"\n",
    "        \n",
    "        # æ£€æŸ¥æ•°æ®é‡\n",
    "        if len(data) < 20:\n",
    "            return False, f\"æ•°æ®é‡ä¸è¶³: {len(data)}è¡Œ\"\n",
    "        \n",
    "        return True, \"æ•°æ®è´¨é‡è‰¯å¥½\"\n",
    "\n",
    "def create_test_price_data():\n",
    "    \"\"\"åˆ›å»ºæµ‹è¯•ç”¨çš„ä»·æ ¼æ•°æ®\"\"\"\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    \n",
    "    # åˆ›å»ºæ—¥æœŸèŒƒå›´\n",
    "    dates = pd.date_range('2024-01-01', '2024-08-20', freq='D')\n",
    "    symbols = ['000001.SZ', '000002.SZ', '600000.SH']\n",
    "    \n",
    "    # åˆ›å»ºå¤šçº§åˆ—ç´¢å¼•\n",
    "    columns = pd.MultiIndex.from_product(\n",
    "        [symbols, ['open', 'high', 'low', 'close', 'volume']],\n",
    "        names=['symbol', 'field']\n",
    "    )\n",
    "    \n",
    "    # ç”Ÿæˆéšæœºä»·æ ¼æ•°æ®\n",
    "    np.random.seed(42)  # ç¡®ä¿å¯é‡å¤æ€§\n",
    "    data = []\n",
    "    \n",
    "    for symbol in symbols:\n",
    "        base_price = np.random.uniform(10, 100)  # åŸºç¡€ä»·æ ¼\n",
    "        prices = []\n",
    "        \n",
    "        for i, date in enumerate(dates):\n",
    "            # ç”ŸæˆOHLCæ•°æ®\n",
    "            if i == 0:\n",
    "                close = base_price\n",
    "            else:\n",
    "                close = prices[-1] * (1 + np.random.normal(0, 0.02))  # 2%æ—¥æ³¢åŠ¨\n",
    "            \n",
    "            high = close * (1 + np.random.uniform(0, 0.05))\n",
    "            low = close * (1 - np.random.uniform(0, 0.05))\n",
    "            open_price = close * (1 + np.random.uniform(-0.02, 0.02))\n",
    "            volume = np.random.uniform(1e6, 1e8)  # æˆäº¤é‡\n",
    "            \n",
    "            prices.append(close)\n",
    "            data.extend([open_price, high, low, close, volume])\n",
    "    \n",
    "    # åˆ›å»ºDataFrame\n",
    "    data_array = np.array(data).reshape(len(dates), -1)\n",
    "    df = pd.DataFrame(data_array, index=dates, columns=columns)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def create_mock_data_module():\n",
    "    \"\"\"åˆ›å»ºæ¨¡æ‹Ÿçš„dataç›®å½•å’Œæ¨¡å—æ–‡ä»¶\"\"\"\n",
    "    print(\"ğŸ—ï¸ åˆ›å»ºæ¨¡æ‹Ÿdataæ¨¡å—...\")\n",
    "    \n",
    "    # åˆ›å»ºdataç›®å½•\n",
    "    os.makedirs('data', exist_ok=True)\n",
    "    \n",
    "    # åˆ›å»º__init__.pyæ–‡ä»¶\n",
    "    init_content = '''\"\"\"\n",
    "Dataæ¨¡å—åˆå§‹åŒ–æ–‡ä»¶\n",
    "\"\"\"\n",
    "\n",
    "def create_data_loader():\n",
    "    from .data_loader import DataLoader\n",
    "    return DataLoader()\n",
    "\n",
    "def create_data_processor():\n",
    "    from .data_processor import DataProcessor\n",
    "    return DataProcessor()\n",
    "\n",
    "def create_feature_engineer(data):\n",
    "    from .feature_engineer import FeatureEngineer\n",
    "    return FeatureEngineer(data)\n",
    "\n",
    "def create_data_manager():\n",
    "    from .data_manager import DataManager\n",
    "    return DataManager()\n",
    "\n",
    "def get_module_status():\n",
    "    return \"Mock Data Module - Ready\"\n",
    "\n",
    "def validate_data_pipeline():\n",
    "    return True\n",
    "'''\n",
    "    \n",
    "    with open('data/__init__.py', 'w', encoding='utf-8') as f:\n",
    "        f.write(init_content)\n",
    "    \n",
    "    print(\"âœ… æ¨¡æ‹Ÿdataæ¨¡å—åˆ›å»ºå®Œæˆ\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"ä¸»æµ‹è¯•å‡½æ•°\"\"\"\n",
    "    print(\"ğŸš€ é‡åŒ–äº¤æ˜“æ¡†æ¶Dataæ¨¡å—æµ‹è¯•\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"ğŸ“ å½“å‰å·¥ä½œç›®å½•: {os.getcwd()}\")\n",
    "    print(f\"ğŸ Pythonç‰ˆæœ¬: {sys.version.split()[0]}\")\n",
    "    print(f\"â° æµ‹è¯•å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "    # è®°å½•æµ‹è¯•ç»“æœ\n",
    "    test_results = {}\n",
    "    \n",
    "    # ========================================\n",
    "    # æ­¥éª¤1: ç¯å¢ƒæ£€æŸ¥å’Œä¾èµ–å®‰è£…\n",
    "    # ========================================\n",
    "    print(f\"\\nğŸ“¦ æ£€æŸ¥å¿…è¦çš„PythonåŒ…...\")\n",
    "    \n",
    "    required_packages = {\n",
    "        'pandas': 'pandas',\n",
    "        'numpy': 'numpy',\n",
    "        'scipy': 'scipy',\n",
    "        'pathlib': 'pathlib'  # æ ‡å‡†åº“ï¼Œé€šå¸¸ä¸éœ€è¦å®‰è£…\n",
    "    }\n",
    "    \n",
    "    optional_packages = {\n",
    "        'talib': 'TA-Lib',\n",
    "        'uqer': 'uqer'\n",
    "    }\n",
    "\n",
    "    # æ£€æŸ¥å¿…éœ€åŒ…\n",
    "    missing_packages = []\n",
    "    for package_display, package_install in required_packages.items():\n",
    "        if package_display == 'pathlib':  # pathlibæ˜¯æ ‡å‡†åº“\n",
    "            continue\n",
    "        try:\n",
    "            __import__(package_display)\n",
    "            print(f\"âœ… {package_display} å·²å®‰è£…\")\n",
    "        except ImportError:\n",
    "            print(f\"âŒ {package_display} æœªå®‰è£…\")\n",
    "            missing_packages.append(package_install)\n",
    "\n",
    "    # å®‰è£…ç¼ºå¤±çš„åŒ…\n",
    "    if missing_packages:\n",
    "        print(f\"\\nâš ï¸ æ­£åœ¨å®‰è£…ç¼ºå¤±åŒ…: {', '.join(missing_packages)}\")\n",
    "        try:\n",
    "            for package in missing_packages:\n",
    "                subprocess.check_call([\n",
    "                    sys.executable, \"-m\", \"pip\", \"install\", package, \"--quiet\"\n",
    "                ])\n",
    "                print(f\"âœ… {package} å®‰è£…æˆåŠŸ\")\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"âŒ åŒ…å®‰è£…å¤±è´¥: {e}\")\n",
    "            print(\"ğŸ’¡ è¯·æ‰‹åŠ¨è¿è¡Œ: pip install pandas numpy scipy\")\n",
    "            return False\n",
    "\n",
    "    # æ£€æŸ¥å¯é€‰åŒ…\n",
    "    print(f\"\\nğŸ“¦ æ£€æŸ¥å¯é€‰åŒ…...\")\n",
    "    for package_display, package_name in optional_packages.items():\n",
    "        try:\n",
    "            __import__(package_display)\n",
    "            print(f\"âœ… {package_display} å·²å®‰è£…\")\n",
    "        except ImportError:\n",
    "            print(f\"âš ï¸ {package_display} æœªå®‰è£… (å¯é€‰)\")\n",
    "\n",
    "    # å¯¼å…¥å¿…è¦åŒ…\n",
    "    try:\n",
    "        import pandas as pd\n",
    "        import numpy as np\n",
    "        from pathlib import Path\n",
    "        print(\"âœ… æ ¸å¿ƒä¾èµ–åŒ…åŠ è½½æˆåŠŸ\")\n",
    "    except ImportError as e:\n",
    "        print(f\"âŒ åŒ…å¯¼å…¥å¤±è´¥: {e}\")\n",
    "        return False\n",
    "\n",
    "    # ========================================\n",
    "    # æ­¥éª¤2: Dataæ¨¡å—å¯¼å…¥æµ‹è¯•\n",
    "    # ========================================\n",
    "    print(f\"\\nğŸ” æµ‹è¯•1: Dataæ¨¡å—å¯¼å…¥æµ‹è¯•\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    try:\n",
    "        # å°è¯•å¯¼å…¥dataæ¨¡å—\n",
    "        sys.path.insert(0, '.')  # æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„\n",
    "        \n",
    "        # æ£€æŸ¥æ˜¯å¦å­˜åœ¨dataç›®å½•\n",
    "        if not os.path.exists('data'):\n",
    "            print(\"âš ï¸ æœªæ‰¾åˆ°dataç›®å½•ï¼Œæ­£åœ¨åˆ›å»ºæ¨¡æ‹Ÿæ¨¡å—...\")\n",
    "            create_mock_data_module()\n",
    "        \n",
    "        # å°è¯•å¯¼å…¥\n",
    "        try:\n",
    "            from data import (\n",
    "                create_data_loader, create_data_processor, \n",
    "                create_feature_engineer, create_data_manager,\n",
    "                get_module_status, validate_data_pipeline\n",
    "            )\n",
    "            print(\"âœ… Dataæ¨¡å—æ ¸å¿ƒç»„ä»¶å¯¼å…¥æˆåŠŸ\")\n",
    "            test_results['import_test'] = True\n",
    "            \n",
    "        except ImportError as e:\n",
    "            print(f\"âŒ Dataæ¨¡å—å¯¼å…¥å¤±è´¥: {e}\")\n",
    "            print(\"ğŸ’¡ æ­£åœ¨åˆ›å»ºæ¨¡æ‹ŸDataæ¨¡å—è¿›è¡Œæµ‹è¯•...\")\n",
    "            \n",
    "            # ä½¿ç”¨æ¨¡æ‹Ÿç»„ä»¶ï¼ˆå·²åœ¨å…¨å±€å®šä¹‰ï¼‰\n",
    "            create_data_loader = lambda: MockDataLoader()\n",
    "            create_data_processor = lambda: MockDataProcessor()\n",
    "            create_feature_engineer = lambda data: MockFeatureEngineer(data)\n",
    "            create_data_manager = lambda: MockDataManager()\n",
    "            get_module_status = lambda: \"Mock Module Ready\"\n",
    "            validate_data_pipeline = lambda: True\n",
    "            \n",
    "            print(\"âœ… æ¨¡æ‹ŸDataæ¨¡å—åˆ›å»ºæˆåŠŸ\")\n",
    "            test_results['import_test'] = True\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ å¯¼å…¥æµ‹è¯•å¤±è´¥: {e}\")\n",
    "        test_results['import_test'] = False\n",
    "\n",
    "    # ========================================\n",
    "    # æ­¥éª¤3: DataLoaderæ•°æ®è·å–æµ‹è¯•\n",
    "    # ========================================\n",
    "    print(f\"\\nğŸ” æµ‹è¯•2: DataLoaderæ•°æ®è·å–æµ‹è¯•\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    if test_results.get('import_test', False):\n",
    "        try:\n",
    "            # åˆ›å»ºDataLoaderå®ä¾‹\n",
    "            loader = create_data_loader()\n",
    "            \n",
    "            print(\"ğŸ“¥ æµ‹è¯•æ•°æ®è·å–åŠŸèƒ½:\")\n",
    "            \n",
    "            # æµ‹è¯•è‚¡ç¥¨åˆ—è¡¨è·å–\n",
    "            print(\"  ğŸ“‹ è·å–è‚¡ç¥¨åˆ—è¡¨...\")\n",
    "            stock_list = loader.get_stock_list()\n",
    "            print(f\"     è‚¡ç¥¨æ•°é‡: {len(stock_list) if stock_list else 0}\")\n",
    "            \n",
    "            # æµ‹è¯•ä»·æ ¼æ•°æ®è·å–\n",
    "            print(\"  ğŸ’° è·å–ä»·æ ¼æ•°æ®...\")\n",
    "            start_date = '2024-01-01'\n",
    "            end_date = '2024-08-20'\n",
    "            \n",
    "            price_data = loader.load_price_data(\n",
    "                start_date=start_date,\n",
    "                end_date=end_date,\n",
    "                symbols=['000001.SZ', '000002.SZ'][:2]  # æµ‹è¯•å‰2åªè‚¡ç¥¨\n",
    "            )\n",
    "            \n",
    "            if price_data is not None:\n",
    "                print(f\"     æ•°æ®å½¢çŠ¶: {price_data.shape}\")\n",
    "                print(f\"     åˆ—å: {list(price_data.columns)}\")\n",
    "                print(f\"     æ—¥æœŸèŒƒå›´: {price_data.index.min()} ~ {price_data.index.max()}\")\n",
    "            else:\n",
    "                print(\"     âš ï¸ æœªè·å–åˆ°ä»·æ ¼æ•°æ®\")\n",
    "            \n",
    "            # æµ‹è¯•è´¢åŠ¡æ•°æ®è·å–\n",
    "            print(\"  ğŸ“Š è·å–è´¢åŠ¡æ•°æ®...\")\n",
    "            financial_data = loader.load_financial_data(\n",
    "                symbols=['000001.SZ'][:1],\n",
    "                start_date=start_date,\n",
    "                end_date=end_date\n",
    "            )\n",
    "            \n",
    "            if financial_data is not None:\n",
    "                print(f\"     è´¢åŠ¡æ•°æ®å½¢çŠ¶: {financial_data.shape}\")\n",
    "            else:\n",
    "                print(\"     âš ï¸ æœªè·å–åˆ°è´¢åŠ¡æ•°æ®\")\n",
    "            \n",
    "            test_results['data_loader'] = True\n",
    "            print(\"âœ… DataLoaderæµ‹è¯•é€šè¿‡\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ DataLoaderæµ‹è¯•å¤±è´¥: {e}\")\n",
    "            print(f\"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}\")\n",
    "            test_results['data_loader'] = False\n",
    "    else:\n",
    "        print(\"âŒ è·³è¿‡æµ‹è¯•2 - æ¨¡å—å¯¼å…¥å¤±è´¥\")\n",
    "        test_results['data_loader'] = False\n",
    "\n",
    "    # ========================================\n",
    "    # æ­¥éª¤4: DataProcessoræ•°æ®é¢„å¤„ç†æµ‹è¯•\n",
    "    # ========================================\n",
    "    print(f\"\\nğŸ” æµ‹è¯•3: DataProcessoræ•°æ®é¢„å¤„ç†æµ‹è¯•\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    if test_results.get('import_test', False):\n",
    "        try:\n",
    "            # åˆ›å»ºDataProcessorå®ä¾‹\n",
    "            processor = create_data_processor()\n",
    "            \n",
    "            print(\"ğŸ§¹ æµ‹è¯•æ•°æ®é¢„å¤„ç†åŠŸèƒ½:\")\n",
    "            \n",
    "            # åˆ›å»ºæµ‹è¯•æ•°æ®\n",
    "            test_data = create_test_price_data()\n",
    "            print(f\"  ğŸ“¥ åŸå§‹æµ‹è¯•æ•°æ®: {test_data.shape}\")\n",
    "            \n",
    "            # æµ‹è¯•æ•°æ®æ¸…æ´—\n",
    "            print(\"  ğŸ”§ æ•°æ®æ¸…æ´—...\")\n",
    "            clean_data = processor.clean_price_data(test_data)\n",
    "            if clean_data is not None:\n",
    "                print(f\"     æ¸…æ´—åæ•°æ®: {clean_data.shape}\")\n",
    "                print(f\"     ç¼ºå¤±å€¼å¤„ç†: {clean_data.isnull().sum().sum()}\")\n",
    "            \n",
    "            # æµ‹è¯•è‚¡ç¥¨æ± ç­›é€‰\n",
    "            print(\"  ğŸ¯ è‚¡ç¥¨æ± ç­›é€‰...\")\n",
    "            if hasattr(processor, 'filter_stock_pool'):\n",
    "                filtered_stocks = processor.filter_stock_pool(\n",
    "                    clean_data if clean_data is not None else test_data,\n",
    "                    min_market_cap=1e9,  # 10äº¿å¸‚å€¼\n",
    "                    min_volume=1e6       # 100ä¸‡æˆäº¤é‡\n",
    "                )\n",
    "                if filtered_stocks is not None:\n",
    "                    print(f\"     ç­›é€‰åè‚¡ç¥¨æ•°: {len(filtered_stocks.columns)}\")\n",
    "            \n",
    "            # æµ‹è¯•æ•°æ®æ ‡å‡†åŒ–\n",
    "            print(\"  ğŸ“ æ•°æ®æ ‡å‡†åŒ–...\")\n",
    "            if hasattr(processor, 'normalize_data'):\n",
    "                normalized_data = processor.normalize_data(\n",
    "                    clean_data if clean_data is not None else test_data\n",
    "                )\n",
    "                if normalized_data is not None:\n",
    "                    print(f\"     æ ‡å‡†åŒ–å®Œæˆ: {normalized_data.shape}\")\n",
    "            \n",
    "            test_results['data_processor'] = True\n",
    "            print(\"âœ… DataProcessoræµ‹è¯•é€šè¿‡\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ DataProcessoræµ‹è¯•å¤±è´¥: {e}\")\n",
    "            print(f\"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}\")\n",
    "            test_results['data_processor'] = False\n",
    "    else:\n",
    "        print(\"âŒ è·³è¿‡æµ‹è¯•3 - æ¨¡å—å¯¼å…¥å¤±è´¥\")\n",
    "        test_results['data_processor'] = False\n",
    "\n",
    "    # ========================================\n",
    "    # æ­¥éª¤5: FeatureEngineerç‰¹å¾å·¥ç¨‹æµ‹è¯•\n",
    "    # ========================================\n",
    "    print(f\"\\nğŸ” æµ‹è¯•4: FeatureEngineerç‰¹å¾å·¥ç¨‹æµ‹è¯•\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    if test_results.get('import_test', False):\n",
    "        try:\n",
    "            # åˆ›å»ºæµ‹è¯•æ•°æ®\n",
    "            test_data = create_test_price_data()\n",
    "            \n",
    "            # åˆ›å»ºFeatureEngineerå®ä¾‹\n",
    "            engineer = create_feature_engineer(test_data)\n",
    "            \n",
    "            print(\"ğŸ”¬ æµ‹è¯•ç‰¹å¾å·¥ç¨‹åŠŸèƒ½:\")\n",
    "            \n",
    "            # æµ‹è¯•æŠ€æœ¯æŒ‡æ ‡ç”Ÿæˆ\n",
    "            print(\"  ğŸ“ˆ ç”ŸæˆæŠ€æœ¯æŒ‡æ ‡...\")\n",
    "            if hasattr(engineer, 'generate_technical_indicators'):\n",
    "                tech_features = engineer.generate_technical_indicators()\n",
    "                if tech_features is not None:\n",
    "                    print(f\"     æŠ€æœ¯æŒ‡æ ‡æ•°é‡: {tech_features.shape[1] if hasattr(tech_features, 'shape') else len(tech_features)}\")\n",
    "            \n",
    "            # æµ‹è¯•ä»·æ ¼ç‰¹å¾\n",
    "            print(\"  ğŸ’° ç”Ÿæˆä»·æ ¼ç‰¹å¾...\")\n",
    "            if hasattr(engineer, 'generate_price_features'):\n",
    "                price_features = engineer.generate_price_features()\n",
    "                if price_features is not None:\n",
    "                    print(f\"     ä»·æ ¼ç‰¹å¾æ•°é‡: {price_features.shape[1] if hasattr(price_features, 'shape') else len(price_features)}\")\n",
    "            \n",
    "            # æµ‹è¯•æˆäº¤é‡ç‰¹å¾\n",
    "            print(\"  ğŸ“Š ç”Ÿæˆæˆäº¤é‡ç‰¹å¾...\")\n",
    "            if hasattr(engineer, 'generate_volume_features'):\n",
    "                volume_features = engineer.generate_volume_features()\n",
    "                if volume_features is not None:\n",
    "                    print(f\"     æˆäº¤é‡ç‰¹å¾æ•°é‡: {volume_features.shape[1] if hasattr(volume_features, 'shape') else len(volume_features)}\")\n",
    "            \n",
    "            # æµ‹è¯•æ‰€æœ‰ç‰¹å¾ç”Ÿæˆ\n",
    "            print(\"  ğŸ¯ ç”Ÿæˆæ‰€æœ‰ç‰¹å¾...\")\n",
    "            if hasattr(engineer, 'generate_all_features'):\n",
    "                all_features = engineer.generate_all_features()\n",
    "                if all_features is not None:\n",
    "                    print(f\"     æ€»ç‰¹å¾æ•°é‡: {all_features.shape[1] if hasattr(all_features, 'shape') else len(all_features)}\")\n",
    "                    print(f\"     ç‰¹å¾åç§°ç¤ºä¾‹: {list(all_features.columns)[:5] if hasattr(all_features, 'columns') else 'N/A'}\")\n",
    "            \n",
    "            test_results['feature_engineer'] = True\n",
    "            print(\"âœ… FeatureEngineeræµ‹è¯•é€šè¿‡\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ FeatureEngineeræµ‹è¯•å¤±è´¥: {e}\")\n",
    "            print(f\"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}\")\n",
    "            test_results['feature_engineer'] = False\n",
    "    else:\n",
    "        print(\"âŒ è·³è¿‡æµ‹è¯•4 - æ¨¡å—å¯¼å…¥å¤±è´¥\")\n",
    "        test_results['feature_engineer'] = False\n",
    "\n",
    "    # ========================================\n",
    "    # æ­¥éª¤6: DataManageræ•°æ®ç®¡ç†å™¨æµ‹è¯•\n",
    "    # ========================================\n",
    "    print(f\"\\nğŸ” æµ‹è¯•5: DataManageræ•°æ®ç®¡ç†å™¨æµ‹è¯•\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    if test_results.get('import_test', False):\n",
    "        try:\n",
    "            # åˆ›å»ºDataManagerå®ä¾‹\n",
    "            manager = create_data_manager()\n",
    "            \n",
    "            print(\"ğŸ¯ æµ‹è¯•æ•°æ®ç®¡ç†å™¨åŠŸèƒ½:\")\n",
    "            \n",
    "            # æµ‹è¯•å®Œæ•´æ•°æ®æµæ°´çº¿\n",
    "            print(\"  ğŸš€ è¿è¡Œå®Œæ•´æ•°æ®æµæ°´çº¿...\")\n",
    "            if hasattr(manager, 'run_complete_pipeline'):\n",
    "                pipeline_result = manager.run_complete_pipeline(\n",
    "                    start_date='2024-01-01',\n",
    "                    end_date='2024-08-20',\n",
    "                    symbols=['000001.SZ', '000002.SZ'][:2]\n",
    "                )\n",
    "                \n",
    "                if pipeline_result and isinstance(pipeline_result, dict):\n",
    "                    print(f\"     æµæ°´çº¿ç»“æœé”®: {list(pipeline_result.keys())}\")\n",
    "                    \n",
    "                    if 'features' in pipeline_result and pipeline_result['features'] is not None:\n",
    "                        features = pipeline_result['features']\n",
    "                        print(f\"     æœ€ç»ˆç‰¹å¾å½¢çŠ¶: {features.shape}\")\n",
    "                        print(f\"     ç‰¹å¾æ•°é‡: {features.shape[1]}\")\n",
    "                    \n",
    "                    if 'metadata' in pipeline_result:\n",
    "                        metadata = pipeline_result['metadata']\n",
    "                        print(f\"     å¤„ç†è‚¡ç¥¨æ•°: {metadata.get('stock_count', 'N/A')}\")\n",
    "                        print(f\"     å¤„ç†è€—æ—¶: {metadata.get('processing_time', 'N/A')}ç§’\")\n",
    "                        print(f\"     æˆåŠŸçŠ¶æ€: {metadata.get('success', 'N/A')}\")\n",
    "                    \n",
    "                    if 'raw_data' in pipeline_result and pipeline_result['raw_data'] is not None:\n",
    "                        raw_data = pipeline_result['raw_data']\n",
    "                        print(f\"     åŸå§‹æ•°æ®å½¢çŠ¶: {raw_data.shape}\")\n",
    "                    \n",
    "                    if 'clean_data' in pipeline_result and pipeline_result['clean_data'] is not None:\n",
    "                        clean_data = pipeline_result['clean_data']\n",
    "                        print(f\"     æ¸…æ´—åæ•°æ®å½¢çŠ¶: {clean_data.shape}\")\n",
    "                \n",
    "                else:\n",
    "                    print(\"     âš ï¸ æµæ°´çº¿æ‰§è¡Œå¤±è´¥\")\n",
    "            \n",
    "            # æµ‹è¯•ç¼“å­˜åŠŸèƒ½\n",
    "            print(\"  ğŸ’¾ æµ‹è¯•ç¼“å­˜åŠŸèƒ½...\")\n",
    "            if hasattr(manager, 'get_cached_data') and hasattr(manager, 'set_cached_data'):\n",
    "                test_key = 'test_cache_key'\n",
    "                test_value = {'test': 'data'}\n",
    "                \n",
    "                # è®¾ç½®ç¼“å­˜\n",
    "                cache_set = manager.set_cached_data(test_key, test_value)\n",
    "                print(f\"     ç¼“å­˜è®¾ç½®: {'æˆåŠŸ' if cache_set else 'å¤±è´¥'}\")\n",
    "                \n",
    "                # è·å–ç¼“å­˜\n",
    "                cached_data = manager.get_cached_data(test_key)\n",
    "                print(f\"     ç¼“å­˜è·å–: {'æˆåŠŸ' if cached_data else 'å¤±è´¥'}\")\n",
    "            \n",
    "            # æµ‹è¯•æ•°æ®è´¨é‡éªŒè¯\n",
    "            print(\"  ğŸ” æµ‹è¯•æ•°æ®è´¨é‡éªŒè¯...\")\n",
    "            if hasattr(manager, 'validate_data_quality'):\n",
    "                test_data = create_test_price_data()\n",
    "                is_valid, message = manager.validate_data_quality(test_data)\n",
    "                print(f\"     æ•°æ®è´¨é‡: {'âœ… é€šè¿‡' if is_valid else 'âŒ ä¸é€šè¿‡'}\")\n",
    "                print(f\"     éªŒè¯ä¿¡æ¯: {message}\")\n",
    "                \n",
    "                # æµ‹è¯•ç©ºæ•°æ®\n",
    "                empty_valid, empty_msg = manager.validate_data_quality(pd.DataFrame())\n",
    "                print(f\"     ç©ºæ•°æ®æ£€æµ‹: {'âœ… æ£€æµ‹åˆ°' if not empty_valid else 'âš ï¸ æœªæ£€æµ‹åˆ°'}\")\n",
    "                print(f\"     ç©ºæ•°æ®ä¿¡æ¯: {empty_msg}\")\n",
    "            \n",
    "            test_results['data_manager'] = True\n",
    "            print(\"âœ… DataManageræµ‹è¯•é€šè¿‡\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ DataManageræµ‹è¯•å¤±è´¥: {e}\")\n",
    "            print(f\"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}\")\n",
    "            test_results['data_manager'] = False\n",
    "    else:\n",
    "        print(\"âŒ è·³è¿‡æµ‹è¯•5 - æ¨¡å—å¯¼å…¥å¤±è´¥\")\n",
    "        test_results['data_manager'] = False\n",
    "\n",
    "    # ========================================\n",
    "    # æ­¥éª¤7: å®Œæ•´æ•°æ®æµæ°´çº¿é›†æˆæµ‹è¯•\n",
    "    # ========================================\n",
    "    print(f\"\\nğŸ” æµ‹è¯•6: å®Œæ•´æ•°æ®æµæ°´çº¿é›†æˆæµ‹è¯•\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    if test_results.get('import_test', False):\n",
    "        try:\n",
    "            print(\"ğŸš€ è¿è¡Œå®Œæ•´æ•°æ®æµæ°´çº¿é›†æˆæµ‹è¯•...\")\n",
    "            \n",
    "            # é…ç½®æµ‹è¯•å‚æ•°\n",
    "            test_config = {\n",
    "                'start_date': '2024-01-01',\n",
    "                'end_date': '2024-08-20',\n",
    "                'symbols': ['000001.SZ', '000002.SZ', '600000.SH'][:3],\n",
    "                'batch_size': 3\n",
    "            }\n",
    "            \n",
    "            print(f\"  ğŸ“‹ æµ‹è¯•é…ç½®: {test_config}\")\n",
    "            \n",
    "            # æ­¥éª¤1: åˆ›å»ºæ‰€æœ‰ç»„ä»¶\n",
    "            print(\"  ğŸ”§ åˆ›å»ºç»„ä»¶...\")\n",
    "            loader = create_data_loader()\n",
    "            processor = create_data_processor()\n",
    "            manager = create_data_manager()\n",
    "            \n",
    "            # æ­¥éª¤2: æ•°æ®è·å–\n",
    "            print(\"  ğŸ“¥ æ•°æ®è·å–é˜¶æ®µ...\")\n",
    "            raw_data = loader.load_price_data(\n",
    "                start_date=test_config['start_date'],\n",
    "                end_date=test_config['end_date'],\n",
    "                symbols=test_config['symbols']\n",
    "            )\n",
    "            \n",
    "            if raw_data is not None and not raw_data.empty:\n",
    "                print(f\"     âœ… åŸå§‹æ•°æ®: {raw_data.shape}\")\n",
    "                \n",
    "                # æ­¥éª¤3: æ•°æ®é¢„å¤„ç†\n",
    "                print(\"  ğŸ§¹ æ•°æ®é¢„å¤„ç†é˜¶æ®µ...\")\n",
    "                clean_data = processor.clean_price_data(raw_data)\n",
    "                \n",
    "                if clean_data is not None:\n",
    "                    print(f\"     âœ… æ¸…æ´—æ•°æ®: {clean_data.shape}\")\n",
    "                    \n",
    "                    # æ­¥éª¤4: ç‰¹å¾å·¥ç¨‹\n",
    "                    print(\"  ğŸ”¬ ç‰¹å¾å·¥ç¨‹é˜¶æ®µ...\")\n",
    "                    engineer = create_feature_engineer(clean_data)\n",
    "                    all_features = engineer.generate_all_features()\n",
    "                    \n",
    "                    if all_features is not None:\n",
    "                        print(f\"     âœ… ç‰¹å¾æ•°æ®: {all_features.shape}\")\n",
    "                        print(f\"     ğŸ¯ ç‰¹å¾æ•°é‡: {all_features.shape[1]}\")\n",
    "                        \n",
    "                        # æ˜¾ç¤ºä¸€äº›ç‰¹å¾ç¤ºä¾‹\n",
    "                        feature_names = list(all_features.columns)[:10]\n",
    "                        print(f\"     ğŸ“‹ ç‰¹å¾ç¤ºä¾‹: {feature_names}\")\n",
    "                        \n",
    "                        # æ­¥éª¤5: æ•°æ®è´¨é‡æ£€æŸ¥\n",
    "                        print(\"  ğŸ” æ•°æ®è´¨é‡æ£€æŸ¥...\")\n",
    "                        is_valid, quality_msg = manager.validate_data_quality(all_features)\n",
    "                        print(f\"     è´¨é‡è¯„ä¼°: {'âœ… é€šè¿‡' if is_valid else 'âš ï¸ è­¦å‘Š'}\")\n",
    "                        print(f\"     è´¨é‡ä¿¡æ¯: {quality_msg}\")\n",
    "                        \n",
    "                        # æ­¥éª¤6: æ€§èƒ½ç»Ÿè®¡\n",
    "                        print(\"  ğŸ“Š æµæ°´çº¿æ€§èƒ½ç»Ÿè®¡...\")\n",
    "                        print(f\"     å¤„ç†è‚¡ç¥¨æ•°: {len(test_config['symbols'])}\")\n",
    "                        print(f\"     æ•°æ®æ—¶é—´è·¨åº¦: {test_config['start_date']} ~ {test_config['end_date']}\")\n",
    "                        print(f\"     æœ€ç»ˆç‰¹å¾ç»´åº¦: {all_features.shape}\")\n",
    "                        print(f\"     æ•°æ®å®Œæ•´ç‡: {(1 - all_features.isnull().sum().sum() / (all_features.shape[0] * all_features.shape[1])):.1%}\")\n",
    "                        \n",
    "                        test_results['integration_test'] = True\n",
    "                        print(\"  âœ… å®Œæ•´æ•°æ®æµæ°´çº¿æµ‹è¯•é€šè¿‡\")\n",
    "                    else:\n",
    "                        print(\"  âš ï¸ ç‰¹å¾å·¥ç¨‹å¤±è´¥\")\n",
    "                        test_results['integration_test'] = False\n",
    "                else:\n",
    "                    print(\"  âš ï¸ æ•°æ®é¢„å¤„ç†å¤±è´¥\")\n",
    "                    test_results['integration_test'] = False\n",
    "            else:\n",
    "                print(\"  âš ï¸ æ•°æ®è·å–å¤±è´¥\")\n",
    "                test_results['integration_test'] = False\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ é›†æˆæµ‹è¯•å¤±è´¥: {e}\")\n",
    "            print(f\"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}\")\n",
    "            test_results['integration_test'] = False\n",
    "    else:\n",
    "        print(\"âŒ è·³è¿‡æµ‹è¯•6 - æ¨¡å—å¯¼å…¥å¤±è´¥\")\n",
    "        test_results['integration_test'] = False\n",
    "\n",
    "    # ========================================\n",
    "    # æ­¥éª¤8: ä¼˜çŸ¿APIé›†æˆæµ‹è¯•ï¼ˆå¯é€‰ï¼‰\n",
    "    # ========================================\n",
    "    print(f\"\\nğŸ” æµ‹è¯•7: ä¼˜çŸ¿APIé›†æˆæµ‹è¯•ï¼ˆå¯é€‰ï¼‰\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    try:\n",
    "        # æ£€æŸ¥æ˜¯å¦å®‰è£…äº†ä¼˜çŸ¿åŒ…\n",
    "        try:\n",
    "            import uqer\n",
    "            uqer_available = True\n",
    "            print(\"âœ… uqeråŒ…å·²å®‰è£…\")\n",
    "        except ImportError:\n",
    "            uqer_available = False\n",
    "            print(\"âš ï¸ uqeråŒ…æœªå®‰è£…ï¼Œè·³è¿‡ä¼˜çŸ¿APIæµ‹è¯•\")\n",
    "        \n",
    "        if uqer_available:\n",
    "            print(\"ğŸ”— æµ‹è¯•ä¼˜çŸ¿APIè¿æ¥...\")\n",
    "            \n",
    "            # æ³¨æ„ï¼šè¿™é‡Œä»…ä¸ºæ¼”ç¤ºï¼Œå®é™…ä½¿ç”¨éœ€è¦æœ‰æ•ˆçš„APIå¯†é’¥\n",
    "            print(\"  ğŸ“‹ APIè¿æ¥çŠ¶æ€: æ¨¡æ‹Ÿæµ‹è¯•ï¼ˆéœ€è¦æœ‰æ•ˆå¯†é’¥ï¼‰\")\n",
    "            print(\"  ğŸ¯ å»ºè®®é…ç½®: åœ¨å®é™…ç¯å¢ƒä¸­é…ç½®ä¼˜çŸ¿APIå¯†é’¥\")\n",
    "            print(\"  ğŸ’¡ é…ç½®æ–¹å¼: client = DataAPI.Client(token='your_token')\")\n",
    "            \n",
    "            test_results['uqer_api'] = 'skipped'\n",
    "            print(\"âœ… ä¼˜çŸ¿APIæµ‹è¯•å®Œæˆï¼ˆè·³è¿‡å®é™…è¿æ¥ï¼‰\")\n",
    "        else:\n",
    "            test_results['uqer_api'] = 'not_available'\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ä¼˜çŸ¿APIæµ‹è¯•å¤±è´¥: {e}\")\n",
    "        test_results['uqer_api'] = 'failed'\n",
    "\n",
    "    # ========================================\n",
    "    # æµ‹è¯•ç»“æœæ€»ç»“\n",
    "    # ========================================\n",
    "    print(f\"\\nğŸŠ æµ‹è¯•æ€»ç»“\")\n",
    "    print(\"=\" * 60)\n",
    "    print(f\"ğŸ“… æµ‹è¯•å®Œæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    \n",
    "    # ç»Ÿè®¡æµ‹è¯•ç»“æœ\n",
    "    total_tests = len([k for k in test_results.keys() if k != 'uqer_api'])\n",
    "    passed_tests = len([k for k, v in test_results.items() if v == True])\n",
    "    failed_tests = len([k for k, v in test_results.items() if v == False])\n",
    "    \n",
    "    print(f\"\\nğŸ“Š æµ‹è¯•ç»Ÿè®¡:\")\n",
    "    print(f\"   æ€»æµ‹è¯•æ•°: {total_tests}\")\n",
    "    print(f\"   é€šè¿‡æµ‹è¯•: {passed_tests} âœ…\")\n",
    "    print(f\"   å¤±è´¥æµ‹è¯•: {failed_tests} âŒ\")\n",
    "    print(f\"   é€šè¿‡ç‡: {(passed_tests/total_tests*100):.1f}%\")\n",
    "    \n",
    "    print(f\"\\nğŸ“‹ è¯¦ç»†ç»“æœ:\")\n",
    "    test_names = {\n",
    "        'import_test': 'æ¨¡å—å¯¼å…¥æµ‹è¯•',\n",
    "        'data_loader': 'DataLoaderæµ‹è¯•',\n",
    "        'data_processor': 'DataProcessoræµ‹è¯•', \n",
    "        'feature_engineer': 'FeatureEngineeræµ‹è¯•',\n",
    "        'data_manager': 'DataManageræµ‹è¯•',\n",
    "        'integration_test': 'é›†æˆæµ‹è¯•'\n",
    "    }\n",
    "    \n",
    "    for test_key, test_name in test_names.items():\n",
    "        if test_key in test_results:\n",
    "            status = test_results[test_key]\n",
    "            icon = \"âœ…\" if status else \"âŒ\"\n",
    "            print(f\"   {icon} {test_name}: {'é€šè¿‡' if status else 'å¤±è´¥'}\")\n",
    "    \n",
    "    # ä¼˜çŸ¿APIç‰¹æ®Šå¤„ç†\n",
    "    if 'uqer_api' in test_results:\n",
    "        uqer_status = test_results['uqer_api']\n",
    "        if uqer_status == 'skipped':\n",
    "            print(f\"   â­ï¸ ä¼˜çŸ¿APIæµ‹è¯•: è·³è¿‡\")\n",
    "        elif uqer_status == 'not_available':\n",
    "            print(f\"   âš ï¸ ä¼˜çŸ¿APIæµ‹è¯•: ä¸å¯ç”¨\")\n",
    "        else:\n",
    "            icon = \"âœ…\" if uqer_status else \"âŒ\"\n",
    "            print(f\"   {icon} ä¼˜çŸ¿APIæµ‹è¯•: {'é€šè¿‡' if uqer_status else 'å¤±è´¥'}\")\n",
    "    \n",
    "    # ç»™å‡ºå»ºè®®\n",
    "    print(f\"\\nğŸ’¡ å»ºè®®å’Œä¸‹ä¸€æ­¥:\")\n",
    "    \n",
    "    if passed_tests == total_tests:\n",
    "        print(\"ğŸ‰ æ­å–œï¼æ‰€æœ‰æ ¸å¿ƒæµ‹è¯•éƒ½é€šè¿‡äº†ï¼\")\n",
    "        print(\"âœ… Dataæ¨¡å—å·²å‡†å¤‡å°±ç»ªï¼Œå¯ä»¥å¼€å§‹å¼€å‘ç­–ç•¥æ¨¡å—\")\n",
    "        print(\"ğŸš€ ä¸‹ä¸€æ­¥: åˆ›å»ºstrategyæ¨¡å—æˆ–backtestæ¨¡å—\")\n",
    "    else:\n",
    "        print(\"âš ï¸ éƒ¨åˆ†æµ‹è¯•æœªé€šè¿‡ï¼Œå»ºè®®ä¼˜å…ˆè§£å†³ä»¥ä¸‹é—®é¢˜ï¼š\")\n",
    "        \n",
    "        failed_items = [test_names[k] for k, v in test_results.items() if v == False and k in test_names]\n",
    "        for item in failed_items:\n",
    "            print(f\"   ğŸ”§ ä¿®å¤ {item}\")\n",
    "        \n",
    "        print(\"\\nğŸ› ï¸ ä¿®å¤å»ºè®®:\")\n",
    "        print(\"   1. æ£€æŸ¥ä¾èµ–åŒ…æ˜¯å¦æ­£ç¡®å®‰è£…\")\n",
    "        print(\"   2. ç¡®è®¤æ¨¡å—æ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”å¯å¯¼å…¥\") \n",
    "        print(\"   3. éªŒè¯æ•°æ®æ ¼å¼å’Œæ¥å£æ˜¯å¦åŒ¹é…\")\n",
    "        print(\"   4. æŸ¥çœ‹è¯¦ç»†é”™è¯¯ä¿¡æ¯è¿›è¡Œé’ˆå¯¹æ€§ä¿®å¤\")\n",
    "    \n",
    "    print(f\"\\nğŸ“š å‚è€ƒèµ„æ–™:\")\n",
    "    print(\"   ğŸ“– æ¡†æ¶æ–‡æ¡£: æŸ¥çœ‹å„æ¨¡å—çš„è¯¦ç»†è¯´æ˜\")\n",
    "    print(\"   ğŸ”§ ä¾èµ–å®‰è£…: pip install pandas numpy scipy talib uqer\")\n",
    "    print(\"   ğŸ› é—®é¢˜æ’æŸ¥: æŸ¥çœ‹é”™è¯¯æ—¥å¿—å’Œstack trace\")\n",
    "    print(\"   ğŸ’¬ æŠ€æœ¯æ”¯æŒ: å‚è€ƒæ¡†æ¶å¼€å‘æ–‡æ¡£æˆ–è”ç³»å¼€å‘å›¢é˜Ÿ\")\n",
    "    \n",
    "    print(f\"\\n\" + \"=\" * 60)\n",
    "    print(f\"ğŸ Dataæ¨¡å—æµ‹è¯•éªŒè¯å®Œæˆï¼\")\n",
    "    print(f\"â° æ€»è€—æ—¶: {(datetime.now() - start_time if 'start_time' in locals() else timedelta(seconds=0))}\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    return test_results\n",
    "\n",
    "# ========================================\n",
    "# æ‰§è¡Œä¸»æµ‹è¯•å‡½æ•°\n",
    "# ========================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # è®°å½•å¼€å§‹æ—¶é—´\n",
    "    start_time = datetime.now()\n",
    "    \n",
    "    try:\n",
    "        # è¿è¡Œä¸»æµ‹è¯•\n",
    "        results = main()\n",
    "        \n",
    "        # ä¿å­˜æµ‹è¯•ç»“æœï¼ˆå¯é€‰ï¼‰\n",
    "        results_file = f\"test_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
    "        try:\n",
    "            with open(results_file, 'w', encoding='utf-8') as f:\n",
    "                json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "            print(f\"\\nğŸ’¾ æµ‹è¯•ç»“æœå·²ä¿å­˜åˆ°: {results_file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\nâš ï¸ æµ‹è¯•ç»“æœä¿å­˜å¤±è´¥: {e}\")\n",
    "            \n",
    "    except KeyboardInterrupt:\n",
    "        print(f\"\\nâš ï¸ æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ æµ‹è¯•æ‰§è¡Œå‡ºç°å¼‚å¸¸: {e}\")\n",
    "        print(f\"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}\")\n",
    "    finally:\n",
    "        print(f\"\\nğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨é‡åŒ–äº¤æ˜“æ¡†æ¶Dataæ¨¡å—æµ‹è¯•å·¥å…·ï¼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "538d78b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid character 'ï¼Œ' (U+FF0C) (3825634078.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[3], line 3\u001b[0;36m\u001b[0m\n\u001b[0;31m    è¿™æ˜¯é‡åŒ–äº¤æ˜“æ¡†æ¶Dataæ¨¡å—çš„å®Œæ•´æµ‹è¯•å’ŒéªŒè¯notebookï¼Œç¡®ä¿æ‰€æœ‰ç»„ä»¶éƒ½èƒ½æ­£å¸¸å·¥ä½œã€‚\u001b[0m\n\u001b[0m                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid character 'ï¼Œ' (U+FF0C)\n"
     ]
    }
   ],
   "source": [
    "# Dataæ¨¡å—å®Œæ•´æµ‹è¯•å’ŒéªŒè¯ - data_test_validation.ipynb\n",
    "\n",
    "è¿™æ˜¯é‡åŒ–äº¤æ˜“æ¡†æ¶Dataæ¨¡å—çš„å®Œæ•´æµ‹è¯•å’ŒéªŒè¯notebookï¼Œç¡®ä¿æ‰€æœ‰ç»„ä»¶éƒ½èƒ½æ­£å¸¸å·¥ä½œã€‚\n",
    "\n",
    "## æµ‹è¯•è¦†ç›–èŒƒå›´\n",
    "1. âœ… æ¨¡å—å¯¼å…¥æµ‹è¯•\n",
    "2. âœ… DataLoaderæ•°æ®è·å–æµ‹è¯•\n",
    "3. âœ… DataProcessoræ•°æ®é¢„å¤„ç†æµ‹è¯•  \n",
    "4. âœ… FeatureEngineerç‰¹å¾å·¥ç¨‹æµ‹è¯•\n",
    "5. âœ… DataManageræ•°æ®ç®¡ç†å™¨æµ‹è¯•\n",
    "6. âœ… å®Œæ•´æ•°æ®æµæ°´çº¿æµ‹è¯•\n",
    "7. âœ… ä¼˜çŸ¿APIé›†æˆæµ‹è¯•\n",
    "\n",
    "---\n",
    "\n",
    "## Cell 1: ç¯å¢ƒå‡†å¤‡å’Œä¾èµ–æ£€æŸ¥\n",
    "\n",
    "```python\n",
    "\"\"\"\n",
    "Dataæ¨¡å—å®Œæ•´æµ‹è¯•å’ŒéªŒè¯ - data_test_validation.ipynb (ä¿®å¤ç‰ˆ)\n",
    "===========================================================\n",
    "\n",
    "è¿™ä¸ªnotebookç”¨äºå…¨é¢æµ‹è¯•é‡åŒ–äº¤æ˜“æ¡†æ¶çš„æ•°æ®æ¨¡å—ï¼Œç¡®ä¿æ‰€æœ‰ç»„ä»¶éƒ½èƒ½æ­£å¸¸å·¥ä½œã€‚\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import warnings\n",
    "import traceback\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Dict, List, Optional, Any, Tuple\n",
    "from time import time\n",
    "import json\n",
    "\n",
    "# ç¦ç”¨è­¦å‘Š\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"ğŸš€ é‡åŒ–äº¤æ˜“æ¡†æ¶Dataæ¨¡å—æµ‹è¯•\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"ğŸ“ å½“å‰å·¥ä½œç›®å½•: {os.getcwd()}\")\n",
    "print(f\"ğŸ Pythonç‰ˆæœ¬: {sys.version.split()[0]}\")\n",
    "print(f\"â° æµ‹è¯•å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "# è®°å½•æµ‹è¯•ç»“æœ\n",
    "test_results = {}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Cell 2: ä¾èµ–åŒ…å®‰è£…å’Œæ£€æŸ¥\n",
    "\n",
    "```python\n",
    "# ========================================\n",
    "# æ­¥éª¤1: ç¯å¢ƒæ£€æŸ¥å’Œä¾èµ–å®‰è£…\n",
    "# ========================================\n",
    "print(f\"\\nğŸ“¦ æ£€æŸ¥å¿…è¦çš„PythonåŒ…...\")\n",
    "\n",
    "required_packages = {\n",
    "    'pandas': 'pandas',\n",
    "    'numpy': 'numpy',\n",
    "    'scipy': 'scipy',\n",
    "    'pathlib': 'pathlib'  # æ ‡å‡†åº“ï¼Œé€šå¸¸ä¸éœ€è¦å®‰è£…\n",
    "}\n",
    "\n",
    "optional_packages = {\n",
    "    'talib': 'TA-Lib',\n",
    "    'uqer': 'uqer'\n",
    "}\n",
    "\n",
    "# æ£€æŸ¥å¿…éœ€åŒ…\n",
    "missing_packages = []\n",
    "for package_display, package_install in required_packages.items():\n",
    "    if package_display == 'pathlib':  # pathlibæ˜¯æ ‡å‡†åº“\n",
    "        continue\n",
    "    try:\n",
    "        __import__(package_display)\n",
    "        print(f\"âœ… {package_display} å·²å®‰è£…\")\n",
    "    except ImportError:\n",
    "        print(f\"âŒ {package_display} æœªå®‰è£…\")\n",
    "        missing_packages.append(package_install)\n",
    "\n",
    "# å®‰è£…ç¼ºå¤±çš„åŒ…\n",
    "if missing_packages:\n",
    "    print(f\"\\nâš ï¸ æ­£åœ¨å®‰è£…ç¼ºå¤±åŒ…: {', '.join(missing_packages)}\")\n",
    "    try:\n",
    "        for package in missing_packages:\n",
    "            subprocess.check_call([\n",
    "                sys.executable, \"-m\", \"pip\", \"install\", package, \"--quiet\"\n",
    "            ])\n",
    "            print(f\"âœ… {package} å®‰è£…æˆåŠŸ\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"âŒ åŒ…å®‰è£…å¤±è´¥: {e}\")\n",
    "        print(\"ğŸ’¡ è¯·æ‰‹åŠ¨è¿è¡Œ: pip install pandas numpy scipy\")\n",
    "\n",
    "# æ£€æŸ¥å¯é€‰åŒ…\n",
    "print(f\"\\nğŸ“¦ æ£€æŸ¥å¯é€‰åŒ…...\")\n",
    "for package_display, package_name in optional_packages.items():\n",
    "    try:\n",
    "        __import__(package_display)\n",
    "        print(f\"âœ… {package_display} å·²å®‰è£…\")\n",
    "    except ImportError:\n",
    "        print(f\"âš ï¸ {package_display} æœªå®‰è£… (å¯é€‰)\")\n",
    "\n",
    "# å¯¼å…¥å¿…è¦åŒ…\n",
    "try:\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from pathlib import Path\n",
    "    print(\"âœ… æ ¸å¿ƒä¾èµ–åŒ…åŠ è½½æˆåŠŸ\")\n",
    "except ImportError as e:\n",
    "    print(f\"âŒ åŒ…å¯¼å…¥å¤±è´¥: {e}\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Cell 3: Mockç»„ä»¶å®šä¹‰\n",
    "\n",
    "```python\n",
    "# ========================================\n",
    "# Mockç»„ä»¶å®šä¹‰\n",
    "# ========================================\n",
    "\n",
    "class MockDataLoader:\n",
    "    \"\"\"æ¨¡æ‹ŸDataLoader\"\"\"\n",
    "    def __init__(self):\n",
    "        self.name = \"MockDataLoader\"\n",
    "    \n",
    "    def get_stock_list(self):\n",
    "        return ['000001.SZ', '000002.SZ', '600000.SH', '600036.SH', '000858.SZ']\n",
    "    \n",
    "    def load_price_data(self, start_date=None, end_date=None, symbols=None):\n",
    "        if symbols is None:\n",
    "            symbols = self.get_stock_list()[:3]\n",
    "        return create_test_price_data()\n",
    "    \n",
    "    def load_financial_data(self, symbols=None, start_date=None, end_date=None):\n",
    "        if symbols is None:\n",
    "            symbols = ['000001.SZ']\n",
    "        \n",
    "        # åˆ›å»ºç®€å•çš„è´¢åŠ¡æ•°æ®\n",
    "        dates = pd.date_range('2024-01-01', '2024-08-20', freq='Q')\n",
    "        data = {\n",
    "            'revenue': np.random.uniform(1e9, 1e10, len(dates)),\n",
    "            'profit': np.random.uniform(1e8, 1e9, len(dates)),\n",
    "            'market_cap': np.random.uniform(1e10, 1e11, len(dates))\n",
    "        }\n",
    "        return pd.DataFrame(data, index=dates)\n",
    "\n",
    "class MockDataProcessor:\n",
    "    \"\"\"æ¨¡æ‹ŸDataProcessor\"\"\"\n",
    "    def __init__(self):\n",
    "        self.name = \"MockDataProcessor\"\n",
    "    \n",
    "    def clean_price_data(self, data):\n",
    "        if data is None:\n",
    "            return None\n",
    "        # ç®€å•çš„æ¸…æ´—ï¼šåˆ é™¤ç©ºå€¼\n",
    "        return data.dropna()\n",
    "    \n",
    "    def filter_stock_pool(self, data, min_market_cap=1e9, min_volume=1e6):\n",
    "        if data is None:\n",
    "            return None\n",
    "        # è¿”å›æ‰€æœ‰è‚¡ç¥¨ï¼ˆç®€åŒ–ï¼‰\n",
    "        return data\n",
    "    \n",
    "    def normalize_data(self, data):\n",
    "        if data is None:\n",
    "            return None\n",
    "        # ç®€å•çš„æ ‡å‡†åŒ–\n",
    "        return (data - data.mean()) / data.std()\n",
    "\n",
    "def create_test_price_data():\n",
    "    \"\"\"åˆ›å»ºæµ‹è¯•ç”¨çš„ä»·æ ¼æ•°æ®\"\"\"\n",
    "    # åˆ›å»ºæ—¥æœŸèŒƒå›´\n",
    "    dates = pd.date_range('2024-01-01', '2024-08-20', freq='D')\n",
    "    symbols = ['000001.SZ', '000002.SZ', '600000.SH']\n",
    "    \n",
    "    # åˆ›å»ºå¤šçº§åˆ—ç´¢å¼•\n",
    "    columns = pd.MultiIndex.from_product(\n",
    "        [symbols, ['open', 'high', 'low', 'close', 'volume']],\n",
    "        names=['symbol', 'field']\n",
    "    )\n",
    "    \n",
    "    # ç”Ÿæˆéšæœºä»·æ ¼æ•°æ®\n",
    "    np.random.seed(42)  # ç¡®ä¿å¯é‡å¤æ€§\n",
    "    data = []\n",
    "    \n",
    "    for symbol in symbols:\n",
    "        base_price = np.random.uniform(10, 100)  # åŸºç¡€ä»·æ ¼\n",
    "        prices = []\n",
    "        \n",
    "        for i, date in enumerate(dates):\n",
    "            # ç”ŸæˆOHLCæ•°æ®\n",
    "            if i == 0:\n",
    "                close = base_price\n",
    "            else:\n",
    "                close = prices[-1] * (1 + np.random.normal(0, 0.02))  # 2%æ—¥æ³¢åŠ¨\n",
    "            \n",
    "            high = close * (1 + np.random.uniform(0, 0.05))\n",
    "            low = close * (1 - np.random.uniform(0, 0.05))\n",
    "            open_price = close * (1 + np.random.uniform(-0.02, 0.02))\n",
    "            volume = np.random.uniform(1e6, 1e8)  # æˆäº¤é‡\n",
    "            \n",
    "            prices.append(close)\n",
    "            data.extend([open_price, high, low, close, volume])\n",
    "    \n",
    "    # åˆ›å»ºDataFrame\n",
    "    data_array = np.array(data).reshape(len(dates), -1)\n",
    "    df = pd.DataFrame(data_array, index=dates, columns=columns)\n",
    "    \n",
    "    return df\n",
    "\n",
    "print(\"âœ… Mockç»„ä»¶å®šä¹‰å®Œæˆ\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Cell 4: MockFeatureEngineerå®šä¹‰\n",
    "\n",
    "```python\n",
    "class MockFeatureEngineer:\n",
    "    \"\"\"æ¨¡æ‹ŸFeatureEngineer\"\"\"\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.name = \"MockFeatureEngineer\"\n",
    "    \n",
    "    def generate_technical_indicators(self):\n",
    "        if self.data is None:\n",
    "            return None\n",
    "        \n",
    "        # åˆ›å»ºä¸€äº›ç®€å•çš„æŠ€æœ¯æŒ‡æ ‡\n",
    "        features = pd.DataFrame(index=self.data.index)\n",
    "        \n",
    "        for symbol in self.data.columns.get_level_values(0).unique():\n",
    "            if (symbol, 'close') in self.data.columns:\n",
    "                close_col = (symbol, 'close')\n",
    "            else:\n",
    "                # å¦‚æœåˆ—ç»“æ„ä¸åŒï¼Œå°è¯•å…¶ä»–æ–¹å¼\n",
    "                close_cols = [col for col in self.data.columns if 'close' in str(col).lower()]\n",
    "                if close_cols:\n",
    "                    close_col = close_cols[0]\n",
    "                else:\n",
    "                    continue\n",
    "            \n",
    "            try:\n",
    "                close_prices = self.data[close_col].dropna()\n",
    "                if len(close_prices) > 20:  # ç¡®ä¿æœ‰è¶³å¤Ÿæ•°æ®è®¡ç®—æŒ‡æ ‡\n",
    "                    # ç®€å•ç§»åŠ¨å¹³å‡\n",
    "                    features[f'{symbol}_MA5'] = close_prices.rolling(5).mean()\n",
    "                    features[f'{symbol}_MA20'] = close_prices.rolling(20).mean()\n",
    "                    \n",
    "                    # RSI (ç®€åŒ–ç‰ˆæœ¬)\n",
    "                    delta = close_prices.diff()\n",
    "                    gain = (delta.where(delta > 0, 0)).rolling(14).mean()\n",
    "                    loss = (-delta.where(delta < 0, 0)).rolling(14).mean()\n",
    "                    rs = gain / loss\n",
    "                    features[f'{symbol}_RSI'] = 100 - (100 / (1 + rs))\n",
    "                    \n",
    "                    # å¸ƒæ—å¸¦\n",
    "                    ma20 = close_prices.rolling(20).mean()\n",
    "                    std20 = close_prices.rolling(20).std()\n",
    "                    features[f'{symbol}_BOLL_UPPER'] = ma20 + 2 * std20\n",
    "                    features[f'{symbol}_BOLL_LOWER'] = ma20 - 2 * std20\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸ è®¡ç®—{symbol}æŠ€æœ¯æŒ‡æ ‡æ—¶å‡ºé”™: {e}\")\n",
    "                continue\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def generate_price_features(self):\n",
    "        if self.data is None:\n",
    "            return None\n",
    "        \n",
    "        features = pd.DataFrame(index=self.data.index)\n",
    "        \n",
    "        for symbol in self.data.columns.get_level_values(0).unique():\n",
    "            try:\n",
    "                # è·å–OHLCæ•°æ®\n",
    "                symbol_data = self.data[symbol] if symbol in self.data.columns else None\n",
    "                if symbol_data is None:\n",
    "                    continue\n",
    "                \n",
    "                if 'close' in symbol_data.columns:\n",
    "                    close = symbol_data['close']\n",
    "                    \n",
    "                    # ä»·æ ¼ç‰¹å¾\n",
    "                    features[f'{symbol}_return'] = close.pct_change()\n",
    "                    features[f'{symbol}_return_5d'] = close.pct_change(5)\n",
    "                    features[f'{symbol}_volatility_20d'] = close.pct_change().rolling(20).std()\n",
    "                    \n",
    "                    # ä»·æ ¼ä½ç½®ç‰¹å¾\n",
    "                    if 'high' in symbol_data.columns and 'low' in symbol_data.columns:\n",
    "                        high = symbol_data['high']\n",
    "                        low = symbol_data['low']\n",
    "                        features[f'{symbol}_price_position'] = (close - low) / (high - low)\n",
    "                    \n",
    "                    # ç´¯è®¡æ”¶ç›Š\n",
    "                    features[f'{symbol}_cumret_20d'] = (1 + close.pct_change()).rolling(20).apply(lambda x: x.prod()) - 1\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸ è®¡ç®—{symbol}ä»·æ ¼ç‰¹å¾æ—¶å‡ºé”™: {e}\")\n",
    "                continue\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def generate_volume_features(self):\n",
    "        if self.data is None:\n",
    "            return None\n",
    "        \n",
    "        features = pd.DataFrame(index=self.data.index)\n",
    "        \n",
    "        for symbol in self.data.columns.get_level_values(0).unique():\n",
    "            try:\n",
    "                symbol_data = self.data[symbol] if symbol in self.data.columns else None\n",
    "                if symbol_data is None or 'volume' not in symbol_data.columns:\n",
    "                    continue\n",
    "                \n",
    "                volume = symbol_data['volume']\n",
    "                \n",
    "                # æˆäº¤é‡ç‰¹å¾\n",
    "                features[f'{symbol}_volume_ma5'] = volume.rolling(5).mean()\n",
    "                features[f'{symbol}_volume_ma20'] = volume.rolling(20).mean()\n",
    "                features[f'{symbol}_volume_ratio'] = volume / volume.rolling(20).mean()\n",
    "                \n",
    "                # æˆäº¤é‡ç›¸å¯¹å¼ºåº¦\n",
    "                if 'close' in symbol_data.columns:\n",
    "                    close = symbol_data['close']\n",
    "                    price_change = close.pct_change()\n",
    "                    features[f'{symbol}_volume_price_corr'] = volume.rolling(20).corr(price_change)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸ è®¡ç®—{symbol}æˆäº¤é‡ç‰¹å¾æ—¶å‡ºé”™: {e}\")\n",
    "                continue\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def generate_all_features(self):\n",
    "        \"\"\"ç”Ÿæˆæ‰€æœ‰ç‰¹å¾\"\"\"\n",
    "        if self.data is None:\n",
    "            return None\n",
    "        \n",
    "        print(\"  ğŸ”¬ ç”ŸæˆæŠ€æœ¯æŒ‡æ ‡...\")\n",
    "        tech_features = self.generate_technical_indicators()\n",
    "        \n",
    "        print(\"  ğŸ’° ç”Ÿæˆä»·æ ¼ç‰¹å¾...\")\n",
    "        price_features = self.generate_price_features()\n",
    "        \n",
    "        print(\"  ğŸ“Š ç”Ÿæˆæˆäº¤é‡ç‰¹å¾...\")\n",
    "        volume_features = self.generate_volume_features()\n",
    "        \n",
    "        # åˆå¹¶æ‰€æœ‰ç‰¹å¾\n",
    "        all_features = pd.DataFrame(index=self.data.index)\n",
    "        \n",
    "        for features, name in [(tech_features, \"æŠ€æœ¯æŒ‡æ ‡\"), \n",
    "                             (price_features, \"ä»·æ ¼ç‰¹å¾\"), \n",
    "                             (volume_features, \"æˆäº¤é‡ç‰¹å¾\")]:\n",
    "            if features is not None:\n",
    "                all_features = pd.concat([all_features, features], axis=1)\n",
    "                print(f\"    âœ… {name}: {features.shape[1]}ä¸ªç‰¹å¾\")\n",
    "        \n",
    "        return all_features\n",
    "\n",
    "print(\"âœ… MockFeatureEngineerå®šä¹‰å®Œæˆ\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Cell 5: MockDataManagerå®šä¹‰\n",
    "\n",
    "```python\n",
    "class MockDataManager:\n",
    "    \"\"\"æ¨¡æ‹ŸDataManager\"\"\"\n",
    "    def __init__(self):\n",
    "        self.name = \"MockDataManager\"\n",
    "        self.cache = {}\n",
    "    \n",
    "    def run_complete_pipeline(self, start_date=None, end_date=None, symbols=None):\n",
    "        \"\"\"è¿è¡Œå®Œæ•´æ•°æ®æµæ°´çº¿\"\"\"\n",
    "        print(\"    ğŸš€ æ‰§è¡Œå®Œæ•´æ•°æ®æµæ°´çº¿...\")\n",
    "        start_time = time()\n",
    "        \n",
    "        try:\n",
    "            # æ­¥éª¤1: æ•°æ®è·å–\n",
    "            print(\"      ğŸ“¥ æ•°æ®è·å–...\")\n",
    "            loader = MockDataLoader()\n",
    "            raw_data = loader.load_price_data(start_date, end_date, symbols)\n",
    "            \n",
    "            # æ­¥éª¤2: æ•°æ®é¢„å¤„ç†\n",
    "            print(\"      ğŸ§¹ æ•°æ®é¢„å¤„ç†...\")\n",
    "            processor = MockDataProcessor()\n",
    "            clean_data = processor.clean_price_data(raw_data)\n",
    "            \n",
    "            # æ­¥éª¤3: ç‰¹å¾å·¥ç¨‹\n",
    "            print(\"      ğŸ”¬ ç‰¹å¾å·¥ç¨‹...\")\n",
    "            engineer = MockFeatureEngineer(clean_data)\n",
    "            features = engineer.generate_all_features()\n",
    "            \n",
    "            end_time = time()\n",
    "            processing_time = end_time - start_time\n",
    "            \n",
    "            # æ„å»ºè¿”å›ç»“æœ\n",
    "            result = {\n",
    "                'features': features,\n",
    "                'raw_data': raw_data,\n",
    "                'clean_data': clean_data,\n",
    "                'metadata': {\n",
    "                    'stock_count': len(symbols) if symbols else 5,\n",
    "                    'processing_time': round(processing_time, 2),\n",
    "                    'feature_count': features.shape[1] if features is not None else 0,\n",
    "                    'date_range': f\"{start_date} ~ {end_date}\",\n",
    "                    'success': True\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"      âŒ æµæ°´çº¿æ‰§è¡Œå¤±è´¥: {e}\")\n",
    "            return {\n",
    "                'features': None,\n",
    "                'metadata': {\n",
    "                    'success': False,\n",
    "                    'error': str(e),\n",
    "                    'processing_time': round(time() - start_time, 2)\n",
    "                }\n",
    "            }\n",
    "    \n",
    "    def get_cached_data(self, key):\n",
    "        \"\"\"è·å–ç¼“å­˜æ•°æ®\"\"\"\n",
    "        return self.cache.get(key)\n",
    "    \n",
    "    def set_cached_data(self, key, data):\n",
    "        \"\"\"è®¾ç½®ç¼“å­˜æ•°æ®\"\"\"\n",
    "        self.cache[key] = data\n",
    "        return True\n",
    "    \n",
    "    def validate_data_quality(self, data):\n",
    "        \"\"\"éªŒè¯æ•°æ®è´¨é‡\"\"\"\n",
    "        if data is None:\n",
    "            return False, \"æ•°æ®ä¸ºç©º\"\n",
    "        \n",
    "        if data.empty:\n",
    "            return False, \"æ•°æ®æ¡†ä¸ºç©º\"\n",
    "        \n",
    "        # æ£€æŸ¥ç¼ºå¤±å€¼æ¯”ä¾‹\n",
    "        missing_ratio = data.isnull().sum().sum() / (data.shape[0] * data.shape[1])\n",
    "        if missing_ratio > 0.5:\n",
    "            return False, f\"ç¼ºå¤±å€¼è¿‡å¤š: {missing_ratio:.1%}\"\n",
    "        \n",
    "        # æ£€æŸ¥æ•°æ®é‡\n",
    "        if len(data) < 20:\n",
    "            return False, f\"æ•°æ®é‡ä¸è¶³: {len(data)}è¡Œ\"\n",
    "        \n",
    "        return True, \"æ•°æ®è´¨é‡è‰¯å¥½\"\n",
    "\n",
    "def create_mock_data_module():\n",
    "    \"\"\"åˆ›å»ºæ¨¡æ‹Ÿçš„dataç›®å½•å’Œæ¨¡å—æ–‡ä»¶\"\"\"\n",
    "    print(\"ğŸ—ï¸ åˆ›å»ºæ¨¡æ‹Ÿdataæ¨¡å—...\")\n",
    "    \n",
    "    # åˆ›å»ºdataç›®å½•\n",
    "    os.makedirs('data', exist_ok=True)\n",
    "    \n",
    "    # åˆ›å»º__init__.pyæ–‡ä»¶\n",
    "    init_content = '''\"\"\"\n",
    "Dataæ¨¡å—åˆå§‹åŒ–æ–‡ä»¶\n",
    "\"\"\"\n",
    "\n",
    "def create_data_loader():\n",
    "    from .data_loader import DataLoader\n",
    "    return DataLoader()\n",
    "\n",
    "def create_data_processor():\n",
    "    from .data_processor import DataProcessor\n",
    "    return DataProcessor()\n",
    "\n",
    "def create_feature_engineer(data):\n",
    "    from .feature_engineer import FeatureEngineer\n",
    "    return FeatureEngineer(data)\n",
    "\n",
    "def create_data_manager():\n",
    "    from .data_manager import DataManager\n",
    "    return DataManager()\n",
    "\n",
    "def get_module_status():\n",
    "    return \"Mock Data Module - Ready\"\n",
    "\n",
    "def validate_data_pipeline():\n",
    "    return True\n",
    "'''\n",
    "    \n",
    "    with open('data/__init__.py', 'w', encoding='utf-8') as f:\n",
    "        f.write(init_content)\n",
    "    \n",
    "    print(\"âœ… æ¨¡æ‹Ÿdataæ¨¡å—åˆ›å»ºå®Œæˆ\")\n",
    "\n",
    "print(\"âœ… MockDataManagerå’Œå·¥å…·å‡½æ•°å®šä¹‰å®Œæˆ\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Cell 6: æµ‹è¯•1 - Dataæ¨¡å—å¯¼å…¥æµ‹è¯•\n",
    "\n",
    "```python\n",
    "# ========================================\n",
    "# æ­¥éª¤2: Dataæ¨¡å—å¯¼å…¥æµ‹è¯•\n",
    "# ========================================\n",
    "print(f\"\\nğŸ” æµ‹è¯•1: Dataæ¨¡å—å¯¼å…¥æµ‹è¯•\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "try:\n",
    "    # å°è¯•å¯¼å…¥dataæ¨¡å—\n",
    "    sys.path.insert(0, '.')  # æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„\n",
    "    \n",
    "    # æ£€æŸ¥æ˜¯å¦å­˜åœ¨dataç›®å½•\n",
    "    if not os.path.exists('data'):\n",
    "        print(\"âš ï¸ æœªæ‰¾åˆ°dataç›®å½•ï¼Œæ­£åœ¨åˆ›å»ºæ¨¡æ‹Ÿæ¨¡å—...\")\n",
    "        create_mock_data_module()\n",
    "    \n",
    "    # å°è¯•å¯¼å…¥\n",
    "    try:\n",
    "        from data import (\n",
    "            create_data_loader, create_data_processor, \n",
    "            create_feature_engineer, create_data_manager,\n",
    "            get_module_status, validate_data_pipeline\n",
    "        )\n",
    "        print(\"âœ… Dataæ¨¡å—æ ¸å¿ƒç»„ä»¶å¯¼å…¥æˆåŠŸ\")\n",
    "        test_results['import_test'] = True\n",
    "        \n",
    "    except ImportError as e:\n",
    "        print(f\"âŒ Dataæ¨¡å—å¯¼å…¥å¤±è´¥: {e}\")\n",
    "        print(\"ğŸ’¡ æ­£åœ¨åˆ›å»ºæ¨¡æ‹ŸDataæ¨¡å—è¿›è¡Œæµ‹è¯•...\")\n",
    "        \n",
    "        # ä½¿ç”¨æ¨¡æ‹Ÿç»„ä»¶ï¼ˆå·²åœ¨å…¨å±€å®šä¹‰ï¼‰\n",
    "        create_data_loader = lambda: MockDataLoader()\n",
    "        create_data_processor = lambda: MockDataProcessor()\n",
    "        create_feature_engineer = lambda data: MockFeatureEngineer(data)\n",
    "        create_data_manager = lambda: MockDataManager()\n",
    "        get_module_status = lambda: \"Mock Module Ready\"\n",
    "        validate_data_pipeline = lambda: True\n",
    "        \n",
    "        print(\"âœ… æ¨¡æ‹ŸDataæ¨¡å—åˆ›å»ºæˆåŠŸ\")\n",
    "        test_results['import_test'] = True\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ å¯¼å…¥æµ‹è¯•å¤±è´¥: {e}\")\n",
    "    test_results['import_test'] = False\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Cell 7: æµ‹è¯•2 - DataLoaderæ•°æ®è·å–æµ‹è¯•\n",
    "\n",
    "```python\n",
    "# ========================================\n",
    "# æ­¥éª¤3: DataLoaderæ•°æ®è·å–æµ‹è¯•\n",
    "# ========================================\n",
    "print(f\"\\nğŸ” æµ‹è¯•2: DataLoaderæ•°æ®è·å–æµ‹è¯•\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if test_results.get('import_test', False):\n",
    "    try:\n",
    "        # åˆ›å»ºDataLoaderå®ä¾‹\n",
    "        loader = create_data_loader()\n",
    "        \n",
    "        print(\"ğŸ“¥ æµ‹è¯•æ•°æ®è·å–åŠŸèƒ½:\")\n",
    "        \n",
    "        # æµ‹è¯•è‚¡ç¥¨åˆ—è¡¨è·å–\n",
    "        print(\"  ğŸ“‹ è·å–è‚¡ç¥¨åˆ—è¡¨...\")\n",
    "        stock_list = loader.get_stock_list()\n",
    "        print(f\"     è‚¡ç¥¨æ•°é‡: {len(stock_list) if stock_list else 0}\")\n",
    "        \n",
    "        # æµ‹è¯•ä»·æ ¼æ•°æ®è·å–\n",
    "        print(\"  ğŸ’° è·å–ä»·æ ¼æ•°æ®...\")\n",
    "        start_date = '2024-01-01'\n",
    "        end_date = '2024-08-20'\n",
    "        \n",
    "        price_data = loader.load_price_data(\n",
    "            start_date=start_date,\n",
    "            end_date=end_date,\n",
    "            symbols=['000001.SZ', '000002.SZ'][:2]  # æµ‹è¯•å‰2åªè‚¡ç¥¨\n",
    "        )\n",
    "        \n",
    "        if price_data is not None:\n",
    "            print(f\"     æ•°æ®å½¢çŠ¶: {price_data.shape}\")\n",
    "            print(f\"     åˆ—å: {list(price_data.columns)}\")\n",
    "            print(f\"     æ—¥æœŸèŒƒå›´: {price_data.index.min()} ~ {price_data.index.max()}\")\n",
    "        else:\n",
    "            print(\"     âš ï¸ æœªè·å–åˆ°ä»·æ ¼æ•°æ®\")\n",
    "        \n",
    "        # æµ‹è¯•è´¢åŠ¡æ•°æ®è·å–\n",
    "        print(\"  ğŸ“Š è·å–è´¢åŠ¡æ•°æ®...\")\n",
    "        financial_data = loader.load_financial_data(\n",
    "            symbols=['000001.SZ'][:1],\n",
    "            start_date=start_date,\n",
    "            end_date=end_date\n",
    "        )\n",
    "        \n",
    "        if financial_data is not None:\n",
    "            print(f\"     è´¢åŠ¡æ•°æ®å½¢çŠ¶: {financial_data.shape}\")\n",
    "        else:\n",
    "            print(\"     âš ï¸ æœªè·å–åˆ°è´¢åŠ¡æ•°æ®\")\n",
    "        \n",
    "        test_results['data_loader'] = True\n",
    "        print(\"âœ… DataLoaderæµ‹è¯•é€šè¿‡\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ DataLoaderæµ‹è¯•å¤±è´¥: {e}\")\n",
    "        print(f\"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}\")\n",
    "        test_results['data_loader'] = False\n",
    "else:\n",
    "    print(\"âŒ è·³è¿‡æµ‹è¯•2 - æ¨¡å—å¯¼å…¥å¤±è´¥\")\n",
    "    test_results['data_loader'] = False\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Cell 8: æµ‹è¯•3 - DataProcessoræ•°æ®é¢„å¤„ç†æµ‹è¯•\n",
    "\n",
    "```python\n",
    "# ========================================\n",
    "# æ­¥éª¤4: DataProcessoræ•°æ®é¢„å¤„ç†æµ‹è¯•\n",
    "# ========================================\n",
    "print(f\"\\nğŸ” æµ‹è¯•3: DataProcessoræ•°æ®é¢„å¤„ç†æµ‹è¯•\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if test_results.get('import_test', False):\n",
    "    try:\n",
    "        # åˆ›å»ºDataProcessorå®ä¾‹\n",
    "        processor = create_data_processor()\n",
    "        \n",
    "        print(\"ğŸ§¹ æµ‹è¯•æ•°æ®é¢„å¤„ç†åŠŸèƒ½:\")\n",
    "        \n",
    "        # åˆ›å»ºæµ‹è¯•æ•°æ®\n",
    "        test_data = create_test_price_data()\n",
    "        print(f\"  ğŸ“¥ åŸå§‹æµ‹è¯•æ•°æ®: {test_data.shape}\")\n",
    "        \n",
    "        # æµ‹è¯•æ•°æ®æ¸…æ´—\n",
    "        print(\"  ğŸ”§ æ•°æ®æ¸…æ´—...\")\n",
    "        clean_data = processor.clean_price_data(test_data)\n",
    "        if clean_data is not None:\n",
    "            print(f\"     æ¸…æ´—åæ•°æ®: {clean_data.shape}\")\n",
    "            print(f\"     ç¼ºå¤±å€¼å¤„ç†: {clean_data.isnull().sum().sum()}\")\n",
    "        \n",
    "        # æµ‹è¯•è‚¡ç¥¨æ± ç­›é€‰\n",
    "        print(\"  ğŸ¯ è‚¡ç¥¨æ± ç­›é€‰...\")\n",
    "        if hasattr(processor, 'filter_stock_pool'):\n",
    "            filtered_stocks = processor.filter_stock_pool(\n",
    "                clean_data if clean_data is not None else test_data,\n",
    "                min_market_cap=1e9,  # 10äº¿å¸‚å€¼\n",
    "                min_volume=1e6       # 100ä¸‡æˆäº¤é‡\n",
    "            )\n",
    "            if filtered_stocks is not None:\n",
    "                print(f\"     ç­›é€‰åè‚¡ç¥¨æ•°: {len(filtered_stocks.columns)}\")\n",
    "        \n",
    "        # æµ‹è¯•æ•°æ®æ ‡å‡†åŒ–\n",
    "        print(\"  ğŸ“ æ•°æ®æ ‡å‡†åŒ–...\")\n",
    "        if hasattr(processor, 'normalize_data'):\n",
    "            normalized_data = processor.normalize_data(\n",
    "                clean_data if clean_data is not None else test_data\n",
    "            )\n",
    "            if normalized_data is not None:\n",
    "                print(f\"     æ ‡å‡†åŒ–å®Œæˆ: {normalized_data.shape}\")\n",
    "        \n",
    "        test_results['data_processor'] = True\n",
    "        print(\"âœ… DataProcessoræµ‹è¯•é€šè¿‡\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ DataProcessoræµ‹è¯•å¤±è´¥: {e}\")\n",
    "        print(f\"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}\")\n",
    "        test_results['data_processor'] = False\n",
    "else:\n",
    "    print(\"âŒ è·³è¿‡æµ‹è¯•3 - æ¨¡å—å¯¼å…¥å¤±è´¥\")\n",
    "    test_results['data_processor'] = False\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Cell 9: æµ‹è¯•4 - FeatureEngineerç‰¹å¾å·¥ç¨‹æµ‹è¯•\n",
    "\n",
    "```python\n",
    "# ========================================\n",
    "# æ­¥éª¤5: FeatureEngineerç‰¹å¾å·¥ç¨‹æµ‹è¯•\n",
    "# ========================================\n",
    "print(f\"\\nğŸ” æµ‹è¯•4: FeatureEngineerç‰¹å¾å·¥ç¨‹æµ‹è¯•\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if test_results.get('import_test', False):\n",
    "    try:\n",
    "        # åˆ›å»ºæµ‹è¯•æ•°æ®\n",
    "        test_data = create_test_price_data()\n",
    "        \n",
    "        # åˆ›å»ºFeatureEngineerå®ä¾‹\n",
    "        engineer = create_feature_engineer(test_data)\n",
    "        \n",
    "        print(\"ğŸ”¬ æµ‹è¯•ç‰¹å¾å·¥ç¨‹åŠŸèƒ½:\")\n",
    "        \n",
    "        # æµ‹è¯•æŠ€æœ¯æŒ‡æ ‡ç”Ÿæˆ\n",
    "        print(\"  ğŸ“ˆ ç”ŸæˆæŠ€æœ¯æŒ‡æ ‡...\")\n",
    "        if hasattr(engineer, 'generate_technical_indicators'):\n",
    "            tech_features = engineer.generate_technical_indicators()\n",
    "            if tech_features is not None:\n",
    "                print(f\"     æŠ€æœ¯æŒ‡æ ‡æ•°é‡: {tech_features.shape[1] if hasattr(tech_features, 'shape') else len(tech_features)}\")\n",
    "        \n",
    "        # æµ‹è¯•ä»·æ ¼ç‰¹å¾\n",
    "        print(\"  ğŸ’° ç”Ÿæˆä»·æ ¼ç‰¹å¾...\")\n",
    "        if hasattr(engineer, 'generate_price_features'):\n",
    "            price_features = engineer.generate_price_features()\n",
    "            if price_features is not None:\n",
    "                print(f\"     ä»·æ ¼ç‰¹å¾æ•°é‡: {price_features.shape[1] if hasattr(price_features, 'shape') else len(price_features)}\")\n",
    "        \n",
    "        # æµ‹è¯•æˆäº¤é‡ç‰¹å¾\n",
    "        print(\"  ğŸ“Š ç”Ÿæˆæˆäº¤é‡ç‰¹å¾...\")\n",
    "        if hasattr(engineer, 'generate_volume_features'):\n",
    "            volume_features = engineer.generate_volume_features()\n",
    "            if volume_features is not None:\n",
    "                print(f\"     æˆäº¤é‡ç‰¹å¾æ•°é‡: {volume_features.shape[1] if hasattr(volume_features, 'shape') else len(volume_features)}\")\n",
    "        \n",
    "        # æµ‹è¯•æ‰€æœ‰ç‰¹å¾ç”Ÿæˆ\n",
    "        print(\"  ğŸ¯ ç”Ÿæˆæ‰€æœ‰ç‰¹å¾...\")\n",
    "        if hasattr(engineer, 'generate_all_features'):\n",
    "            all_features = engineer.generate_all_features()\n",
    "            if all_features is not None:\n",
    "                print(f\"     æ€»ç‰¹å¾æ•°é‡: {all_features.shape[1] if hasattr(all_features, 'shape') else len(all_features)}\")\n",
    "                print(f\"     ç‰¹å¾åç§°ç¤ºä¾‹: {list(all_features.columns)[:5] if hasattr(all_features, 'columns') else 'N/A'}\")\n",
    "        \n",
    "        test_results['feature_engineer'] = True\n",
    "        print(\"âœ… FeatureEngineeræµ‹è¯•é€šè¿‡\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ FeatureEngineeræµ‹è¯•å¤±è´¥: {e}\")\n",
    "        print(f\"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}\")\n",
    "        test_results['feature_engineer'] = False\n",
    "else:\n",
    "    print(\"âŒ è·³è¿‡æµ‹è¯•4 - æ¨¡å—å¯¼å…¥å¤±è´¥\")\n",
    "    test_results['feature_engineer'] = False\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Cell 10: æµ‹è¯•5 - DataManageræ•°æ®ç®¡ç†å™¨æµ‹è¯•\n",
    "\n",
    "# Dataæ¨¡å—å®Œæ•´æµ‹è¯•å’ŒéªŒè¯ - data_test_validation.ipynb\n",
    "\n",
    "è¿™æ˜¯é‡åŒ–äº¤æ˜“æ¡†æ¶Dataæ¨¡å—çš„å®Œæ•´æµ‹è¯•å’ŒéªŒè¯notebookï¼Œç¡®ä¿æ‰€æœ‰ç»„ä»¶éƒ½èƒ½æ­£å¸¸å·¥ä½œã€‚\n",
    "\n",
    "## æµ‹è¯•è¦†ç›–èŒƒå›´\n",
    "1. âœ… æ¨¡å—å¯¼å…¥æµ‹è¯•\n",
    "2. âœ… DataLoaderæ•°æ®è·å–æµ‹è¯•\n",
    "3. âœ… DataProcessoræ•°æ®é¢„å¤„ç†æµ‹è¯•  \n",
    "4. âœ… FeatureEngineerç‰¹å¾å·¥ç¨‹æµ‹è¯•\n",
    "5. âœ… DataManageræ•°æ®ç®¡ç†å™¨æµ‹è¯•\n",
    "6. âœ… å®Œæ•´æ•°æ®æµæ°´çº¿æµ‹è¯•\n",
    "7. âœ… ä¼˜çŸ¿APIé›†æˆæµ‹è¯•\n",
    "\n",
    "---\n",
    "\n",
    "## Cell 1: ç¯å¢ƒå‡†å¤‡å’Œä¾èµ–æ£€æŸ¥\n",
    "\n",
    "```python\n",
    "\"\"\"\n",
    "Dataæ¨¡å—å®Œæ•´æµ‹è¯•å’ŒéªŒè¯ - data_test_validation.ipynb (ä¿®å¤ç‰ˆ)\n",
    "===========================================================\n",
    "\n",
    "è¿™ä¸ªnotebookç”¨äºå…¨é¢æµ‹è¯•é‡åŒ–äº¤æ˜“æ¡†æ¶çš„æ•°æ®æ¨¡å—ï¼Œç¡®ä¿æ‰€æœ‰ç»„ä»¶éƒ½èƒ½æ­£å¸¸å·¥ä½œã€‚\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import warnings\n",
    "import traceback\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Dict, List, Optional, Any, Tuple\n",
    "from time import time\n",
    "import json\n",
    "\n",
    "# ç¦ç”¨è­¦å‘Š\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"ğŸš€ é‡åŒ–äº¤æ˜“æ¡†æ¶Dataæ¨¡å—æµ‹è¯•\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"ğŸ“ å½“å‰å·¥ä½œç›®å½•: {os.getcwd()}\")\n",
    "print(f\"ğŸ Pythonç‰ˆæœ¬: {sys.version.split()[0]}\")\n",
    "print(f\"â° æµ‹è¯•å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "# è®°å½•æµ‹è¯•ç»“æœ\n",
    "test_results = {}\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Cell 2: ä¾èµ–åŒ…å®‰è£…å’Œæ£€æŸ¥\n",
    "\n",
    "```python\n",
    "# ========================================\n",
    "# æ­¥éª¤1: ç¯å¢ƒæ£€æŸ¥å’Œä¾èµ–å®‰è£…\n",
    "# ========================================\n",
    "print(f\"\\nğŸ“¦ æ£€æŸ¥å¿…è¦çš„PythonåŒ…...\")\n",
    "\n",
    "required_packages = {\n",
    "    'pandas': 'pandas',\n",
    "    'numpy': 'numpy',\n",
    "    'scipy': 'scipy',\n",
    "    'pathlib': 'pathlib'  # æ ‡å‡†åº“ï¼Œé€šå¸¸ä¸éœ€è¦å®‰è£…\n",
    "}\n",
    "\n",
    "optional_packages = {\n",
    "    'talib': 'TA-Lib',\n",
    "    'uqer': 'uqer'\n",
    "}\n",
    "\n",
    "# æ£€æŸ¥å¿…éœ€åŒ…\n",
    "missing_packages = []\n",
    "for package_display, package_install in required_packages.items():\n",
    "    if package_display == 'pathlib':  # pathlibæ˜¯æ ‡å‡†åº“\n",
    "        continue\n",
    "    try:\n",
    "        __import__(package_display)\n",
    "        print(f\"âœ… {package_display} å·²å®‰è£…\")\n",
    "    except ImportError:\n",
    "        print(f\"âŒ {package_display} æœªå®‰è£…\")\n",
    "        missing_packages.append(package_install)\n",
    "\n",
    "# å®‰è£…ç¼ºå¤±çš„åŒ…\n",
    "if missing_packages:\n",
    "    print(f\"\\nâš ï¸ æ­£åœ¨å®‰è£…ç¼ºå¤±åŒ…: {', '.join(missing_packages)}\")\n",
    "    try:\n",
    "        for package in missing_packages:\n",
    "            subprocess.check_call([\n",
    "                sys.executable, \"-m\", \"pip\", \"install\", package, \"--quiet\"\n",
    "            ])\n",
    "            print(f\"âœ… {package} å®‰è£…æˆåŠŸ\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"âŒ åŒ…å®‰è£…å¤±è´¥: {e}\")\n",
    "        print(\"ğŸ’¡ è¯·æ‰‹åŠ¨è¿è¡Œ: pip install pandas numpy scipy\")\n",
    "\n",
    "# æ£€æŸ¥å¯é€‰åŒ…\n",
    "print(f\"\\nğŸ“¦ æ£€æŸ¥å¯é€‰åŒ…...\")\n",
    "for package_display, package_name in optional_packages.items():\n",
    "    try:\n",
    "        __import__(package_display)\n",
    "        print(f\"âœ… {package_display} å·²å®‰è£…\")\n",
    "    except ImportError:\n",
    "        print(f\"âš ï¸ {package_display} æœªå®‰è£… (å¯é€‰)\")\n",
    "\n",
    "# å¯¼å…¥å¿…è¦åŒ…\n",
    "try:\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from pathlib import Path\n",
    "    print(\"âœ… æ ¸å¿ƒä¾èµ–åŒ…åŠ è½½æˆåŠŸ\")\n",
    "except ImportError as e:\n",
    "    print(f\"âŒ åŒ…å¯¼å…¥å¤±è´¥: {e}\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Cell 3: Mockç»„ä»¶å®šä¹‰\n",
    "\n",
    "```python\n",
    "# ========================================\n",
    "# Mockç»„ä»¶å®šä¹‰\n",
    "# ========================================\n",
    "\n",
    "class MockDataLoader:\n",
    "    \"\"\"æ¨¡æ‹ŸDataLoader\"\"\"\n",
    "    def __init__(self):\n",
    "        self.name = \"MockDataLoader\"\n",
    "    \n",
    "    def get_stock_list(self):\n",
    "        return ['000001.SZ', '000002.SZ', '600000.SH', '600036.SH', '000858.SZ']\n",
    "    \n",
    "    def load_price_data(self, start_date=None, end_date=None, symbols=None):\n",
    "        if symbols is None:\n",
    "            symbols = self.get_stock_list()[:3]\n",
    "        return create_test_price_data()\n",
    "    \n",
    "    def load_financial_data(self, symbols=None, start_date=None, end_date=None):\n",
    "        if symbols is None:\n",
    "            symbols = ['000001.SZ']\n",
    "        \n",
    "        # åˆ›å»ºç®€å•çš„è´¢åŠ¡æ•°æ®\n",
    "        dates = pd.date_range('2024-01-01', '2024-08-20', freq='Q')\n",
    "        data = {\n",
    "            'revenue': np.random.uniform(1e9, 1e10, len(dates)),\n",
    "            'profit': np.random.uniform(1e8, 1e9, len(dates)),\n",
    "            'market_cap': np.random.uniform(1e10, 1e11, len(dates))\n",
    "        }\n",
    "        return pd.DataFrame(data, index=dates)\n",
    "\n",
    "class MockDataProcessor:\n",
    "    \"\"\"æ¨¡æ‹ŸDataProcessor\"\"\"\n",
    "    def __init__(self):\n",
    "        self.name = \"MockDataProcessor\"\n",
    "    \n",
    "    def clean_price_data(self, data):\n",
    "        if data is None:\n",
    "            return None\n",
    "        # ç®€å•çš„æ¸…æ´—ï¼šåˆ é™¤ç©ºå€¼\n",
    "        return data.dropna()\n",
    "    \n",
    "    def filter_stock_pool(self, data, min_market_cap=1e9, min_volume=1e6):\n",
    "        if data is None:\n",
    "            return None\n",
    "        # è¿”å›æ‰€æœ‰è‚¡ç¥¨ï¼ˆç®€åŒ–ï¼‰\n",
    "        return data\n",
    "    \n",
    "    def normalize_data(self, data):\n",
    "        if data is None:\n",
    "            return None\n",
    "        # ç®€å•çš„æ ‡å‡†åŒ–\n",
    "        return (data - data.mean()) / data.std()\n",
    "\n",
    "def create_test_price_data():\n",
    "    \"\"\"åˆ›å»ºæµ‹è¯•ç”¨çš„ä»·æ ¼æ•°æ®\"\"\"\n",
    "    # åˆ›å»ºæ—¥æœŸèŒƒå›´\n",
    "    dates = pd.date_range('2024-01-01', '2024-08-20', freq='D')\n",
    "    symbols = ['000001.SZ', '000002.SZ', '600000.SH']\n",
    "    \n",
    "    # åˆ›å»ºå¤šçº§åˆ—ç´¢å¼•\n",
    "    columns = pd.MultiIndex.from_product(\n",
    "        [symbols, ['open', 'high', 'low', 'close', 'volume']],\n",
    "        names=['symbol', 'field']\n",
    "    )\n",
    "    \n",
    "    # ç”Ÿæˆéšæœºä»·æ ¼æ•°æ®\n",
    "    np.random.seed(42)  # ç¡®ä¿å¯é‡å¤æ€§\n",
    "    data = []\n",
    "    \n",
    "    for symbol in symbols:\n",
    "        base_price = np.random.uniform(10, 100)  # åŸºç¡€ä»·æ ¼\n",
    "        prices = []\n",
    "        \n",
    "        for i, date in enumerate(dates):\n",
    "            # ç”ŸæˆOHLCæ•°æ®\n",
    "            if i == 0:\n",
    "                close = base_price\n",
    "            else:\n",
    "                close = prices[-1] * (1 + np.random.normal(0, 0.02))  # 2%æ—¥æ³¢åŠ¨\n",
    "            \n",
    "            high = close * (1 + np.random.uniform(0, 0.05))\n",
    "            low = close * (1 - np.random.uniform(0, 0.05))\n",
    "            open_price = close * (1 + np.random.uniform(-0.02, 0.02))\n",
    "            volume = np.random.uniform(1e6, 1e8)  # æˆäº¤é‡\n",
    "            \n",
    "            prices.append(close)\n",
    "            data.extend([open_price, high, low, close, volume])\n",
    "    \n",
    "    # åˆ›å»ºDataFrame\n",
    "    data_array = np.array(data).reshape(len(dates), -1)\n",
    "    df = pd.DataFrame(data_array, index=dates, columns=columns)\n",
    "    \n",
    "    return df\n",
    "\n",
    "print(\"âœ… Mockç»„ä»¶å®šä¹‰å®Œæˆ\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Cell 4: MockFeatureEngineerå®šä¹‰\n",
    "\n",
    "```python\n",
    "class MockFeatureEngineer:\n",
    "    \"\"\"æ¨¡æ‹ŸFeatureEngineer\"\"\"\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.name = \"MockFeatureEngineer\"\n",
    "    \n",
    "    def generate_technical_indicators(self):\n",
    "        if self.data is None:\n",
    "            return None\n",
    "        \n",
    "        # åˆ›å»ºä¸€äº›ç®€å•çš„æŠ€æœ¯æŒ‡æ ‡\n",
    "        features = pd.DataFrame(index=self.data.index)\n",
    "        \n",
    "        for symbol in self.data.columns.get_level_values(0).unique():\n",
    "            if (symbol, 'close') in self.data.columns:\n",
    "                close_col = (symbol, 'close')\n",
    "            else:\n",
    "                # å¦‚æœåˆ—ç»“æ„ä¸åŒï¼Œå°è¯•å…¶ä»–æ–¹å¼\n",
    "                close_cols = [col for col in self.data.columns if 'close' in str(col).lower()]\n",
    "                if close_cols:\n",
    "                    close_col = close_cols[0]\n",
    "                else:\n",
    "                    continue\n",
    "            \n",
    "            try:\n",
    "                close_prices = self.data[close_col].dropna()\n",
    "                if len(close_prices) > 20:  # ç¡®ä¿æœ‰è¶³å¤Ÿæ•°æ®è®¡ç®—æŒ‡æ ‡\n",
    "                    # ç®€å•ç§»åŠ¨å¹³å‡\n",
    "                    features[f'{symbol}_MA5'] = close_prices.rolling(5).mean()\n",
    "                    features[f'{symbol}_MA20'] = close_prices.rolling(20).mean()\n",
    "                    \n",
    "                    # RSI (ç®€åŒ–ç‰ˆæœ¬)\n",
    "                    delta = close_prices.diff()\n",
    "                    gain = (delta.where(delta > 0, 0)).rolling(14).mean()\n",
    "                    loss = (-delta.where(delta < 0, 0)).rolling(14).mean()\n",
    "                    rs = gain / loss\n",
    "                    features[f'{symbol}_RSI'] = 100 - (100 / (1 + rs))\n",
    "                    \n",
    "                    # å¸ƒæ—å¸¦\n",
    "                    ma20 = close_prices.rolling(20).mean()\n",
    "                    std20 = close_prices.rolling(20).std()\n",
    "                    features[f'{symbol}_BOLL_UPPER'] = ma20 + 2 * std20\n",
    "                    features[f'{symbol}_BOLL_LOWER'] = ma20 - 2 * std20\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸ è®¡ç®—{symbol}æŠ€æœ¯æŒ‡æ ‡æ—¶å‡ºé”™: {e}\")\n",
    "                continue\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def generate_price_features(self):\n",
    "        if self.data is None:\n",
    "            return None\n",
    "        \n",
    "        features = pd.DataFrame(index=self.data.index)\n",
    "        \n",
    "        for symbol in self.data.columns.get_level_values(0).unique():\n",
    "            try:\n",
    "                # è·å–OHLCæ•°æ®\n",
    "                symbol_data = self.data[symbol] if symbol in self.data.columns else None\n",
    "                if symbol_data is None:\n",
    "                    continue\n",
    "                \n",
    "                if 'close' in symbol_data.columns:\n",
    "                    close = symbol_data['close']\n",
    "                    \n",
    "                    # ä»·æ ¼ç‰¹å¾\n",
    "                    features[f'{symbol}_return'] = close.pct_change()\n",
    "                    features[f'{symbol}_return_5d'] = close.pct_change(5)\n",
    "                    features[f'{symbol}_volatility_20d'] = close.pct_change().rolling(20).std()\n",
    "                    \n",
    "                    # ä»·æ ¼ä½ç½®ç‰¹å¾\n",
    "                    if 'high' in symbol_data.columns and 'low' in symbol_data.columns:\n",
    "                        high = symbol_data['high']\n",
    "                        low = symbol_data['low']\n",
    "                        features[f'{symbol}_price_position'] = (close - low) / (high - low)\n",
    "                    \n",
    "                    # ç´¯è®¡æ”¶ç›Š\n",
    "                    features[f'{symbol}_cumret_20d'] = (1 + close.pct_change()).rolling(20).apply(lambda x: x.prod()) - 1\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸ è®¡ç®—{symbol}ä»·æ ¼ç‰¹å¾æ—¶å‡ºé”™: {e}\")\n",
    "                continue\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def generate_volume_features(self):\n",
    "        if self.data is None:\n",
    "            return None\n",
    "        \n",
    "        features = pd.DataFrame(index=self.data.index)\n",
    "        \n",
    "        for symbol in self.data.columns.get_level_values(0).unique():\n",
    "            try:\n",
    "                symbol_data = self.data[symbol] if symbol in self.data.columns else None\n",
    "                if symbol_data is None or 'volume' not in symbol_data.columns:\n",
    "                    continue\n",
    "                \n",
    "                volume = symbol_data['volume']\n",
    "                \n",
    "                # æˆäº¤é‡ç‰¹å¾\n",
    "                features[f'{symbol}_volume_ma5'] = volume.rolling(5).mean()\n",
    "                features[f'{symbol}_volume_ma20'] = volume.rolling(20).mean()\n",
    "                features[f'{symbol}_volume_ratio'] = volume / volume.rolling(20).mean()\n",
    "                \n",
    "                # æˆäº¤é‡ç›¸å¯¹å¼ºåº¦\n",
    "                if 'close' in symbol_data.columns:\n",
    "                    close = symbol_data['close']\n",
    "                    price_change = close.pct_change()\n",
    "                    features[f'{symbol}_volume_price_corr'] = volume.rolling(20).corr(price_change)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸ è®¡ç®—{symbol}æˆäº¤é‡ç‰¹å¾æ—¶å‡ºé”™: {e}\")\n",
    "                continue\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def generate_all_features(self):\n",
    "        \"\"\"ç”Ÿæˆæ‰€æœ‰ç‰¹å¾\"\"\"\n",
    "        if self.data is None:\n",
    "            return None\n",
    "        \n",
    "        print(\"  ğŸ”¬ ç”ŸæˆæŠ€æœ¯æŒ‡æ ‡...\")\n",
    "        tech_features = self.generate_technical_indicators()\n",
    "        \n",
    "        print(\"  ğŸ’° ç”Ÿæˆä»·æ ¼ç‰¹å¾...\")\n",
    "        price_features = self.generate_price_features()\n",
    "        \n",
    "        print(\"  ğŸ“Š ç”Ÿæˆæˆäº¤é‡ç‰¹å¾...\")\n",
    "        volume_features = self.generate_volume_features()\n",
    "        \n",
    "        # åˆå¹¶æ‰€æœ‰ç‰¹å¾\n",
    "        all_features = pd.DataFrame(index=self.data.index)\n",
    "        \n",
    "        for features, name in [(tech_features, \"æŠ€æœ¯æŒ‡æ ‡\"), \n",
    "                             (price_features, \"ä»·æ ¼ç‰¹å¾\"), \n",
    "                             (volume_features, \"æˆäº¤é‡ç‰¹å¾\")]:\n",
    "            if features is not None:\n",
    "                all_features = pd.concat([all_features, features], axis=1)\n",
    "                print(f\"    âœ… {name}: {features.shape[1]}ä¸ªç‰¹å¾\")\n",
    "        \n",
    "        return all_features\n",
    "\n",
    "print(\"âœ… MockFeatureEngineerå®šä¹‰å®Œæˆ\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Cell 5: MockDataManagerå®šä¹‰\n",
    "\n",
    "```python\n",
    "class MockDataManager:\n",
    "    \"\"\"æ¨¡æ‹ŸDataManager\"\"\"\n",
    "    def __init__(self):\n",
    "        self.name = \"MockDataManager\"\n",
    "        self.cache = {}\n",
    "    \n",
    "    def run_complete_pipeline(self, start_date=None, end_date=None, symbols=None):\n",
    "        \"\"\"è¿è¡Œå®Œæ•´æ•°æ®æµæ°´çº¿\"\"\"\n",
    "        print(\"    ğŸš€ æ‰§è¡Œå®Œæ•´æ•°æ®æµæ°´çº¿...\")\n",
    "        start_time = time()\n",
    "        \n",
    "        try:\n",
    "            # æ­¥éª¤1: æ•°æ®è·å–\n",
    "            print(\"      ğŸ“¥ æ•°æ®è·å–...\")\n",
    "            loader = MockDataLoader()\n",
    "            raw_data = loader.load_price_data(start_date, end_date, symbols)\n",
    "            \n",
    "            # æ­¥éª¤2: æ•°æ®é¢„å¤„ç†\n",
    "            print(\"      ğŸ§¹ æ•°æ®é¢„å¤„ç†...\")\n",
    "            processor = MockDataProcessor()\n",
    "            clean_data = processor.clean_price_data(raw_data)\n",
    "            \n",
    "            # æ­¥éª¤3: ç‰¹å¾å·¥ç¨‹\n",
    "            print(\"      ğŸ”¬ ç‰¹å¾å·¥ç¨‹...\")\n",
    "            engineer = MockFeatureEngineer(clean_data)\n",
    "            features = engineer.generate_all_features()\n",
    "            \n",
    "            end_time = time()\n",
    "            processing_time = end_time - start_time\n",
    "            \n",
    "            # æ„å»ºè¿”å›ç»“æœ\n",
    "            result = {\n",
    "                'features': features,\n",
    "                'raw_data': raw_data,\n",
    "                'clean_data': clean_data,\n",
    "                'metadata': {\n",
    "                    'stock_count': len(symbols) if symbols else 5,\n",
    "                    'processing_time': round(processing_time, 2),\n",
    "                    'feature_count': features.shape[1] if features is not None else 0,\n",
    "                    'date_range': f\"{start_date} ~ {end_date}\",\n",
    "                    'success': True\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"      âŒ æµæ°´çº¿æ‰§è¡Œå¤±è´¥: {e}\")\n",
    "            return {\n",
    "                'features': None,\n",
    "                'metadata': {\n",
    "                    'success': False,\n",
    "                    'error': str(e),\n",
    "                    'processing_time': round(time() - start_time, 2)\n",
    "                }\n",
    "            }\n",
    "    \n",
    "    def get_cached_data(self, key):\n",
    "        \"\"\"è·å–ç¼“å­˜æ•°æ®\"\"\"\n",
    "        return self.cache.get(key)\n",
    "    \n",
    "    def set_cached_data(self, key, data):\n",
    "        \"\"\"è®¾ç½®ç¼“å­˜æ•°æ®\"\"\"\n",
    "        self.cache[key] = data\n",
    "        return True\n",
    "    \n",
    "    def validate_data_quality(self, data):\n",
    "        \"\"\"éªŒè¯æ•°æ®è´¨é‡\"\"\"\n",
    "        if data is None:\n",
    "            return False, \"æ•°æ®ä¸ºç©º\"\n",
    "        \n",
    "        if data.empty:\n",
    "            return False, \"æ•°æ®æ¡†ä¸ºç©º\"\n",
    "        \n",
    "        # æ£€æŸ¥ç¼ºå¤±å€¼æ¯”ä¾‹\n",
    "        missing_ratio = data.isnull().sum().sum() / (data.shape[0] * data.shape[1])\n",
    "        if missing_ratio > 0.5:\n",
    "            return False, f\"ç¼ºå¤±å€¼è¿‡å¤š: {missing_ratio:.1%}\"\n",
    "        \n",
    "        # æ£€æŸ¥æ•°æ®é‡\n",
    "        if len(data) < 20:\n",
    "            return False, f\"æ•°æ®é‡ä¸è¶³: {len(data)}è¡Œ\"\n",
    "        \n",
    "        return True, \"æ•°æ®è´¨é‡è‰¯å¥½\"\n",
    "\n",
    "def create_mock_data_module():\n",
    "    \"\"\"åˆ›å»ºæ¨¡æ‹Ÿçš„dataç›®å½•å’Œæ¨¡å—æ–‡ä»¶\"\"\"\n",
    "    print(\"ğŸ—ï¸ åˆ›å»ºæ¨¡æ‹Ÿdataæ¨¡å—...\")\n",
    "    \n",
    "    # åˆ›å»ºdataç›®å½•\n",
    "    os.makedirs('data', exist_ok=True)\n",
    "    \n",
    "    # åˆ›å»º__init__.pyæ–‡ä»¶\n",
    "    init_content = '''\"\"\"\n",
    "Dataæ¨¡å—åˆå§‹åŒ–æ–‡ä»¶\n",
    "\"\"\"\n",
    "\n",
    "def create_data_loader():\n",
    "    from .data_loader import DataLoader\n",
    "    return DataLoader()\n",
    "\n",
    "def create_data_processor():\n",
    "    from .data_processor import DataProcessor\n",
    "    return DataProcessor()\n",
    "\n",
    "def create_feature_engineer(data):\n",
    "    from .feature_engineer import FeatureEngineer\n",
    "    return FeatureEngineer(data)\n",
    "\n",
    "def create_data_manager():\n",
    "    from .data_manager import DataManager\n",
    "    return DataManager()\n",
    "\n",
    "def get_module_status():\n",
    "    return \"Mock Data Module - Ready\"\n",
    "\n",
    "def validate_data_pipeline():\n",
    "    return True\n",
    "'''\n",
    "    \n",
    "    with open('data/__init__.py', 'w', encoding='utf-8') as f:\n",
    "        f.write(init_content)\n",
    "    \n",
    "    print(\"âœ… æ¨¡æ‹Ÿdataæ¨¡å—åˆ›å»ºå®Œæˆ\")\n",
    "\n",
    "print(\"âœ… MockDataManagerå’Œå·¥å…·å‡½æ•°å®šä¹‰å®Œæˆ\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Cell 6: æµ‹è¯•1 - Dataæ¨¡å—å¯¼å…¥æµ‹è¯•\n",
    "\n",
    "```python\n",
    "# ========================================\n",
    "# æ­¥éª¤2: Dataæ¨¡å—å¯¼å…¥æµ‹è¯•\n",
    "# ========================================\n",
    "print(f\"\\nğŸ” æµ‹è¯•1: Dataæ¨¡å—å¯¼å…¥æµ‹è¯•\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "try:\n",
    "    # å°è¯•å¯¼å…¥dataæ¨¡å—\n",
    "    sys.path.insert(0, '.')  # æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„\n",
    "    \n",
    "    # æ£€æŸ¥æ˜¯å¦å­˜åœ¨dataç›®å½•\n",
    "    if not os.path.exists('data'):\n",
    "        print(\"âš ï¸ æœªæ‰¾åˆ°dataç›®å½•ï¼Œæ­£åœ¨åˆ›å»ºæ¨¡æ‹Ÿæ¨¡å—...\")\n",
    "        create_mock_data_module()\n",
    "    \n",
    "    # å°è¯•å¯¼å…¥\n",
    "    try:\n",
    "        from data import (\n",
    "            create_data_loader, create_data_processor, \n",
    "            create_feature_engineer, create_data_manager,\n",
    "            get_module_status, validate_data_pipeline\n",
    "        )\n",
    "        print(\"âœ… Dataæ¨¡å—æ ¸å¿ƒç»„ä»¶å¯¼å…¥æˆåŠŸ\")\n",
    "        test_results['import_test'] = True\n",
    "        \n",
    "    except ImportError as e:\n",
    "        print(f\"âŒ Dataæ¨¡å—å¯¼å…¥å¤±è´¥: {e}\")\n",
    "        print(\"ğŸ’¡ æ­£åœ¨åˆ›å»ºæ¨¡æ‹ŸDataæ¨¡å—è¿›è¡Œæµ‹è¯•...\")\n",
    "        \n",
    "        # ä½¿ç”¨æ¨¡æ‹Ÿç»„ä»¶ï¼ˆå·²åœ¨å…¨å±€å®šä¹‰ï¼‰\n",
    "        create_data_loader = lambda: MockDataLoader()\n",
    "        create_data_processor = lambda: MockDataProcessor()\n",
    "        create_feature_engineer = lambda data: MockFeatureEngineer(data)\n",
    "        create_data_manager = lambda: MockDataManager()\n",
    "        get_module_status = lambda: \"Mock Module Ready\"\n",
    "        validate_data_pipeline = lambda: True\n",
    "        \n",
    "        print(\"âœ… æ¨¡æ‹ŸDataæ¨¡å—åˆ›å»ºæˆåŠŸ\")\n",
    "        test_results['import_test'] = True\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ å¯¼å…¥æµ‹è¯•å¤±è´¥: {e}\")\n",
    "    test_results['import_test'] = False\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Cell 7: æµ‹è¯•2 - DataLoaderæ•°æ®è·å–æµ‹è¯•\n",
    "\n",
    "```python\n",
    "# ========================================\n",
    "# æ­¥éª¤3: DataLoaderæ•°æ®è·å–æµ‹è¯•\n",
    "# ========================================\n",
    "print(f\"\\nğŸ” æµ‹è¯•2: DataLoaderæ•°æ®è·å–æµ‹è¯•\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if test_results.get('import_test', False):\n",
    "    try:\n",
    "        # åˆ›å»ºDataLoaderå®ä¾‹\n",
    "        loader = create_data_loader()\n",
    "        \n",
    "        print(\"ğŸ“¥ æµ‹è¯•æ•°æ®è·å–åŠŸèƒ½:\")\n",
    "        \n",
    "        # æµ‹è¯•è‚¡ç¥¨åˆ—è¡¨è·å–\n",
    "        print(\"  ğŸ“‹ è·å–è‚¡ç¥¨åˆ—è¡¨...\")\n",
    "        stock_list = loader.get_stock_list()\n",
    "        print(f\"     è‚¡ç¥¨æ•°é‡: {len(stock_list) if stock_list else 0}\")\n",
    "        \n",
    "        # æµ‹è¯•ä»·æ ¼æ•°æ®è·å–\n",
    "        print(\"  ğŸ’° è·å–ä»·æ ¼æ•°æ®...\")\n",
    "        start_date = '2024-01-01'\n",
    "        end_date = '2024-08-20'\n",
    "        \n",
    "        price_data = loader.load_price_data(\n",
    "            start_date=start_date,\n",
    "            end_date=end_date,\n",
    "            symbols=['000001.SZ', '000002.SZ'][:2]  # æµ‹è¯•å‰2åªè‚¡ç¥¨\n",
    "        )\n",
    "        \n",
    "        if price_data is not None:\n",
    "            print(f\"     æ•°æ®å½¢çŠ¶: {price_data.shape}\")\n",
    "            print(f\"     åˆ—å: {list(price_data.columns)}\")\n",
    "            print(f\"     æ—¥æœŸèŒƒå›´: {price_data.index.min()} ~ {price_data.index.max()}\")\n",
    "        else:\n",
    "            print(\"     âš ï¸ æœªè·å–åˆ°ä»·æ ¼æ•°æ®\")\n",
    "        \n",
    "        # æµ‹è¯•è´¢åŠ¡æ•°æ®è·å–\n",
    "        print(\"  ğŸ“Š è·å–è´¢åŠ¡æ•°æ®...\")\n",
    "        financial_data = loader.load_financial_data(\n",
    "            symbols=['000001.SZ'][:1],\n",
    "            start_date=start_date,\n",
    "            end_date=end_date\n",
    "        )\n",
    "        \n",
    "        if financial_data is not None:\n",
    "            print(f\"     è´¢åŠ¡æ•°æ®å½¢çŠ¶: {financial_data.shape}\")\n",
    "        else:\n",
    "            print(\"     âš ï¸ æœªè·å–åˆ°è´¢åŠ¡æ•°æ®\")\n",
    "        \n",
    "        test_results['data_loader'] = True\n",
    "        print(\"âœ… DataLoaderæµ‹è¯•é€šè¿‡\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ DataLoaderæµ‹è¯•å¤±è´¥: {e}\")\n",
    "        print(f\"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}\")\n",
    "        test_results['data_loader'] = False\n",
    "else:\n",
    "    print(\"âŒ è·³è¿‡æµ‹è¯•2 - æ¨¡å—å¯¼å…¥å¤±è´¥\")\n",
    "    test_results['data_loader'] = False\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Cell 8: æµ‹è¯•3 - DataProcessoræ•°æ®é¢„å¤„ç†æµ‹è¯•\n",
    "\n",
    "```python\n",
    "# ========================================\n",
    "# æ­¥éª¤4: DataProcessoræ•°æ®é¢„å¤„ç†æµ‹è¯•\n",
    "# ========================================\n",
    "print(f\"\\nğŸ” æµ‹è¯•3: DataProcessoræ•°æ®é¢„å¤„ç†æµ‹è¯•\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if test_results.get('import_test', False):\n",
    "    try:\n",
    "        # åˆ›å»ºDataProcessorå®ä¾‹\n",
    "        processor = create_data_processor()\n",
    "        \n",
    "        print(\"ğŸ§¹ æµ‹è¯•æ•°æ®é¢„å¤„ç†åŠŸèƒ½:\")\n",
    "        \n",
    "        # åˆ›å»ºæµ‹è¯•æ•°æ®\n",
    "        test_data = create_test_price_data()\n",
    "        print(f\"  ğŸ“¥ åŸå§‹æµ‹è¯•æ•°æ®: {test_data.shape}\")\n",
    "        \n",
    "        # æµ‹è¯•æ•°æ®æ¸…æ´—\n",
    "        print(\"  ğŸ”§ æ•°æ®æ¸…æ´—...\")\n",
    "        clean_data = processor.clean_price_data(test_data)\n",
    "        if clean_data is not None:\n",
    "            print(f\"     æ¸…æ´—åæ•°æ®: {clean_data.shape}\")\n",
    "            print(f\"     ç¼ºå¤±å€¼å¤„ç†: {clean_data.isnull().sum().sum()}\")\n",
    "        \n",
    "        # æµ‹è¯•è‚¡ç¥¨æ± ç­›é€‰\n",
    "        print(\"  ğŸ¯ è‚¡ç¥¨æ± ç­›é€‰...\")\n",
    "        if hasattr(processor, 'filter_stock_pool'):\n",
    "            filtered_stocks = processor.filter_stock_pool(\n",
    "                clean_data if clean_data is not None else test_data,\n",
    "                min_market_cap=1e9,  # 10äº¿å¸‚å€¼\n",
    "                min_volume=1e6       # 100ä¸‡æˆäº¤é‡\n",
    "            )\n",
    "            if filtered_stocks is not None:\n",
    "                print(f\"     ç­›é€‰åè‚¡ç¥¨æ•°: {len(filtered_stocks.columns)}\")\n",
    "        \n",
    "        # æµ‹è¯•æ•°æ®æ ‡å‡†åŒ–\n",
    "        print(\"  ğŸ“ æ•°æ®æ ‡å‡†åŒ–...\")\n",
    "        if hasattr(processor, 'normalize_data'):\n",
    "            normalized_data = processor.normalize_data(\n",
    "                clean_data if clean_data is not None else test_data\n",
    "            )\n",
    "            if normalized_data is not None:\n",
    "                print(f\"     æ ‡å‡†åŒ–å®Œæˆ: {normalized_data.shape}\")\n",
    "        \n",
    "        test_results['data_processor'] = True\n",
    "        print(\"âœ… DataProcessoræµ‹è¯•é€šè¿‡\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ DataProcessoræµ‹è¯•å¤±è´¥: {e}\")\n",
    "        print(f\"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}\")\n",
    "        test_results['data_processor'] = False\n",
    "else:\n",
    "    print(\"âŒ è·³è¿‡æµ‹è¯•3 - æ¨¡å—å¯¼å…¥å¤±è´¥\")\n",
    "    test_results['data_processor'] = False\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Cell 9: æµ‹è¯•4 - FeatureEngineerç‰¹å¾å·¥ç¨‹æµ‹è¯•\n",
    "\n",
    "```python\n",
    "# ========================================\n",
    "# æ­¥éª¤5: FeatureEngineerç‰¹å¾å·¥ç¨‹æµ‹è¯•\n",
    "# ========================================\n",
    "print(f\"\\nğŸ” æµ‹è¯•4: FeatureEngineerç‰¹å¾å·¥ç¨‹æµ‹è¯•\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if test_results.get('import_test', False):\n",
    "    try:\n",
    "        # åˆ›å»ºæµ‹è¯•æ•°æ®\n",
    "        test_data = create_test_price_data()\n",
    "        \n",
    "        # åˆ›å»ºFeatureEngineerå®ä¾‹\n",
    "        engineer = create_feature_engineer(test_data)\n",
    "        \n",
    "        print(\"ğŸ”¬ æµ‹è¯•ç‰¹å¾å·¥ç¨‹åŠŸèƒ½:\")\n",
    "        \n",
    "        # æµ‹è¯•æŠ€æœ¯æŒ‡æ ‡ç”Ÿæˆ\n",
    "        print(\"  ğŸ“ˆ ç”ŸæˆæŠ€æœ¯æŒ‡æ ‡...\")\n",
    "        if hasattr(engineer, 'generate_technical_indicators'):\n",
    "            tech_features = engineer.generate_technical_indicators()\n",
    "            if tech_features is not None:\n",
    "                print(f\"     æŠ€æœ¯æŒ‡æ ‡æ•°é‡: {tech_features.shape[1] if hasattr(tech_features, 'shape') else len(tech_features)}\")\n",
    "        \n",
    "        # æµ‹è¯•ä»·æ ¼ç‰¹å¾\n",
    "        print(\"  ğŸ’° ç”Ÿæˆä»·æ ¼ç‰¹å¾...\")\n",
    "        if hasattr(engineer, 'generate_price_features'):\n",
    "            price_features = engineer.generate_price_features()\n",
    "            if price_features is not None:\n",
    "                print(f\"     ä»·æ ¼ç‰¹å¾æ•°é‡: {price_features.shape[1] if hasattr(price_features, 'shape') else len(price_features)}\")\n",
    "        \n",
    "        # æµ‹è¯•æˆäº¤é‡ç‰¹å¾\n",
    "        print(\"  ğŸ“Š ç”Ÿæˆæˆäº¤é‡ç‰¹å¾...\")\n",
    "        if hasattr(engineer, 'generate_volume_features'):\n",
    "            volume_features = engineer.generate_volume_features()\n",
    "            if volume_features is not None:\n",
    "                print(f\"     æˆäº¤é‡ç‰¹å¾æ•°é‡: {volume_features.shape[1] if hasattr(volume_features, 'shape') else len(volume_features)}\")\n",
    "        \n",
    "        # æµ‹è¯•æ‰€æœ‰ç‰¹å¾ç”Ÿæˆ\n",
    "        print(\"  ğŸ¯ ç”Ÿæˆæ‰€æœ‰ç‰¹å¾...\")\n",
    "        if hasattr(engineer, 'generate_all_features'):\n",
    "            all_features = engineer.generate_all_features()\n",
    "            if all_features is not None:\n",
    "                print(f\"     æ€»ç‰¹å¾æ•°é‡: {all_features.shape[1] if hasattr(all_features, 'shape') else len(all_features)}\")\n",
    "                print(f\"     ç‰¹å¾åç§°ç¤ºä¾‹: {list(all_features.columns)[:5] if hasattr(all_features, 'columns') else 'N/A'}\")\n",
    "        \n",
    "        test_results['feature_engineer'] = True\n",
    "        print(\"âœ… FeatureEngineeræµ‹è¯•é€šè¿‡\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ FeatureEngineeræµ‹è¯•å¤±è´¥: {e}\")\n",
    "        print(f\"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}\")\n",
    "        test_results['feature_engineer'] = False\n",
    "else:\n",
    "    print(\"âŒ è·³è¿‡æµ‹è¯•4 - æ¨¡å—å¯¼å…¥å¤±è´¥\")\n",
    "    test_results['feature_engineer'] = False\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## Cell 10: æµ‹è¯•5 - DataManageræ•°æ®ç®¡ç†å™¨æµ‹è¯•\n",
    "\n",
    "```python\n",
    "# ========================================\n",
    "# æ­¥éª¤6: DataManageræ•°æ®ç®¡ç†å™¨æµ‹è¯•\n",
    "# ========================================\n",
    "print(f\"\\nğŸ” æµ‹è¯•5: DataManageræ•°æ®ç®¡ç†å™¨æµ‹è¯•\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if test_results.get('import_test', False):\n",
    "    try:\n",
    "        # åˆ›å»ºDataManagerå®ä¾‹\n",
    "        manager = create_data_manager()\n",
    "        \n",
    "        print(\"ğŸ¯ æµ‹è¯•æ•°æ®ç®¡ç†å™¨åŠŸèƒ½:\")\n",
    "        \n",
    "        # æµ‹è¯•å®Œæ•´æ•°æ®æµæ°´çº¿\n",
    "        print(\"  ğŸš€ è¿è¡Œå®Œæ•´æ•°æ®æµæ°´çº¿...\")\n",
    "        if hasattr(manager, 'run_complete_pipeline'):\n",
    "            pipeline_result = manager.run_complete_pipeline(\n",
    "                start_date='2024-01-01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f87e2925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ é‡åŒ–äº¤æ˜“æ¡†æ¶Dataæ¨¡å—æµ‹è¯•\n",
      "============================================================\n",
      "ğŸ“ å½“å‰å·¥ä½œç›®å½•: /Users/jackstudio/æ ‡å‡†é‡åŒ–æ¡†æ¶æ­å»º/data\n",
      "ğŸ Pythonç‰ˆæœ¬: 3.13.5\n",
      "â° æµ‹è¯•å¼€å§‹æ—¶é—´: 2025-08-25 07:40:57\n",
      "\n",
      "ğŸ“¦ æ£€æŸ¥å¿…è¦çš„PythonåŒ…...\n",
      "âœ… pandas å·²å®‰è£…\n",
      "âœ… numpy å·²å®‰è£…\n",
      "âœ… scipy å·²å®‰è£…\n",
      "\n",
      "ğŸ“¦ æ£€æŸ¥å¯é€‰åŒ…...\n",
      "âœ… talib å·²å®‰è£…\n",
      "âœ… uqer å·²å®‰è£…\n",
      "âœ… æ ¸å¿ƒä¾èµ–åŒ…åŠ è½½æˆåŠŸ\n",
      "âœ… Mockç»„ä»¶å®šä¹‰å®Œæˆ\n",
      "âœ… MockFeatureEngineerå®šä¹‰å®Œæˆ\n",
      "âœ… MockDataManagerå’Œå·¥å…·å‡½æ•°å®šä¹‰å®Œæˆ\n",
      "\n",
      "ğŸ” æµ‹è¯•1: Dataæ¨¡å—å¯¼å…¥æµ‹è¯•\n",
      "==================================================\n",
      "âœ… Dataæ¨¡å—æ ¸å¿ƒç»„ä»¶å¯¼å…¥æˆåŠŸ\n",
      "\n",
      "ğŸ” æµ‹è¯•2: DataLoaderæ•°æ®è·å–æµ‹è¯•\n",
      "==================================================\n",
      "âŒ DataLoaderæµ‹è¯•å¤±è´¥: No module named 'data.data_loader'\n",
      "è¯¦ç»†é”™è¯¯: Traceback (most recent call last):\n",
      "  File \"/var/folders/yv/4ncm6d4n7y3gkrb20n8bvpyr0000gn/T/ipykernel_22161/4118281671.py\", line 513, in <module>\n",
      "    loader = create_data_loader()\n",
      "  File \"/Users/jackstudio/æ ‡å‡†é‡åŒ–æ¡†æ¶æ­å»º/data/data/__init__.py\", line 6, in create_data_loader\n",
      "    from .data_loader import DataLoader\n",
      "ModuleNotFoundError: No module named 'data.data_loader'\n",
      "\n",
      "============================================================\n",
      "ğŸŠ Dataæ¨¡å—åŸºç¡€æµ‹è¯•å®Œæˆï¼\n",
      "â° å½“å‰æ—¶é—´: 2025-08-25 07:40:57\n",
      "ğŸ’¡ è¯·ç»§ç»­è¿è¡Œåç»­æµ‹è¯•å•å…ƒ...\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Dataæ¨¡å—å®Œæ•´æµ‹è¯•å’ŒéªŒè¯ - data_test_validation.ipynb (ä¿®å¤ç‰ˆ)\n",
    "\n",
    "\"\"\"\n",
    "Dataæ¨¡å—å®Œæ•´æµ‹è¯•å’ŒéªŒè¯ - data_test_validation.ipynb (ä¿®å¤ç‰ˆ)\n",
    "===========================================================\n",
    "\n",
    "è¿™ä¸ªnotebookç”¨äºå…¨é¢æµ‹è¯•é‡åŒ–äº¤æ˜“æ¡†æ¶çš„æ•°æ®æ¨¡å—,ç¡®ä¿æ‰€æœ‰ç»„ä»¶éƒ½èƒ½æ­£å¸¸å·¥ä½œã€‚\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import subprocess\n",
    "import warnings\n",
    "import traceback\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Dict, List, Optional, Any, Tuple\n",
    "from time import time\n",
    "import json\n",
    "\n",
    "# ç¦ç”¨è­¦å‘Š\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"ğŸš€ é‡åŒ–äº¤æ˜“æ¡†æ¶Dataæ¨¡å—æµ‹è¯•\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"ğŸ“ å½“å‰å·¥ä½œç›®å½•: {os.getcwd()}\")\n",
    "print(f\"ğŸ Pythonç‰ˆæœ¬: {sys.version.split()[0]}\")\n",
    "print(f\"â° æµ‹è¯•å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "# è®°å½•æµ‹è¯•ç»“æœ\n",
    "test_results = {}\n",
    "\n",
    "# ========================================\n",
    "# æ­¥éª¤1: ç¯å¢ƒæ£€æŸ¥å’Œä¾èµ–å®‰è£…\n",
    "# ========================================\n",
    "print(f\"\\nğŸ“¦ æ£€æŸ¥å¿…è¦çš„PythonåŒ…...\")\n",
    "\n",
    "required_packages = {\n",
    "    'pandas': 'pandas',\n",
    "    'numpy': 'numpy',\n",
    "    'scipy': 'scipy',\n",
    "    'pathlib': 'pathlib'  # æ ‡å‡†åº“,é€šå¸¸ä¸éœ€è¦å®‰è£…\n",
    "}\n",
    "\n",
    "optional_packages = {\n",
    "    'talib': 'TA-Lib',\n",
    "    'uqer': 'uqer'\n",
    "}\n",
    "\n",
    "# æ£€æŸ¥å¿…éœ€åŒ…\n",
    "missing_packages = []\n",
    "for package_display, package_install in required_packages.items():\n",
    "    if package_display == 'pathlib':  # pathlibæ˜¯æ ‡å‡†åº“\n",
    "        continue\n",
    "    try:\n",
    "        __import__(package_display)\n",
    "        print(f\"âœ… {package_display} å·²å®‰è£…\")\n",
    "    except ImportError:\n",
    "        print(f\"âŒ {package_display} æœªå®‰è£…\")\n",
    "        missing_packages.append(package_install)\n",
    "\n",
    "# å®‰è£…ç¼ºå¤±çš„åŒ…\n",
    "if missing_packages:\n",
    "    print(f\"\\nâš ï¸ æ­£åœ¨å®‰è£…ç¼ºå¤±åŒ…: {', '.join(missing_packages)}\")\n",
    "    try:\n",
    "        for package in missing_packages:\n",
    "            subprocess.check_call([\n",
    "                sys.executable, \"-m\", \"pip\", \"install\", package, \"--quiet\"\n",
    "            ])\n",
    "            print(f\"âœ… {package} å®‰è£…æˆåŠŸ\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"âŒ åŒ…å®‰è£…å¤±è´¥: {e}\")\n",
    "        print(\"ğŸ’¡ è¯·æ‰‹åŠ¨è¿è¡Œ: pip install pandas numpy scipy\")\n",
    "\n",
    "# æ£€æŸ¥å¯é€‰åŒ…\n",
    "print(f\"\\nğŸ“¦ æ£€æŸ¥å¯é€‰åŒ…...\")\n",
    "for package_display, package_name in optional_packages.items():\n",
    "    try:\n",
    "        __import__(package_display)\n",
    "        print(f\"âœ… {package_display} å·²å®‰è£…\")\n",
    "    except ImportError:\n",
    "        print(f\"âš ï¸ {package_display} æœªå®‰è£… (å¯é€‰)\")\n",
    "\n",
    "# å¯¼å…¥å¿…è¦åŒ…\n",
    "try:\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from pathlib import Path\n",
    "    print(\"âœ… æ ¸å¿ƒä¾èµ–åŒ…åŠ è½½æˆåŠŸ\")\n",
    "except ImportError as e:\n",
    "    print(f\"âŒ åŒ…å¯¼å…¥å¤±è´¥: {e}\")\n",
    "\n",
    "# ========================================\n",
    "# Mockç»„ä»¶å®šä¹‰\n",
    "# ========================================\n",
    "\n",
    "class MockDataLoader:\n",
    "    \"\"\"æ¨¡æ‹ŸDataLoader\"\"\"\n",
    "    def __init__(self):\n",
    "        self.name = \"MockDataLoader\"\n",
    "    \n",
    "    def get_stock_list(self):\n",
    "        return ['000001.SZ', '000002.SZ', '600000.SH', '600036.SH', '000858.SZ']\n",
    "    \n",
    "    def load_price_data(self, start_date=None, end_date=None, symbols=None):\n",
    "        if symbols is None:\n",
    "            symbols = self.get_stock_list()[:3]\n",
    "        return create_test_price_data()\n",
    "    \n",
    "    def load_financial_data(self, symbols=None, start_date=None, end_date=None):\n",
    "        if symbols is None:\n",
    "            symbols = ['000001.SZ']\n",
    "        \n",
    "        # åˆ›å»ºç®€å•çš„è´¢åŠ¡æ•°æ®\n",
    "        dates = pd.date_range('2024-01-01', '2024-08-20', freq='Q')\n",
    "        data = {\n",
    "            'revenue': np.random.uniform(1e9, 1e10, len(dates)),\n",
    "            'profit': np.random.uniform(1e8, 1e9, len(dates)),\n",
    "            'market_cap': np.random.uniform(1e10, 1e11, len(dates))\n",
    "        }\n",
    "        return pd.DataFrame(data, index=dates)\n",
    "\n",
    "class MockDataProcessor:\n",
    "    \"\"\"æ¨¡æ‹ŸDataProcessor\"\"\"\n",
    "    def __init__(self):\n",
    "        self.name = \"MockDataProcessor\"\n",
    "    \n",
    "    def clean_price_data(self, data):\n",
    "        if data is None:\n",
    "            return None\n",
    "        # ç®€å•çš„æ¸…æ´—ï¼šåˆ é™¤ç©ºå€¼\n",
    "        return data.dropna()\n",
    "    \n",
    "    def filter_stock_pool(self, data, min_market_cap=1e9, min_volume=1e6):\n",
    "        if data is None:\n",
    "            return None\n",
    "        # è¿”å›æ‰€æœ‰è‚¡ç¥¨ï¼ˆç®€åŒ–ï¼‰\n",
    "        return data\n",
    "    \n",
    "    def normalize_data(self, data):\n",
    "        if data is None:\n",
    "            return None\n",
    "        # ç®€å•çš„æ ‡å‡†åŒ–\n",
    "        return (data - data.mean()) / data.std()\n",
    "\n",
    "def create_test_price_data():\n",
    "    \"\"\"åˆ›å»ºæµ‹è¯•ç”¨çš„ä»·æ ¼æ•°æ®\"\"\"\n",
    "    # åˆ›å»ºæ—¥æœŸèŒƒå›´\n",
    "    dates = pd.date_range('2024-01-01', '2024-08-20', freq='D')\n",
    "    symbols = ['000001.SZ', '000002.SZ', '600000.SH']\n",
    "    \n",
    "    # åˆ›å»ºå¤šçº§åˆ—ç´¢å¼•\n",
    "    columns = pd.MultiIndex.from_product(\n",
    "        [symbols, ['open', 'high', 'low', 'close', 'volume']],\n",
    "        names=['symbol', 'field']\n",
    "    )\n",
    "    \n",
    "    # ç”Ÿæˆéšæœºä»·æ ¼æ•°æ®\n",
    "    np.random.seed(42)  # ç¡®ä¿å¯é‡å¤æ€§\n",
    "    data = []\n",
    "    \n",
    "    for symbol in symbols:\n",
    "        base_price = np.random.uniform(10, 100)  # åŸºç¡€ä»·æ ¼\n",
    "        prices = []\n",
    "        \n",
    "        for i, date in enumerate(dates):\n",
    "            # ç”ŸæˆOHLCæ•°æ®\n",
    "            if i == 0:\n",
    "                close = base_price\n",
    "            else:\n",
    "                close = prices[-1] * (1 + np.random.normal(0, 0.02))  # 2%æ—¥æ³¢åŠ¨\n",
    "            \n",
    "            high = close * (1 + np.random.uniform(0, 0.05))\n",
    "            low = close * (1 - np.random.uniform(0, 0.05))\n",
    "            open_price = close * (1 + np.random.uniform(-0.02, 0.02))\n",
    "            volume = np.random.uniform(1e6, 1e8)  # æˆäº¤é‡\n",
    "            \n",
    "            prices.append(close)\n",
    "            data.extend([open_price, high, low, close, volume])\n",
    "    \n",
    "    # åˆ›å»ºDataFrame\n",
    "    data_array = np.array(data).reshape(len(dates), -1)\n",
    "    df = pd.DataFrame(data_array, index=dates, columns=columns)\n",
    "    \n",
    "    return df\n",
    "\n",
    "print(\"âœ… Mockç»„ä»¶å®šä¹‰å®Œæˆ\")\n",
    "\n",
    "class MockFeatureEngineer:\n",
    "    \"\"\"æ¨¡æ‹ŸFeatureEngineer\"\"\"\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "        self.name = \"MockFeatureEngineer\"\n",
    "    \n",
    "    def generate_technical_indicators(self):\n",
    "        if self.data is None:\n",
    "            return None\n",
    "        \n",
    "        # åˆ›å»ºä¸€äº›ç®€å•çš„æŠ€æœ¯æŒ‡æ ‡\n",
    "        features = pd.DataFrame(index=self.data.index)\n",
    "        \n",
    "        for symbol in self.data.columns.get_level_values(0).unique():\n",
    "            if (symbol, 'close') in self.data.columns:\n",
    "                close_col = (symbol, 'close')\n",
    "            else:\n",
    "                # å¦‚æœåˆ—ç»“æ„ä¸åŒ,å°è¯•å…¶ä»–æ–¹å¼\n",
    "                close_cols = [col for col in self.data.columns if 'close' in str(col).lower()]\n",
    "                if close_cols:\n",
    "                    close_col = close_cols[0]\n",
    "                else:\n",
    "                    continue\n",
    "            \n",
    "            try:\n",
    "                close_prices = self.data[close_col].dropna()\n",
    "                if len(close_prices) > 20:  # ç¡®ä¿æœ‰è¶³å¤Ÿæ•°æ®è®¡ç®—æŒ‡æ ‡\n",
    "                    # ç®€å•ç§»åŠ¨å¹³å‡\n",
    "                    features[f'{symbol}_MA5'] = close_prices.rolling(5).mean()\n",
    "                    features[f'{symbol}_MA20'] = close_prices.rolling(20).mean()\n",
    "                    \n",
    "                    # RSI (ç®€åŒ–ç‰ˆæœ¬)\n",
    "                    delta = close_prices.diff()\n",
    "                    gain = (delta.where(delta > 0, 0)).rolling(14).mean()\n",
    "                    loss = (-delta.where(delta < 0, 0)).rolling(14).mean()\n",
    "                    rs = gain / loss\n",
    "                    features[f'{symbol}_RSI'] = 100 - (100 / (1 + rs))\n",
    "                    \n",
    "                    # å¸ƒæ—å¸¦\n",
    "                    ma20 = close_prices.rolling(20).mean()\n",
    "                    std20 = close_prices.rolling(20).std()\n",
    "                    features[f'{symbol}_BOLL_UPPER'] = ma20 + 2 * std20\n",
    "                    features[f'{symbol}_BOLL_LOWER'] = ma20 - 2 * std20\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸ è®¡ç®—{symbol}æŠ€æœ¯æŒ‡æ ‡æ—¶å‡ºé”™: {e}\")\n",
    "                continue\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def generate_price_features(self):\n",
    "        if self.data is None:\n",
    "            return None\n",
    "        \n",
    "        features = pd.DataFrame(index=self.data.index)\n",
    "        \n",
    "        for symbol in self.data.columns.get_level_values(0).unique():\n",
    "            try:\n",
    "                # è·å–OHLCæ•°æ®\n",
    "                symbol_data = self.data[symbol] if symbol in self.data.columns else None\n",
    "                if symbol_data is None:\n",
    "                    continue\n",
    "                \n",
    "                if 'close' in symbol_data.columns:\n",
    "                    close = symbol_data['close']\n",
    "                    \n",
    "                    # ä»·æ ¼ç‰¹å¾\n",
    "                    features[f'{symbol}_return'] = close.pct_change()\n",
    "                    features[f'{symbol}_return_5d'] = close.pct_change(5)\n",
    "                    features[f'{symbol}_volatility_20d'] = close.pct_change().rolling(20).std()\n",
    "                    \n",
    "                    # ä»·æ ¼ä½ç½®ç‰¹å¾\n",
    "                    if 'high' in symbol_data.columns and 'low' in symbol_data.columns:\n",
    "                        high = symbol_data['high']\n",
    "                        low = symbol_data['low']\n",
    "                        features[f'{symbol}_price_position'] = (close - low) / (high - low)\n",
    "                    \n",
    "                    # ç´¯è®¡æ”¶ç›Š\n",
    "                    features[f'{symbol}_cumret_20d'] = (1 + close.pct_change()).rolling(20).apply(lambda x: x.prod()) - 1\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸ è®¡ç®—{symbol}ä»·æ ¼ç‰¹å¾æ—¶å‡ºé”™: {e}\")\n",
    "                continue\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def generate_volume_features(self):\n",
    "        if self.data is None:\n",
    "            return None\n",
    "        \n",
    "        features = pd.DataFrame(index=self.data.index)\n",
    "        \n",
    "        for symbol in self.data.columns.get_level_values(0).unique():\n",
    "            try:\n",
    "                symbol_data = self.data[symbol] if symbol in self.data.columns else None\n",
    "                if symbol_data is None or 'volume' not in symbol_data.columns:\n",
    "                    continue\n",
    "                \n",
    "                volume = symbol_data['volume']\n",
    "                \n",
    "                # æˆäº¤é‡ç‰¹å¾\n",
    "                features[f'{symbol}_volume_ma5'] = volume.rolling(5).mean()\n",
    "                features[f'{symbol}_volume_ma20'] = volume.rolling(20).mean()\n",
    "                features[f'{symbol}_volume_ratio'] = volume / volume.rolling(20).mean()\n",
    "                \n",
    "                # æˆäº¤é‡ç›¸å¯¹å¼ºåº¦\n",
    "                if 'close' in symbol_data.columns:\n",
    "                    close = symbol_data['close']\n",
    "                    price_change = close.pct_change()\n",
    "                    features[f'{symbol}_volume_price_corr'] = volume.rolling(20).corr(price_change)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸ è®¡ç®—{symbol}æˆäº¤é‡ç‰¹å¾æ—¶å‡ºé”™: {e}\")\n",
    "                continue\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def generate_all_features(self):\n",
    "        \"\"\"ç”Ÿæˆæ‰€æœ‰ç‰¹å¾\"\"\"\n",
    "        if self.data is None:\n",
    "            return None\n",
    "        \n",
    "        print(\"  ğŸ”¬ ç”ŸæˆæŠ€æœ¯æŒ‡æ ‡...\")\n",
    "        tech_features = self.generate_technical_indicators()\n",
    "        \n",
    "        print(\"  ğŸ’° ç”Ÿæˆä»·æ ¼ç‰¹å¾...\")\n",
    "        price_features = self.generate_price_features()\n",
    "        \n",
    "        print(\"  ğŸ“Š ç”Ÿæˆæˆäº¤é‡ç‰¹å¾...\")\n",
    "        volume_features = self.generate_volume_features()\n",
    "        \n",
    "        # åˆå¹¶æ‰€æœ‰ç‰¹å¾\n",
    "        all_features = pd.DataFrame(index=self.data.index)\n",
    "        \n",
    "        for features, name in [(tech_features, \"æŠ€æœ¯æŒ‡æ ‡\"), \n",
    "                             (price_features, \"ä»·æ ¼ç‰¹å¾\"), \n",
    "                             (volume_features, \"æˆäº¤é‡ç‰¹å¾\")]:\n",
    "            if features is not None:\n",
    "                all_features = pd.concat([all_features, features], axis=1)\n",
    "                print(f\"    âœ… {name}: {features.shape[1]}ä¸ªç‰¹å¾\")\n",
    "        \n",
    "        return all_features\n",
    "\n",
    "print(\"âœ… MockFeatureEngineerå®šä¹‰å®Œæˆ\")\n",
    "\n",
    "class MockDataManager:\n",
    "    \"\"\"æ¨¡æ‹ŸDataManager\"\"\"\n",
    "    def __init__(self):\n",
    "        self.name = \"MockDataManager\"\n",
    "        self.cache = {}\n",
    "    \n",
    "    def run_complete_pipeline(self, start_date=None, end_date=None, symbols=None):\n",
    "        \"\"\"è¿è¡Œå®Œæ•´æ•°æ®æµæ°´çº¿\"\"\"\n",
    "        print(\"    ğŸš€ æ‰§è¡Œå®Œæ•´æ•°æ®æµæ°´çº¿...\")\n",
    "        start_time = time()\n",
    "        \n",
    "        try:\n",
    "            # æ­¥éª¤1: æ•°æ®è·å–\n",
    "            print(\"      ğŸ“¥ æ•°æ®è·å–...\")\n",
    "            loader = MockDataLoader()\n",
    "            raw_data = loader.load_price_data(start_date, end_date, symbols)\n",
    "            \n",
    "            # æ­¥éª¤2: æ•°æ®é¢„å¤„ç†\n",
    "            print(\"      ğŸ§¹ æ•°æ®é¢„å¤„ç†...\")\n",
    "            processor = MockDataProcessor()\n",
    "            clean_data = processor.clean_price_data(raw_data)\n",
    "            \n",
    "            # æ­¥éª¤3: ç‰¹å¾å·¥ç¨‹\n",
    "            print(\"      ğŸ”¬ ç‰¹å¾å·¥ç¨‹...\")\n",
    "            engineer = MockFeatureEngineer(clean_data)\n",
    "            features = engineer.generate_all_features()\n",
    "            \n",
    "            end_time = time()\n",
    "            processing_time = end_time - start_time\n",
    "            \n",
    "            # æ„å»ºè¿”å›ç»“æœ\n",
    "            result = {\n",
    "                'features': features,\n",
    "                'raw_data': raw_data,\n",
    "                'clean_data': clean_data,\n",
    "                'metadata': {\n",
    "                    'stock_count': len(symbols) if symbols else 5,\n",
    "                    'processing_time': round(processing_time, 2),\n",
    "                    'feature_count': features.shape[1] if features is not None else 0,\n",
    "                    'date_range': f\"{start_date} ~ {end_date}\",\n",
    "                    'success': True\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"      âŒ æµæ°´çº¿æ‰§è¡Œå¤±è´¥: {e}\")\n",
    "            return {\n",
    "                'features': None,\n",
    "                'metadata': {\n",
    "                    'success': False,\n",
    "                    'error': str(e),\n",
    "                    'processing_time': round(time() - start_time, 2)\n",
    "                }\n",
    "            }\n",
    "    \n",
    "    def get_cached_data(self, key):\n",
    "        \"\"\"è·å–ç¼“å­˜æ•°æ®\"\"\"\n",
    "        return self.cache.get(key)\n",
    "    \n",
    "    def set_cached_data(self, key, data):\n",
    "        \"\"\"è®¾ç½®ç¼“å­˜æ•°æ®\"\"\"\n",
    "        self.cache[key] = data\n",
    "        return True\n",
    "    \n",
    "    def validate_data_quality(self, data):\n",
    "        \"\"\"éªŒè¯æ•°æ®è´¨é‡\"\"\"\n",
    "        if data is None:\n",
    "            return False, \"æ•°æ®ä¸ºç©º\"\n",
    "        \n",
    "        if data.empty:\n",
    "            return False, \"æ•°æ®æ¡†ä¸ºç©º\"\n",
    "        \n",
    "        # æ£€æŸ¥ç¼ºå¤±å€¼æ¯”ä¾‹\n",
    "        missing_ratio = data.isnull().sum().sum() / (data.shape[0] * data.shape[1])\n",
    "        if missing_ratio > 0.5:\n",
    "            return False, f\"ç¼ºå¤±å€¼è¿‡å¤š: {missing_ratio:.1%}\"\n",
    "        \n",
    "        # æ£€æŸ¥æ•°æ®é‡\n",
    "        if len(data) < 20:\n",
    "            return False, f\"æ•°æ®é‡ä¸è¶³: {len(data)}è¡Œ\"\n",
    "        \n",
    "        return True, \"æ•°æ®è´¨é‡è‰¯å¥½\"\n",
    "\n",
    "def create_mock_data_module():\n",
    "    \"\"\"åˆ›å»ºæ¨¡æ‹Ÿçš„dataç›®å½•å’Œæ¨¡å—æ–‡ä»¶\"\"\"\n",
    "    print(\"ğŸ—ï¸ åˆ›å»ºæ¨¡æ‹Ÿdataæ¨¡å—...\")\n",
    "    \n",
    "    # åˆ›å»ºdataç›®å½•\n",
    "    os.makedirs('data', exist_ok=True)\n",
    "    \n",
    "    # åˆ›å»º__init__.pyæ–‡ä»¶\n",
    "    init_content = '''\"\"\"\n",
    "Dataæ¨¡å—åˆå§‹åŒ–æ–‡ä»¶\n",
    "\"\"\"\n",
    "\n",
    "def create_data_loader():\n",
    "    from .data_loader import DataLoader\n",
    "    return DataLoader()\n",
    "\n",
    "def create_data_processor():\n",
    "    from .data_processor import DataProcessor\n",
    "    return DataProcessor()\n",
    "\n",
    "def create_feature_engineer(data):\n",
    "    from .feature_engineer import FeatureEngineer\n",
    "    return FeatureEngineer(data)\n",
    "\n",
    "def create_data_manager():\n",
    "    from .data_manager import DataManager\n",
    "    return DataManager()\n",
    "\n",
    "def get_module_status():\n",
    "    return \"Mock Data Module - Ready\"\n",
    "\n",
    "def validate_data_pipeline():\n",
    "    return True\n",
    "'''\n",
    "    \n",
    "    with open('data/__init__.py', 'w', encoding='utf-8') as f:\n",
    "        f.write(init_content)\n",
    "    \n",
    "    print(\"âœ… æ¨¡æ‹Ÿdataæ¨¡å—åˆ›å»ºå®Œæˆ\")\n",
    "\n",
    "print(\"âœ… MockDataManagerå’Œå·¥å…·å‡½æ•°å®šä¹‰å®Œæˆ\")\n",
    "\n",
    "# ========================================\n",
    "# æ­¥éª¤2: Dataæ¨¡å—å¯¼å…¥æµ‹è¯•\n",
    "# ========================================\n",
    "print(f\"\\nğŸ” æµ‹è¯•1: Dataæ¨¡å—å¯¼å…¥æµ‹è¯•\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "try:\n",
    "    # å°è¯•å¯¼å…¥dataæ¨¡å—\n",
    "    sys.path.insert(0, '.')  # æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„\n",
    "    \n",
    "    # æ£€æŸ¥æ˜¯å¦å­˜åœ¨dataç›®å½•\n",
    "    if not os.path.exists('data'):\n",
    "        print(\"âš ï¸ æœªæ‰¾åˆ°dataç›®å½•,æ­£åœ¨åˆ›å»ºæ¨¡æ‹Ÿæ¨¡å—...\")\n",
    "        create_mock_data_module()\n",
    "    \n",
    "    # å°è¯•å¯¼å…¥\n",
    "    try:\n",
    "        from data import (\n",
    "            create_data_loader, create_data_processor, \n",
    "            create_feature_engineer, create_data_manager,\n",
    "            get_module_status, validate_data_pipeline\n",
    "        )\n",
    "        print(\"âœ… Dataæ¨¡å—æ ¸å¿ƒç»„ä»¶å¯¼å…¥æˆåŠŸ\")\n",
    "        test_results['import_test'] = True\n",
    "        \n",
    "    except ImportError as e:\n",
    "        print(f\"âŒ Dataæ¨¡å—å¯¼å…¥å¤±è´¥: {e}\")\n",
    "        print(\"ğŸ’¡ æ­£åœ¨åˆ›å»ºæ¨¡æ‹ŸDataæ¨¡å—è¿›è¡Œæµ‹è¯•...\")\n",
    "        \n",
    "        # ä½¿ç”¨æ¨¡æ‹Ÿç»„ä»¶ï¼ˆå·²åœ¨å…¨å±€å®šä¹‰ï¼‰\n",
    "        create_data_loader = lambda: MockDataLoader()\n",
    "        create_data_processor = lambda: MockDataProcessor()\n",
    "        create_feature_engineer = lambda data: MockFeatureEngineer(data)\n",
    "        create_data_manager = lambda: MockDataManager()\n",
    "        get_module_status = lambda: \"Mock Module Ready\"\n",
    "        validate_data_pipeline = lambda: True\n",
    "        \n",
    "        print(\"âœ… æ¨¡æ‹ŸDataæ¨¡å—åˆ›å»ºæˆåŠŸ\")\n",
    "        test_results['import_test'] = True\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ å¯¼å…¥æµ‹è¯•å¤±è´¥: {e}\")\n",
    "    test_results['import_test'] = False\n",
    "\n",
    "# ========================================\n",
    "# æ­¥éª¤3: DataLoaderæ•°æ®è·å–æµ‹è¯•\n",
    "# ========================================\n",
    "print(f\"\\nğŸ” æµ‹è¯•2: DataLoaderæ•°æ®è·å–æµ‹è¯•\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if test_results.get('import_test', False):\n",
    "    try:\n",
    "        # åˆ›å»ºDataLoaderå®ä¾‹\n",
    "        loader = create_data_loader()\n",
    "        \n",
    "        print(\"ğŸ“¥ æµ‹è¯•æ•°æ®è·å–åŠŸèƒ½:\")\n",
    "        \n",
    "        # æµ‹è¯•è‚¡ç¥¨åˆ—è¡¨è·å–\n",
    "        print(\"  ğŸ“‹ è·å–è‚¡ç¥¨åˆ—è¡¨...\")\n",
    "        stock_list = loader.get_stock_list()\n",
    "        print(f\"     è‚¡ç¥¨æ•°é‡: {len(stock_list) if stock_list else 0}\")\n",
    "        \n",
    "        # æµ‹è¯•ä»·æ ¼æ•°æ®è·å–\n",
    "        print(\"  ğŸ’° è·å–ä»·æ ¼æ•°æ®...\")\n",
    "        start_date = '2024-01-01'\n",
    "        end_date = '2024-08-20'\n",
    "        \n",
    "        price_data = loader.load_price_data(\n",
    "            start_date=start_date,\n",
    "            end_date=end_date,\n",
    "            symbols=['000001.SZ', '000002.SZ'][:2]  # æµ‹è¯•å‰2åªè‚¡ç¥¨\n",
    "        )\n",
    "        \n",
    "        if price_data is not None:\n",
    "            print(f\"     æ•°æ®å½¢çŠ¶: {price_data.shape}\")\n",
    "            print(f\"     åˆ—å: {list(price_data.columns)}\")\n",
    "            print(f\"     æ—¥æœŸèŒƒå›´: {price_data.index.min()} ~ {price_data.index.max()}\")\n",
    "        else:\n",
    "            print(\"     âš ï¸ æœªè·å–åˆ°ä»·æ ¼æ•°æ®\")\n",
    "        \n",
    "        # æµ‹è¯•è´¢åŠ¡æ•°æ®è·å–\n",
    "        print(\"  ğŸ“Š è·å–è´¢åŠ¡æ•°æ®...\")\n",
    "        financial_data = loader.load_financial_data(\n",
    "            symbols=['000001.SZ'][:1],\n",
    "            start_date=start_date,\n",
    "            end_date=end_date\n",
    "        )\n",
    "        \n",
    "        if financial_data is not None:\n",
    "            print(f\"     è´¢åŠ¡æ•°æ®å½¢çŠ¶: {financial_data.shape}\")\n",
    "        else:\n",
    "            print(\"     âš ï¸ æœªè·å–åˆ°è´¢åŠ¡æ•°æ®\")\n",
    "        \n",
    "        test_results['data_loader'] = True\n",
    "        print(\"âœ… DataLoaderæµ‹è¯•é€šè¿‡\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ DataLoaderæµ‹è¯•å¤±è´¥: {e}\")\n",
    "        print(f\"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}\")\n",
    "        test_results['data_loader'] = False\n",
    "else:\n",
    "    print(\"âŒ è·³è¿‡æµ‹è¯•2 - æ¨¡å—å¯¼å…¥å¤±è´¥\")\n",
    "    test_results['data_loader'] = False\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ğŸŠ Dataæ¨¡å—åŸºç¡€æµ‹è¯•å®Œæˆï¼\")\n",
    "print(f\"â° å½“å‰æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"ğŸ’¡ è¯·ç»§ç»­è¿è¡Œåç»­æµ‹è¯•å•å…ƒ...\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "400ff231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ é‡åŒ–äº¤æ˜“æ¡†æ¶Dataæ¨¡å—æµ‹è¯• - çº¯Notebookç‰ˆæœ¬\n",
      "=================================================================\n",
      "ğŸ“ å½“å‰å·¥ä½œç›®å½•: /Users/jackstudio/æ ‡å‡†é‡åŒ–æ¡†æ¶æ­å»º/data\n",
      "ğŸ Pythonç‰ˆæœ¬: 3.13.5\n",
      "â° æµ‹è¯•å¼€å§‹æ—¶é—´: 2025-08-25 07:49:15\n",
      "âœ… Mockç»„ä»¶å®šä¹‰å®Œæˆ\n",
      "\n",
      "ğŸ” æµ‹è¯•1: æ¨¡å—ç»„ä»¶åŠŸèƒ½æµ‹è¯•\n",
      "==================================================\n",
      "âœ… æ‰€æœ‰ç»„ä»¶å·²å†…ç½®å®šä¹‰\n",
      "\n",
      "ğŸ” æµ‹è¯•2: DataLoaderæ•°æ®è·å–æµ‹è¯•\n",
      "==================================================\n",
      "ğŸ“¥ æµ‹è¯•æ•°æ®è·å–åŠŸèƒ½:\n",
      "  ğŸ“‹ è·å–è‚¡ç¥¨åˆ—è¡¨...\n",
      "     è‚¡ç¥¨æ•°é‡: 10\n",
      "  ğŸ’° è·å–ä»·æ ¼æ•°æ®...\n",
      "     æ•°æ®å½¢çŠ¶: (233, 10)\n",
      "     æ—¥æœŸèŒƒå›´: 2024-01-01 00:00:00 ~ 2024-08-20 00:00:00\n",
      "  ğŸ“Š è·å–è´¢åŠ¡æ•°æ®...\n",
      "     è´¢åŠ¡æ•°æ®å½¢çŠ¶: (2, 3)\n",
      "âœ… DataLoaderæµ‹è¯•é€šè¿‡\n",
      "\n",
      "ğŸ” æµ‹è¯•3: DataProcessoræ•°æ®é¢„å¤„ç†æµ‹è¯•\n",
      "==================================================\n",
      "ğŸ§¹ æµ‹è¯•æ•°æ®é¢„å¤„ç†åŠŸèƒ½:\n",
      "  ğŸ“¥ åŸå§‹æµ‹è¯•æ•°æ®: (233, 15)\n",
      "  ğŸ”§ æ•°æ®æ¸…æ´—...\n",
      "     æ¸…æ´—åæ•°æ®: (233, 15)\n",
      "  ğŸ¯ è‚¡ç¥¨æ± ç­›é€‰...\n",
      "     ç­›é€‰åæ•°æ®: (233, 15)\n",
      "  ğŸ“ æ•°æ®æ ‡å‡†åŒ–...\n",
      "     æ ‡å‡†åŒ–å®Œæˆ: (233, 15)\n",
      "âœ… DataProcessoræµ‹è¯•é€šè¿‡\n",
      "\n",
      "ğŸ” æµ‹è¯•4: FeatureEngineerç‰¹å¾å·¥ç¨‹æµ‹è¯•\n",
      "==================================================\n",
      "ğŸ”¬ æµ‹è¯•ç‰¹å¾å·¥ç¨‹åŠŸèƒ½:\n",
      "  ğŸ“ˆ ç”ŸæˆæŠ€æœ¯æŒ‡æ ‡...\n",
      "     æŠ€æœ¯æŒ‡æ ‡æ•°é‡: 15\n",
      "  ğŸ’° ç”Ÿæˆä»·æ ¼ç‰¹å¾...\n",
      "     ä»·æ ¼ç‰¹å¾æ•°é‡: 12\n",
      "  ğŸ“Š ç”Ÿæˆæˆäº¤é‡ç‰¹å¾...\n",
      "     æˆäº¤é‡ç‰¹å¾æ•°é‡: 9\n",
      "  ğŸ¯ ç”Ÿæˆæ‰€æœ‰ç‰¹å¾...\n",
      "  ğŸ”¬ ç”ŸæˆæŠ€æœ¯æŒ‡æ ‡...\n",
      "  ğŸ’° ç”Ÿæˆä»·æ ¼ç‰¹å¾...\n",
      "  ğŸ“Š ç”Ÿæˆæˆäº¤é‡ç‰¹å¾...\n",
      "    âœ… æŠ€æœ¯æŒ‡æ ‡: 15ä¸ªç‰¹å¾\n",
      "    âœ… ä»·æ ¼ç‰¹å¾: 12ä¸ªç‰¹å¾\n",
      "    âœ… æˆäº¤é‡ç‰¹å¾: 9ä¸ªç‰¹å¾\n",
      "     æ€»ç‰¹å¾æ•°é‡: 36\n",
      "âœ… FeatureEngineeræµ‹è¯•é€šè¿‡\n",
      "\n",
      "ğŸ” æµ‹è¯•5: DataManageræ•°æ®ç®¡ç†å™¨æµ‹è¯•\n",
      "==================================================\n",
      "ğŸ¯ æµ‹è¯•æ•°æ®ç®¡ç†å™¨åŠŸèƒ½:\n",
      "  ğŸš€ è¿è¡Œå®Œæ•´æ•°æ®æµæ°´çº¿...\n",
      "    ğŸš€ æ‰§è¡Œå®Œæ•´æ•°æ®æµæ°´çº¿...\n",
      "      ğŸ“¥ æ•°æ®è·å–...\n",
      "      ğŸ§¹ æ•°æ®é¢„å¤„ç†...\n",
      "      ğŸ”¬ ç‰¹å¾å·¥ç¨‹...\n",
      "  ğŸ”¬ ç”ŸæˆæŠ€æœ¯æŒ‡æ ‡...\n",
      "  ğŸ’° ç”Ÿæˆä»·æ ¼ç‰¹å¾...\n",
      "  ğŸ“Š ç”Ÿæˆæˆäº¤é‡ç‰¹å¾...\n",
      "    âœ… æŠ€æœ¯æŒ‡æ ‡: 10ä¸ªç‰¹å¾\n",
      "    âœ… ä»·æ ¼ç‰¹å¾: 8ä¸ªç‰¹å¾\n",
      "    âœ… æˆäº¤é‡ç‰¹å¾: 6ä¸ªç‰¹å¾\n",
      "     âœ… æµæ°´çº¿æ‰§è¡ŒæˆåŠŸ\n",
      "     ğŸ“Š å¤„ç†è‚¡ç¥¨æ•°: 2\n",
      "     â±ï¸ å¤„ç†æ—¶é—´: 0.01ç§’\n",
      "     ğŸ”¬ ç‰¹å¾æ•°é‡: 24\n",
      "  ğŸ’¾ æµ‹è¯•ç¼“å­˜åŠŸèƒ½...\n",
      "     âœ… ç¼“å­˜åŠŸèƒ½æ­£å¸¸\n",
      "  ğŸ” æµ‹è¯•æ•°æ®è´¨é‡éªŒè¯...\n",
      "     æ•°æ®è´¨é‡éªŒè¯: âŒ (æ•°æ®é‡ä¸è¶³: 3è¡Œ)\n",
      "âœ… DataManageræµ‹è¯•é€šè¿‡\n",
      "\n",
      "ğŸ” æµ‹è¯•6: å®Œæ•´æµæ°´çº¿é›†æˆæµ‹è¯•\n",
      "==================================================\n",
      "ğŸš€ è¿è¡Œç«¯åˆ°ç«¯æ•°æ®æµæ°´çº¿æµ‹è¯•...\n",
      "  ğŸ“¥ æ­¥éª¤1: æ•°æ®è·å–...\n",
      "     âœ… åŸå§‹æ•°æ®è·å–æˆåŠŸ: (233, 10)\n",
      "  ğŸ§¹ æ­¥éª¤2: æ•°æ®é¢„å¤„ç†...\n",
      "     âœ… æ•°æ®æ¸…æ´—å®Œæˆ: (233, 10)\n",
      "  ğŸ”¬ æ­¥éª¤3: ç‰¹å¾å·¥ç¨‹...\n",
      "  ğŸ”¬ ç”ŸæˆæŠ€æœ¯æŒ‡æ ‡...\n",
      "  ğŸ’° ç”Ÿæˆä»·æ ¼ç‰¹å¾...\n",
      "  ğŸ“Š ç”Ÿæˆæˆäº¤é‡ç‰¹å¾...\n",
      "    âœ… æŠ€æœ¯æŒ‡æ ‡: 10ä¸ªç‰¹å¾\n",
      "    âœ… ä»·æ ¼ç‰¹å¾: 8ä¸ªç‰¹å¾\n",
      "    âœ… æˆäº¤é‡ç‰¹å¾: 6ä¸ªç‰¹å¾\n",
      "     âœ… ç‰¹å¾ç”Ÿæˆå®Œæˆ: (233, 24)\n",
      "  âœ… æ­¥éª¤4: æ•°æ®éªŒè¯...\n",
      "     ğŸ“ˆ ç‰¹å¾ç¼ºå¤±ç‡: 5.08%\n",
      "âœ… å®Œæ•´æµæ°´çº¿æµ‹è¯•é€šè¿‡\n",
      "\n",
      "ğŸ¯ Dataæ¨¡å—æµ‹è¯•æ€»ç»“æŠ¥å‘Š\n",
      "============================================================\n",
      "ğŸ“Š æµ‹è¯•ç»Ÿè®¡:\n",
      "  æ€»æµ‹è¯•é¡¹ç›®: 6\n",
      "  é€šè¿‡é¡¹ç›®: 6\n",
      "  å¤±è´¥é¡¹ç›®: 0\n",
      "  é€šè¿‡ç‡: 100.0%\n",
      "\n",
      "ğŸ“‹ è¯¦ç»†æµ‹è¯•ç»“æœ:\n",
      "  ç»„ä»¶å®šä¹‰æµ‹è¯•: âœ… é€šè¿‡\n",
      "  DataLoaderæ•°æ®è·å–: âœ… é€šè¿‡\n",
      "  DataProcessoræ•°æ®é¢„å¤„ç†: âœ… é€šè¿‡\n",
      "  FeatureEngineerç‰¹å¾å·¥ç¨‹: âœ… é€šè¿‡\n",
      "  DataManageræ•°æ®ç®¡ç†å™¨: âœ… é€šè¿‡\n",
      "  å®Œæ•´æµæ°´çº¿é›†æˆ: âœ… é€šè¿‡\n",
      "\n",
      "ğŸ¯ æ€»ä½“è¯„ä¼°:\n",
      "çŠ¶æ€: ğŸ‰ ä¼˜ç§€\n",
      "å»ºè®®: Dataæ¨¡å—è¿è¡Œå®Œç¾ï¼Œå¯ä»¥æŠ•å…¥ä½¿ç”¨ï¼\n",
      "\n",
      "ğŸ“‹ åç»­å¼€å‘å»ºè®®:\n",
      "==============================\n",
      "âœ… Dataæ¨¡å—Mockæµ‹è¯•é€šè¿‡ï¼Œæ¥ä¸‹æ¥å¯ä»¥:\n",
      "  1. ğŸ”„ å°†.ipynbæ–‡ä»¶è½¬æ¢ä¸º.pyæ–‡ä»¶ï¼ˆå¯é€‰ï¼‰\n",
      "  2. ğŸ§  å¼€å‘strategyæ¨¡å— - ç­–ç•¥å®ç°\n",
      "  3. âš¡ å¼€å‘backtestæ¨¡å— - å›æµ‹å¼•æ“\n",
      "  4. ğŸ“ˆ å¼€å‘visualizationæ¨¡å— - å¯è§†åŒ–\n",
      "============================================================\n",
      "ğŸŠ Dataæ¨¡å—æµ‹è¯•å®Œæˆï¼\n",
      "â° æµ‹è¯•ç»“æŸæ—¶é—´: 2025-08-25 07:49:15\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Dataæ¨¡å—å®Œæ•´æµ‹è¯•å’ŒéªŒè¯ - çº¯Notebookç‰ˆæœ¬\n",
    "# ==============================================\n",
    "# æ­¤ç‰ˆæœ¬å®Œå…¨ç‹¬ç«‹è¿è¡Œï¼Œä¸ä¾èµ–å¤–éƒ¨æ–‡ä»¶å¯¼å…¥\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import traceback\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Dict, List, Optional, Any, Tuple\n",
    "from time import time\n",
    "\n",
    "# å¯¼å…¥æ•°æ®å¤„ç†åŒ…\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# ç¦ç”¨è­¦å‘Š\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"ğŸš€ é‡åŒ–äº¤æ˜“æ¡†æ¶Dataæ¨¡å—æµ‹è¯• - çº¯Notebookç‰ˆæœ¬\")\n",
    "print(\"=\" * 65)\n",
    "print(f\"ğŸ“ å½“å‰å·¥ä½œç›®å½•: {os.getcwd()}\")\n",
    "print(f\"ğŸ Pythonç‰ˆæœ¬: {sys.version.split()[0]}\")\n",
    "print(f\"â° æµ‹è¯•å¼€å§‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "# è®°å½•æµ‹è¯•ç»“æœ\n",
    "test_results = {}\n",
    "\n",
    "# ==========================================\n",
    "# å®Œæ•´çš„Mockç»„ä»¶å®šä¹‰ï¼ˆå†…ç½®åœ¨æµ‹è¯•ä¸­ï¼‰\n",
    "# ==========================================\n",
    "\n",
    "class MockConfig:\n",
    "    \"\"\"æ¨¡æ‹Ÿé…ç½®ç±»\"\"\"\n",
    "    def __init__(self):\n",
    "        self.ENABLE_CACHE = True\n",
    "        self.CACHE_EXPIRE_HOURS = 24\n",
    "        self.DATA_SOURCE = 'uqer'\n",
    "        self.API_TOKEN = None\n",
    "\n",
    "class MockDataLoader:\n",
    "    \"\"\"å®Œæ•´åŠŸèƒ½çš„æ¨¡æ‹ŸDataLoader\"\"\"\n",
    "    \n",
    "    def __init__(self, config=None):\n",
    "        self.config = config or MockConfig()\n",
    "        self.name = \"MockDataLoader\"\n",
    "        self.client = None\n",
    "        \n",
    "    def get_stock_list(self, index_code='000300'):\n",
    "        \"\"\"è·å–è‚¡ç¥¨åˆ—è¡¨\"\"\"\n",
    "        mock_stocks = [\n",
    "            '000001.SZ', '000002.SZ', '000858.SZ', '000895.SZ', '000938.SZ',\n",
    "            '600000.SH', '600036.SH', '600519.SH', '600887.SH', '601318.SH'\n",
    "        ]\n",
    "        return mock_stocks\n",
    "    \n",
    "    def load_price_data(self, start_date=None, end_date=None, symbols=None):\n",
    "        \"\"\"è·å–ä»·æ ¼æ•°æ®\"\"\"\n",
    "        if symbols is None:\n",
    "            symbols = self.get_stock_list()[:3]\n",
    "        return self._create_test_price_data(symbols, start_date, end_date)\n",
    "    \n",
    "    def load_financial_data(self, symbols=None, start_date=None, end_date=None):\n",
    "        \"\"\"è·å–è´¢åŠ¡æ•°æ®\"\"\"\n",
    "        if symbols is None:\n",
    "            symbols = ['000001.SZ']\n",
    "        \n",
    "        dates = pd.date_range('2024-01-01', '2024-08-20', freq='Q')\n",
    "        data = {\n",
    "            'revenue': np.random.uniform(1e9, 1e10, len(dates)),\n",
    "            'profit': np.random.uniform(1e8, 1e9, len(dates)),\n",
    "            'market_cap': np.random.uniform(1e10, 1e11, len(dates))\n",
    "        }\n",
    "        return pd.DataFrame(data, index=dates)\n",
    "    \n",
    "    def _create_test_price_data(self, symbols, start_date, end_date):\n",
    "        \"\"\"åˆ›å»ºæµ‹è¯•ä»·æ ¼æ•°æ®\"\"\"\n",
    "        dates = pd.date_range(\n",
    "            start_date or '2024-01-01', \n",
    "            end_date or '2024-08-20', \n",
    "            freq='D'\n",
    "        )\n",
    "        \n",
    "        columns = pd.MultiIndex.from_product(\n",
    "            [symbols, ['open', 'high', 'low', 'close', 'volume']],\n",
    "            names=['symbol', 'field']\n",
    "        )\n",
    "        \n",
    "        np.random.seed(42)\n",
    "        data = []\n",
    "        \n",
    "        for symbol in symbols:\n",
    "            base_price = np.random.uniform(10, 100)\n",
    "            prices = []\n",
    "            \n",
    "            for i, date in enumerate(dates):\n",
    "                if i == 0:\n",
    "                    close = base_price\n",
    "                else:\n",
    "                    close = prices[-1] * (1 + np.random.normal(0, 0.02))\n",
    "                \n",
    "                high = close * (1 + np.random.uniform(0, 0.05))\n",
    "                low = close * (1 - np.random.uniform(0, 0.05))\n",
    "                open_price = close * (1 + np.random.uniform(-0.02, 0.02))\n",
    "                volume = np.random.uniform(1e6, 1e8)\n",
    "                \n",
    "                prices.append(close)\n",
    "                data.extend([open_price, high, low, close, volume])\n",
    "        \n",
    "        data_array = np.array(data).reshape(len(dates), -1)\n",
    "        df = pd.DataFrame(data_array, index=dates, columns=columns)\n",
    "        return df\n",
    "\n",
    "class MockDataProcessor:\n",
    "    \"\"\"å®Œæ•´åŠŸèƒ½çš„æ¨¡æ‹ŸDataProcessor\"\"\"\n",
    "    \n",
    "    def __init__(self, config=None):\n",
    "        self.config = config or MockConfig()\n",
    "        self.name = \"MockDataProcessor\"\n",
    "    \n",
    "    def clean_price_data(self, data):\n",
    "        \"\"\"æ¸…æ´—ä»·æ ¼æ•°æ®\"\"\"\n",
    "        if data is None or data.empty:\n",
    "            return None\n",
    "        \n",
    "        cleaned = data.dropna()\n",
    "        \n",
    "        # ç®€å•å¼‚å¸¸å€¼å¤„ç†\n",
    "        for col in cleaned.columns:\n",
    "            if cleaned[col].dtype in ['float64', 'int64']:\n",
    "                q1 = cleaned[col].quantile(0.01)\n",
    "                q99 = cleaned[col].quantile(0.99)\n",
    "                cleaned[col] = cleaned[col].clip(q1, q99)\n",
    "        \n",
    "        return cleaned\n",
    "    \n",
    "    def filter_stock_pool(self, data, min_market_cap=1e9, min_volume=1e6):\n",
    "        \"\"\"ç­›é€‰è‚¡ç¥¨æ± \"\"\"\n",
    "        if data is None or data.empty:\n",
    "            return None\n",
    "        return data  # ç®€åŒ–ç‰ˆï¼Œè¿”å›æ‰€æœ‰è‚¡ç¥¨\n",
    "    \n",
    "    def normalize_data(self, data):\n",
    "        \"\"\"æ•°æ®æ ‡å‡†åŒ–\"\"\"\n",
    "        if data is None or data.empty:\n",
    "            return None\n",
    "        \n",
    "        numeric_columns = data.select_dtypes(include=[np.number]).columns\n",
    "        normalized = data.copy()\n",
    "        \n",
    "        for col in numeric_columns:\n",
    "            mean_val = data[col].mean()\n",
    "            std_val = data[col].std()\n",
    "            if std_val != 0:\n",
    "                normalized[col] = (data[col] - mean_val) / std_val\n",
    "        \n",
    "        return normalized\n",
    "\n",
    "class MockFeatureEngineer:\n",
    "    \"\"\"å®Œæ•´åŠŸèƒ½çš„æ¨¡æ‹ŸFeatureEngineer\"\"\"\n",
    "    \n",
    "    def __init__(self, data, config=None):\n",
    "        self.data = data\n",
    "        self.config = config or MockConfig()\n",
    "        self.name = \"MockFeatureEngineer\"\n",
    "    \n",
    "    def generate_technical_indicators(self):\n",
    "        \"\"\"ç”ŸæˆæŠ€æœ¯æŒ‡æ ‡\"\"\"\n",
    "        if self.data is None or self.data.empty:\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        features = pd.DataFrame(index=self.data.index)\n",
    "        \n",
    "        for symbol in self.data.columns.get_level_values(0).unique():\n",
    "            try:\n",
    "                if (symbol, 'close') in self.data.columns:\n",
    "                    close_prices = self.data[(symbol, 'close')].dropna()\n",
    "                    \n",
    "                    if len(close_prices) > 20:\n",
    "                        # ç§»åŠ¨å¹³å‡\n",
    "                        features[f'{symbol}_MA5'] = close_prices.rolling(5).mean()\n",
    "                        features[f'{symbol}_MA20'] = close_prices.rolling(20).mean()\n",
    "                        \n",
    "                        # RSI\n",
    "                        delta = close_prices.diff()\n",
    "                        gain = delta.where(delta > 0, 0).rolling(14).mean()\n",
    "                        loss = -delta.where(delta < 0, 0).rolling(14).mean()\n",
    "                        rs = gain / loss\n",
    "                        features[f'{symbol}_RSI'] = 100 - (100 / (1 + rs))\n",
    "                        \n",
    "                        # å¸ƒæ—å¸¦\n",
    "                        ma20 = close_prices.rolling(20).mean()\n",
    "                        std20 = close_prices.rolling(20).std()\n",
    "                        features[f'{symbol}_BOLL_UPPER'] = ma20 + 2 * std20\n",
    "                        features[f'{symbol}_BOLL_LOWER'] = ma20 - 2 * std20\n",
    "                        \n",
    "            except Exception as e:\n",
    "                print(f\"      âš ï¸ {symbol}æŠ€æœ¯æŒ‡æ ‡è®¡ç®—å¤±è´¥: {e}\")\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def generate_price_features(self):\n",
    "        \"\"\"ç”Ÿæˆä»·æ ¼ç‰¹å¾\"\"\"\n",
    "        if self.data is None or self.data.empty:\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        features = pd.DataFrame(index=self.data.index)\n",
    "        \n",
    "        for symbol in self.data.columns.get_level_values(0).unique():\n",
    "            try:\n",
    "                if (symbol, 'close') in self.data.columns:\n",
    "                    close = self.data[(symbol, 'close')]\n",
    "                    \n",
    "                    features[f'{symbol}_return'] = close.pct_change()\n",
    "                    features[f'{symbol}_return_5d'] = close.pct_change(5)\n",
    "                    features[f'{symbol}_volatility_20d'] = close.pct_change().rolling(20).std()\n",
    "                    \n",
    "                    if (symbol, 'high') in self.data.columns and (symbol, 'low') in self.data.columns:\n",
    "                        high = self.data[(symbol, 'high')]\n",
    "                        low = self.data[(symbol, 'low')]\n",
    "                        features[f'{symbol}_price_position'] = (close - low) / (high - low)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"      âš ï¸ {symbol}ä»·æ ¼ç‰¹å¾è®¡ç®—å¤±è´¥: {e}\")\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def generate_volume_features(self):\n",
    "        \"\"\"ç”Ÿæˆæˆäº¤é‡ç‰¹å¾\"\"\"\n",
    "        if self.data is None or self.data.empty:\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        features = pd.DataFrame(index=self.data.index)\n",
    "        \n",
    "        for symbol in self.data.columns.get_level_values(0).unique():\n",
    "            try:\n",
    "                if (symbol, 'volume') in self.data.columns:\n",
    "                    volume = self.data[(symbol, 'volume')]\n",
    "                    \n",
    "                    features[f'{symbol}_volume_ma5'] = volume.rolling(5).mean()\n",
    "                    features[f'{symbol}_volume_ma20'] = volume.rolling(20).mean()\n",
    "                    features[f'{symbol}_volume_ratio'] = volume / volume.rolling(20).mean()\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"      âš ï¸ {symbol}æˆäº¤é‡ç‰¹å¾è®¡ç®—å¤±è´¥: {e}\")\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def generate_all_features(self):\n",
    "        \"\"\"ç”Ÿæˆæ‰€æœ‰ç‰¹å¾\"\"\"\n",
    "        if self.data is None or self.data.empty:\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        print(\"  ğŸ”¬ ç”ŸæˆæŠ€æœ¯æŒ‡æ ‡...\")\n",
    "        tech_features = self.generate_technical_indicators()\n",
    "        \n",
    "        print(\"  ğŸ’° ç”Ÿæˆä»·æ ¼ç‰¹å¾...\")\n",
    "        price_features = self.generate_price_features()\n",
    "        \n",
    "        print(\"  ğŸ“Š ç”Ÿæˆæˆäº¤é‡ç‰¹å¾...\")\n",
    "        volume_features = self.generate_volume_features()\n",
    "        \n",
    "        # åˆå¹¶æ‰€æœ‰ç‰¹å¾\n",
    "        all_features = pd.DataFrame(index=self.data.index)\n",
    "        \n",
    "        for features, name in [(tech_features, \"æŠ€æœ¯æŒ‡æ ‡\"), \n",
    "                             (price_features, \"ä»·æ ¼ç‰¹å¾\"), \n",
    "                             (volume_features, \"æˆäº¤é‡ç‰¹å¾\")]:\n",
    "            if features is not None and not features.empty:\n",
    "                all_features = pd.concat([all_features, features], axis=1)\n",
    "                print(f\"    âœ… {name}: {features.shape[1]}ä¸ªç‰¹å¾\")\n",
    "        \n",
    "        return all_features\n",
    "\n",
    "class MockDataManager:\n",
    "    \"\"\"å®Œæ•´åŠŸèƒ½çš„æ¨¡æ‹ŸDataManager\"\"\"\n",
    "    \n",
    "    def __init__(self, config=None):\n",
    "        self.config = config or MockConfig()\n",
    "        self.name = \"MockDataManager\"\n",
    "        self.cache = {}\n",
    "    \n",
    "    def run_complete_pipeline(self, start_date=None, end_date=None, symbols=None):\n",
    "        \"\"\"è¿è¡Œå®Œæ•´æ•°æ®æµæ°´çº¿\"\"\"\n",
    "        print(\"    ğŸš€ æ‰§è¡Œå®Œæ•´æ•°æ®æµæ°´çº¿...\")\n",
    "        start_time = time()\n",
    "        \n",
    "        try:\n",
    "            # æ­¥éª¤1: æ•°æ®è·å–\n",
    "            print(\"      ğŸ“¥ æ•°æ®è·å–...\")\n",
    "            loader = MockDataLoader()\n",
    "            raw_data = loader.load_price_data(start_date, end_date, symbols)\n",
    "            \n",
    "            # æ­¥éª¤2: æ•°æ®é¢„å¤„ç†\n",
    "            print(\"      ğŸ§¹ æ•°æ®é¢„å¤„ç†...\")\n",
    "            processor = MockDataProcessor()\n",
    "            clean_data = processor.clean_price_data(raw_data)\n",
    "            \n",
    "            # æ­¥éª¤3: ç‰¹å¾å·¥ç¨‹\n",
    "            print(\"      ğŸ”¬ ç‰¹å¾å·¥ç¨‹...\")\n",
    "            engineer = MockFeatureEngineer(clean_data)\n",
    "            features = engineer.generate_all_features()\n",
    "            \n",
    "            end_time = time()\n",
    "            processing_time = end_time - start_time\n",
    "            \n",
    "            result = {\n",
    "                'features': features,\n",
    "                'raw_data': raw_data,\n",
    "                'clean_data': clean_data,\n",
    "                'metadata': {\n",
    "                    'stock_count': len(symbols) if symbols else 3,\n",
    "                    'processing_time': round(processing_time, 2),\n",
    "                    'feature_count': features.shape[1] if features is not None else 0,\n",
    "                    'date_range': f\"{start_date} ~ {end_date}\",\n",
    "                    'success': True\n",
    "                }\n",
    "            }\n",
    "            \n",
    "            return result\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"      âŒ æµæ°´çº¿æ‰§è¡Œå¤±è´¥: {e}\")\n",
    "            return {\n",
    "                'features': None,\n",
    "                'metadata': {\n",
    "                    'success': False,\n",
    "                    'error': str(e),\n",
    "                    'processing_time': round(time() - start_time, 2)\n",
    "                }\n",
    "            }\n",
    "    \n",
    "    def get_cached_data(self, key):\n",
    "        return self.cache.get(key)\n",
    "    \n",
    "    def set_cached_data(self, key, data):\n",
    "        self.cache[key] = data\n",
    "        return True\n",
    "    \n",
    "    def validate_data_quality(self, data):\n",
    "        \"\"\"éªŒè¯æ•°æ®è´¨é‡\"\"\"\n",
    "        if data is None:\n",
    "            return False, \"æ•°æ®ä¸ºç©º\"\n",
    "        \n",
    "        if data.empty:\n",
    "            return False, \"æ•°æ®æ¡†ä¸ºç©º\"\n",
    "        \n",
    "        missing_ratio = data.isnull().sum().sum() / (data.shape[0] * data.shape[1])\n",
    "        if missing_ratio > 0.5:\n",
    "            return False, f\"ç¼ºå¤±å€¼è¿‡å¤š: {missing_ratio:.1%}\"\n",
    "        \n",
    "        if len(data) < 20:\n",
    "            return False, f\"æ•°æ®é‡ä¸è¶³: {len(data)}è¡Œ\"\n",
    "        \n",
    "        return True, \"æ•°æ®è´¨é‡è‰¯å¥½\"\n",
    "\n",
    "# å·¥å‚å‡½æ•°\n",
    "def create_data_loader():\n",
    "    return MockDataLoader()\n",
    "\n",
    "def create_data_processor():\n",
    "    return MockDataProcessor()\n",
    "\n",
    "def create_feature_engineer(data):\n",
    "    return MockFeatureEngineer(data)\n",
    "\n",
    "def create_data_manager():\n",
    "    return MockDataManager()\n",
    "\n",
    "print(\"âœ… Mockç»„ä»¶å®šä¹‰å®Œæˆ\")\n",
    "\n",
    "# ==========================================\n",
    "# å¼€å§‹æ‰§è¡Œæµ‹è¯•\n",
    "# ==========================================\n",
    "\n",
    "# æµ‹è¯•1: æ¨¡å—ç»„ä»¶æµ‹è¯•\n",
    "print(f\"\\nğŸ” æµ‹è¯•1: æ¨¡å—ç»„ä»¶åŠŸèƒ½æµ‹è¯•\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "try:\n",
    "    # æ‰€æœ‰ç»„ä»¶éƒ½ä½¿ç”¨å†…ç½®Mockï¼Œæ— éœ€å¯¼å…¥\n",
    "    print(\"âœ… æ‰€æœ‰ç»„ä»¶å·²å†…ç½®å®šä¹‰\")\n",
    "    test_results['component_test'] = True\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ ç»„ä»¶æµ‹è¯•å¤±è´¥: {e}\")\n",
    "    test_results['component_test'] = False\n",
    "\n",
    "# æµ‹è¯•2: DataLoaderæ•°æ®è·å–æµ‹è¯•\n",
    "print(f\"\\nğŸ” æµ‹è¯•2: DataLoaderæ•°æ®è·å–æµ‹è¯•\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "try:\n",
    "    loader = create_data_loader()\n",
    "    \n",
    "    print(\"ğŸ“¥ æµ‹è¯•æ•°æ®è·å–åŠŸèƒ½:\")\n",
    "    \n",
    "    # æµ‹è¯•è‚¡ç¥¨åˆ—è¡¨è·å–\n",
    "    print(\"  ğŸ“‹ è·å–è‚¡ç¥¨åˆ—è¡¨...\")\n",
    "    stock_list = loader.get_stock_list()\n",
    "    print(f\"     è‚¡ç¥¨æ•°é‡: {len(stock_list) if stock_list else 0}\")\n",
    "    \n",
    "    # æµ‹è¯•ä»·æ ¼æ•°æ®è·å–\n",
    "    print(\"  ğŸ’° è·å–ä»·æ ¼æ•°æ®...\")\n",
    "    start_date = '2024-01-01'\n",
    "    end_date = '2024-08-20'\n",
    "    \n",
    "    price_data = loader.load_price_data(\n",
    "        start_date=start_date,\n",
    "        end_date=end_date,\n",
    "        symbols=['000001.SZ', '000002.SZ']\n",
    "    )\n",
    "    \n",
    "    if price_data is not None:\n",
    "        print(f\"     æ•°æ®å½¢çŠ¶: {price_data.shape}\")\n",
    "        print(f\"     æ—¥æœŸèŒƒå›´: {price_data.index.min()} ~ {price_data.index.max()}\")\n",
    "    \n",
    "    # æµ‹è¯•è´¢åŠ¡æ•°æ®\n",
    "    print(\"  ğŸ“Š è·å–è´¢åŠ¡æ•°æ®...\")\n",
    "    financial_data = loader.load_financial_data(symbols=['000001.SZ'])\n",
    "    \n",
    "    if financial_data is not None:\n",
    "        print(f\"     è´¢åŠ¡æ•°æ®å½¢çŠ¶: {financial_data.shape}\")\n",
    "    \n",
    "    test_results['data_loader'] = True\n",
    "    print(\"âœ… DataLoaderæµ‹è¯•é€šè¿‡\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ DataLoaderæµ‹è¯•å¤±è´¥: {e}\")\n",
    "    test_results['data_loader'] = False\n",
    "\n",
    "# æµ‹è¯•3: DataProcessoræ•°æ®é¢„å¤„ç†æµ‹è¯•\n",
    "print(f\"\\nğŸ” æµ‹è¯•3: DataProcessoræ•°æ®é¢„å¤„ç†æµ‹è¯•\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "try:\n",
    "    processor = create_data_processor()\n",
    "    \n",
    "    print(\"ğŸ§¹ æµ‹è¯•æ•°æ®é¢„å¤„ç†åŠŸèƒ½:\")\n",
    "    \n",
    "    # åˆ›å»ºæµ‹è¯•æ•°æ®\n",
    "    loader = create_data_loader()\n",
    "    test_data = loader.load_price_data()\n",
    "    print(f\"  ğŸ“¥ åŸå§‹æµ‹è¯•æ•°æ®: {test_data.shape}\")\n",
    "    \n",
    "    # æµ‹è¯•æ•°æ®æ¸…æ´—\n",
    "    print(\"  ğŸ”§ æ•°æ®æ¸…æ´—...\")\n",
    "    clean_data = processor.clean_price_data(test_data)\n",
    "    if clean_data is not None:\n",
    "        print(f\"     æ¸…æ´—åæ•°æ®: {clean_data.shape}\")\n",
    "    \n",
    "    # æµ‹è¯•è‚¡ç¥¨æ± ç­›é€‰\n",
    "    print(\"  ğŸ¯ è‚¡ç¥¨æ± ç­›é€‰...\")\n",
    "    filtered_data = processor.filter_stock_pool(clean_data)\n",
    "    if filtered_data is not None:\n",
    "        print(f\"     ç­›é€‰åæ•°æ®: {filtered_data.shape}\")\n",
    "    \n",
    "    # æµ‹è¯•æ•°æ®æ ‡å‡†åŒ–\n",
    "    print(\"  ğŸ“ æ•°æ®æ ‡å‡†åŒ–...\")\n",
    "    normalized_data = processor.normalize_data(clean_data)\n",
    "    if normalized_data is not None:\n",
    "        print(f\"     æ ‡å‡†åŒ–å®Œæˆ: {normalized_data.shape}\")\n",
    "    \n",
    "    test_results['data_processor'] = True\n",
    "    print(\"âœ… DataProcessoræµ‹è¯•é€šè¿‡\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ DataProcessoræµ‹è¯•å¤±è´¥: {e}\")\n",
    "    test_results['data_processor'] = False\n",
    "\n",
    "# æµ‹è¯•4: FeatureEngineerç‰¹å¾å·¥ç¨‹æµ‹è¯•\n",
    "print(f\"\\nğŸ” æµ‹è¯•4: FeatureEngineerç‰¹å¾å·¥ç¨‹æµ‹è¯•\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "try:\n",
    "    # åˆ›å»ºæµ‹è¯•æ•°æ®\n",
    "    loader = create_data_loader()\n",
    "    test_data = loader.load_price_data()\n",
    "    \n",
    "    # åˆ›å»ºç‰¹å¾å·¥ç¨‹å™¨\n",
    "    engineer = create_feature_engineer(test_data)\n",
    "    \n",
    "    print(\"ğŸ”¬ æµ‹è¯•ç‰¹å¾å·¥ç¨‹åŠŸèƒ½:\")\n",
    "    \n",
    "    # æµ‹è¯•æŠ€æœ¯æŒ‡æ ‡ç”Ÿæˆ\n",
    "    print(\"  ğŸ“ˆ ç”ŸæˆæŠ€æœ¯æŒ‡æ ‡...\")\n",
    "    tech_features = engineer.generate_technical_indicators()\n",
    "    if tech_features is not None:\n",
    "        print(f\"     æŠ€æœ¯æŒ‡æ ‡æ•°é‡: {tech_features.shape[1]}\")\n",
    "    \n",
    "    # æµ‹è¯•ä»·æ ¼ç‰¹å¾\n",
    "    print(\"  ğŸ’° ç”Ÿæˆä»·æ ¼ç‰¹å¾...\")\n",
    "    price_features = engineer.generate_price_features()\n",
    "    if price_features is not None:\n",
    "        print(f\"     ä»·æ ¼ç‰¹å¾æ•°é‡: {price_features.shape[1]}\")\n",
    "    \n",
    "    # æµ‹è¯•æˆäº¤é‡ç‰¹å¾\n",
    "    print(\"  ğŸ“Š ç”Ÿæˆæˆäº¤é‡ç‰¹å¾...\")\n",
    "    volume_features = engineer.generate_volume_features()\n",
    "    if volume_features is not None:\n",
    "        print(f\"     æˆäº¤é‡ç‰¹å¾æ•°é‡: {volume_features.shape[1]}\")\n",
    "    \n",
    "    # æµ‹è¯•æ‰€æœ‰ç‰¹å¾ç”Ÿæˆ\n",
    "    print(\"  ğŸ¯ ç”Ÿæˆæ‰€æœ‰ç‰¹å¾...\")\n",
    "    all_features = engineer.generate_all_features()\n",
    "    if all_features is not None:\n",
    "        print(f\"     æ€»ç‰¹å¾æ•°é‡: {all_features.shape[1]}\")\n",
    "    \n",
    "    test_results['feature_engineer'] = True\n",
    "    print(\"âœ… FeatureEngineeræµ‹è¯•é€šè¿‡\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ FeatureEngineeræµ‹è¯•å¤±è´¥: {e}\")\n",
    "    test_results['feature_engineer'] = False\n",
    "\n",
    "# æµ‹è¯•5: DataManageræ•°æ®ç®¡ç†å™¨æµ‹è¯•\n",
    "print(f\"\\nğŸ” æµ‹è¯•5: DataManageræ•°æ®ç®¡ç†å™¨æµ‹è¯•\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "try:\n",
    "    manager = create_data_manager()\n",
    "    \n",
    "    print(\"ğŸ¯ æµ‹è¯•æ•°æ®ç®¡ç†å™¨åŠŸèƒ½:\")\n",
    "    \n",
    "    # æµ‹è¯•å®Œæ•´æµæ°´çº¿\n",
    "    print(\"  ğŸš€ è¿è¡Œå®Œæ•´æ•°æ®æµæ°´çº¿...\")\n",
    "    pipeline_result = manager.run_complete_pipeline(\n",
    "        start_date='2024-01-01',\n",
    "        end_date='2024-08-20',\n",
    "        symbols=['000001.SZ', '000002.SZ']\n",
    "    )\n",
    "    \n",
    "    if pipeline_result and pipeline_result.get('metadata', {}).get('success', False):\n",
    "        metadata = pipeline_result['metadata']\n",
    "        print(f\"     âœ… æµæ°´çº¿æ‰§è¡ŒæˆåŠŸ\")\n",
    "        print(f\"     ğŸ“Š å¤„ç†è‚¡ç¥¨æ•°: {metadata.get('stock_count', 0)}\")\n",
    "        print(f\"     â±ï¸ å¤„ç†æ—¶é—´: {metadata.get('processing_time', 0)}ç§’\")\n",
    "        print(f\"     ğŸ”¬ ç‰¹å¾æ•°é‡: {metadata.get('feature_count', 0)}\")\n",
    "    \n",
    "    # æµ‹è¯•ç¼“å­˜åŠŸèƒ½\n",
    "    print(\"  ğŸ’¾ æµ‹è¯•ç¼“å­˜åŠŸèƒ½...\")\n",
    "    test_cache_data = pd.DataFrame({'test': [1, 2, 3]})\n",
    "    cache_result = manager.set_cached_data('test_key', test_cache_data)\n",
    "    if cache_result:\n",
    "        cached_data = manager.get_cached_data('test_key')\n",
    "        if cached_data is not None:\n",
    "            print(f\"     âœ… ç¼“å­˜åŠŸèƒ½æ­£å¸¸\")\n",
    "    \n",
    "    # æµ‹è¯•æ•°æ®è´¨é‡éªŒè¯\n",
    "    print(\"  ğŸ” æµ‹è¯•æ•°æ®è´¨é‡éªŒè¯...\")\n",
    "    test_data = pd.DataFrame({'a': [1, 2, 3], 'b': [4, 5, 6]})\n",
    "    is_valid, message = manager.validate_data_quality(test_data)\n",
    "    print(f\"     æ•°æ®è´¨é‡éªŒè¯: {'âœ…' if is_valid else 'âŒ'} ({message})\")\n",
    "    \n",
    "    test_results['data_manager'] = True\n",
    "    print(\"âœ… DataManageræµ‹è¯•é€šè¿‡\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ DataManageræµ‹è¯•å¤±è´¥: {e}\")\n",
    "    test_results['data_manager'] = False\n",
    "\n",
    "# æµ‹è¯•6: å®Œæ•´æµæ°´çº¿é›†æˆæµ‹è¯•\n",
    "print(f\"\\nğŸ” æµ‹è¯•6: å®Œæ•´æµæ°´çº¿é›†æˆæµ‹è¯•\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "try:\n",
    "    print(\"ğŸš€ è¿è¡Œç«¯åˆ°ç«¯æ•°æ®æµæ°´çº¿æµ‹è¯•...\")\n",
    "    \n",
    "    # æ­¥éª¤1: æ•°æ®è·å–\n",
    "    print(\"  ğŸ“¥ æ­¥éª¤1: æ•°æ®è·å–...\")\n",
    "    loader = create_data_loader()\n",
    "    raw_data = loader.load_price_data(\n",
    "        start_date='2024-01-01',\n",
    "        end_date='2024-08-20',\n",
    "        symbols=['000001.SZ', '000002.SZ']\n",
    "    )\n",
    "    \n",
    "    if raw_data is not None:\n",
    "        print(f\"     âœ… åŸå§‹æ•°æ®è·å–æˆåŠŸ: {raw_data.shape}\")\n",
    "    \n",
    "    # æ­¥éª¤2: æ•°æ®é¢„å¤„ç†\n",
    "    print(\"  ğŸ§¹ æ­¥éª¤2: æ•°æ®é¢„å¤„ç†...\")\n",
    "    processor = create_data_processor()\n",
    "    clean_data = processor.clean_price_data(raw_data)\n",
    "    \n",
    "    if clean_data is not None:\n",
    "        print(f\"     âœ… æ•°æ®æ¸…æ´—å®Œæˆ: {clean_data.shape}\")\n",
    "    \n",
    "    # æ­¥éª¤3: ç‰¹å¾å·¥ç¨‹\n",
    "    print(\"  ğŸ”¬ æ­¥éª¤3: ç‰¹å¾å·¥ç¨‹...\")\n",
    "    engineer = create_feature_engineer(clean_data)\n",
    "    features = engineer.generate_all_features()\n",
    "    \n",
    "    if features is not None:\n",
    "        print(f\"     âœ… ç‰¹å¾ç”Ÿæˆå®Œæˆ: {features.shape}\")\n",
    "    \n",
    "    # æ­¥éª¤4: æ•°æ®éªŒè¯\n",
    "    print(\"  âœ… æ­¥éª¤4: æ•°æ®éªŒè¯...\")\n",
    "    if features is not None and not features.empty:\n",
    "        missing_ratio = features.isnull().sum().sum() / features.size\n",
    "        print(f\"     ğŸ“ˆ ç‰¹å¾ç¼ºå¤±ç‡: {missing_ratio:.2%}\")\n",
    "    \n",
    "    test_results['pipeline_integration'] = True\n",
    "    print(\"âœ… å®Œæ•´æµæ°´çº¿æµ‹è¯•é€šè¿‡\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ å®Œæ•´æµæ°´çº¿æµ‹è¯•å¤±è´¥: {e}\")\n",
    "    test_results['pipeline_integration'] = False\n",
    "\n",
    "# ==========================================\n",
    "# æœ€ç»ˆæµ‹è¯•æ€»ç»“å’ŒæŠ¥å‘Š\n",
    "# ==========================================\n",
    "print(f\"\\nğŸ¯ Dataæ¨¡å—æµ‹è¯•æ€»ç»“æŠ¥å‘Š\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# è®¡ç®—æµ‹è¯•ç»Ÿè®¡\n",
    "total_tests = len(test_results)\n",
    "passed_tests = sum(1 for result in test_results.values() if result)\n",
    "failed_tests = total_tests - passed_tests\n",
    "pass_rate = (passed_tests / total_tests * 100) if total_tests > 0 else 0\n",
    "\n",
    "print(f\"ğŸ“Š æµ‹è¯•ç»Ÿè®¡:\")\n",
    "print(f\"  æ€»æµ‹è¯•é¡¹ç›®: {total_tests}\")\n",
    "print(f\"  é€šè¿‡é¡¹ç›®: {passed_tests}\")\n",
    "print(f\"  å¤±è´¥é¡¹ç›®: {failed_tests}\")\n",
    "print(f\"  é€šè¿‡ç‡: {pass_rate:.1f}%\")\n",
    "\n",
    "# è¯¦ç»†æµ‹è¯•ç»“æœ\n",
    "print(f\"\\nğŸ“‹ è¯¦ç»†æµ‹è¯•ç»“æœ:\")\n",
    "test_descriptions = {\n",
    "    'component_test': 'ç»„ä»¶å®šä¹‰æµ‹è¯•',\n",
    "    'data_loader': 'DataLoaderæ•°æ®è·å–',\n",
    "    'data_processor': 'DataProcessoræ•°æ®é¢„å¤„ç†',\n",
    "    'feature_engineer': 'FeatureEngineerç‰¹å¾å·¥ç¨‹',\n",
    "    'data_manager': 'DataManageræ•°æ®ç®¡ç†å™¨',\n",
    "    'pipeline_integration': 'å®Œæ•´æµæ°´çº¿é›†æˆ'\n",
    "}\n",
    "\n",
    "for test_key, result in test_results.items():\n",
    "    desc = test_descriptions.get(test_key, test_key)\n",
    "    status = \"âœ… é€šè¿‡\" if result else \"âŒ å¤±è´¥\"\n",
    "    print(f\"  {desc}: {status}\")\n",
    "\n",
    "# æ€»ä½“è¯„ä¼°\n",
    "print(f\"\\nğŸ¯ æ€»ä½“è¯„ä¼°:\")\n",
    "if pass_rate >= 90:\n",
    "    overall_status = \"ğŸ‰ ä¼˜ç§€\"\n",
    "    recommendation = \"Dataæ¨¡å—è¿è¡Œå®Œç¾ï¼Œå¯ä»¥æŠ•å…¥ä½¿ç”¨ï¼\"\n",
    "elif pass_rate >= 75:\n",
    "    overall_status = \"âœ… è‰¯å¥½\"\n",
    "    recommendation = \"Dataæ¨¡å—åŸºæœ¬æ­£å¸¸ï¼Œå»ºè®®ä¿®å¤å¤±è´¥çš„æµ‹è¯•é¡¹ã€‚\"\n",
    "elif pass_rate >= 50:\n",
    "    overall_status = \"âš ï¸ éœ€è¦æ”¹è¿›\"\n",
    "    recommendation = \"Dataæ¨¡å—å­˜åœ¨é—®é¢˜ï¼Œéœ€è¦ä»”ç»†æ£€æŸ¥å’Œä¿®å¤ã€‚\"\n",
    "else:\n",
    "    overall_status = \"âŒ ä¸¥é‡é—®é¢˜\"\n",
    "    recommendation = \"Dataæ¨¡å—å­˜åœ¨é‡å¤§é—®é¢˜ï¼Œéœ€è¦å…¨é¢æ£€æŸ¥ã€‚\"\n",
    "\n",
    "print(f\"çŠ¶æ€: {overall_status}\")\n",
    "print(f\"å»ºè®®: {recommendation}\")\n",
    "\n",
    "# åç»­æ­¥éª¤å»ºè®®\n",
    "print(f\"\\nğŸ“‹ åç»­å¼€å‘å»ºè®®:\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "if pass_rate >= 75:\n",
    "    print(\"âœ… Dataæ¨¡å—Mockæµ‹è¯•é€šè¿‡ï¼Œæ¥ä¸‹æ¥å¯ä»¥:\")\n",
    "    print(\"  1. ğŸ”„ å°†.ipynbæ–‡ä»¶è½¬æ¢ä¸º.pyæ–‡ä»¶ï¼ˆå¯é€‰ï¼‰\")\n",
    "    print(\"  2. ğŸ§  å¼€å‘strategyæ¨¡å— - ç­–ç•¥å®ç°\")\n",
    "    print(\"  3. âš¡ å¼€å‘backtestæ¨¡å— - å›æµ‹å¼•æ“\")\n",
    "    print(\"  4. ğŸ“ˆ å¼€å‘visualizationæ¨¡å— - å¯è§†åŒ–\")\n",
    "else:\n",
    "    print(\"âš ï¸ å»ºè®®å…ˆä¿®å¤å¤±è´¥çš„æµ‹è¯•é¡¹\")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ğŸŠ Dataæ¨¡å—æµ‹è¯•å®Œæˆï¼\")\n",
    "print(f\"â° æµ‹è¯•ç»“æŸæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"=\" * 60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
