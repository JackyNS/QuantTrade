#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ä¼˜çŸ¿æƒé™å’Œæ•°æ®çŠ¶æ€æ£€æŸ¥å·¥å…·
=======================

åŠŸèƒ½ï¼š
1. æ£€æŸ¥ä¼˜çŸ¿APIæƒé™å’Œæ¥å£æ¸…å•
2. åˆ†æå·²ä¸‹è½½çš„æ•°æ®æƒ…å†µ
3. ç”Ÿæˆè¯¦ç»†çš„çŠ¶æ€æŠ¥å‘Š

Author: QuantTrader Team
Date: 2025-08-31
"""

import os
import sys
import json
from pathlib import Path
from datetime import datetime, timedelta
import pandas as pd
import numpy as np

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

class UqerStatusChecker:
    """ä¼˜çŸ¿çŠ¶æ€æ£€æŸ¥å™¨"""
    
    def __init__(self):
        self.token = self.get_token()
        self.client = None
        self.data_dir = Path('./data')
        self.report = {
            'check_time': datetime.now(),
            'token_status': None,
            'permissions': {},
            'available_apis': [],
            'data_status': {},
            'recommendations': []
        }
    
    def get_token(self):
        """è·å–ä¼˜çŸ¿Token"""
        # ä»ç¯å¢ƒå˜é‡è·å–
        token = os.environ.get('UQER_TOKEN')
        if token:
            return token
        
        # ä»é…ç½®æ–‡ä»¶è·å–
        config_files = ['config/uqer_config.json', 'uqer_config.json']
        for config_file in config_files:
            if Path(config_file).exists():
                try:
                    with open(config_file, 'r', encoding='utf-8') as f:
                        config = json.load(f)
                        token = config.get('token')
                        if token:
                            return token
                except:
                    continue
        
        return None
    
    def check_uqer_permissions(self):
        """æ£€æŸ¥ä¼˜çŸ¿æƒé™å’Œæ¥å£"""
        print("ğŸ” æ£€æŸ¥ä¼˜çŸ¿APIæƒé™...")
        
        if not self.token:
            print("âŒ æœªæ‰¾åˆ°ä¼˜çŸ¿Token")
            self.report['token_status'] = 'missing'
            return False
        
        try:
            import uqer
            self.client = uqer.Client(token=self.token)
            print("âœ… ä¼˜çŸ¿å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
            self.report['token_status'] = 'valid'
            
            # æ£€æŸ¥åŸºç¡€æƒé™ - å°è¯•è·å–è‚¡ç¥¨åˆ—è¡¨
            print("ğŸ“Š æ£€æŸ¥åŸºç¡€æƒé™...")
            try:
                # è·å–æœ€è¿‘ä¸€ä¸ªäº¤æ˜“æ—¥çš„è‚¡ç¥¨åˆ—è¡¨
                yesterday = (datetime.now() - timedelta(days=1)).strftime('%Y%m%d')
                stock_data = self.client.getMktEqud(
                    tradeDate=yesterday,
                    field='ticker,secShortName,tradeDate',
                    pandas="1"
                )
                
                if not stock_data.empty:
                    print(f"âœ… è‚¡ç¥¨æ•°æ®æƒé™æ­£å¸¸ï¼Œè·å–åˆ° {len(stock_data)} æ¡è®°å½•")
                    self.report['permissions']['stock_basic'] = {
                        'status': 'available',
                        'sample_count': len(stock_data),
                        'latest_date': yesterday
                    }
                else:
                    print("âš ï¸ è‚¡ç¥¨æ•°æ®ä¸ºç©ºï¼Œå¯èƒ½æ˜¯éäº¤æ˜“æ—¥")
                    self.report['permissions']['stock_basic'] = {
                        'status': 'empty_result',
                        'note': 'possible_non_trading_day'
                    }
                    
            except Exception as e:
                print(f"âŒ è‚¡ç¥¨æ•°æ®æƒé™æ£€æŸ¥å¤±è´¥: {e}")
                self.report['permissions']['stock_basic'] = {
                    'status': 'error',
                    'error': str(e)
                }
            
            return True
            
        except ImportError:
            print("âŒ uqeråŒ…æœªå®‰è£…")
            self.report['token_status'] = 'package_missing'
            return False
        except Exception as e:
            print(f"âŒ ä¼˜çŸ¿è¿æ¥å¤±è´¥: {e}")
            self.report['token_status'] = 'connection_failed'
            self.report['permissions']['error'] = str(e)
            return False
    
    def check_available_apis(self):
        """æ£€æŸ¥å¯ç”¨çš„APIæ¥å£"""
        print("\nğŸ“‹ æ£€æŸ¥å¯ç”¨çš„APIæ¥å£...")
        
        if not self.client:
            print("âŒ ä¼˜çŸ¿å®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
            return
        
        # å®šä¹‰è¦æµ‹è¯•çš„APIåˆ—è¡¨
        api_tests = [
            {
                'name': 'getMktEqud',
                'description': 'è‚¡ç¥¨è¡Œæƒ…æ•°æ®',
                'test_params': {
                    'beginDate': '20241201',
                    'endDate': '20241201',
                    'ticker': '000001.XSHE',
                    'field': 'ticker,closePrice,turnoverVol'
                },
                'category': 'market_data'
            },
            {
                'name': 'getEquIndustry', 
                'description': 'è¡Œä¸šåˆ†ç±»æ•°æ®',
                'test_params': {
                    'ticker': '000001.XSHE',
                    'industryVersionCD': '010303'
                },
                'category': 'reference_data'
            },
            {
                'name': 'getFundamental',
                'description': 'è´¢åŠ¡åŸºç¡€æ•°æ®',
                'test_params': {
                    'ticker': '000001.XSHE',
                    'beginDate': '20241001',
                    'endDate': '20241201'
                },
                'category': 'fundamental_data'
            },
            {
                'name': 'getSecIndustry',
                'description': 'è¯åˆ¸è¡Œä¸šåˆ†ç±»',
                'test_params': {
                    'ticker': '000001.XSHE'
                },
                'category': 'reference_data'
            },
            {
                'name': 'getMktIdxd',
                'description': 'æŒ‡æ•°è¡Œæƒ…æ•°æ®',
                'test_params': {
                    'ticker': '000001.XSHG',
                    'beginDate': '20241201',
                    'endDate': '20241201'
                },
                'category': 'index_data'
            }
        ]
        
        available_apis = []
        permission_summary = {}
        
        for api_info in api_tests:
            api_name = api_info['name']
            category = api_info['category']
            
            print(f"   æµ‹è¯• {api_name} - {api_info['description']}...")
            
            try:
                # è·å–APIæ–¹æ³•
                api_method = getattr(self.client, api_name, None)
                if not api_method:
                    print(f"   âŒ APIæ–¹æ³•ä¸å­˜åœ¨")
                    continue
                
                # å°è¯•è°ƒç”¨API
                result = api_method(**api_info['test_params'], pandas="1")
                
                if result is not None and not result.empty:
                    status = 'available'
                    sample_count = len(result)
                    print(f"   âœ… å¯ç”¨ - {sample_count} æ¡è®°å½•")
                else:
                    status = 'available_but_empty'
                    sample_count = 0
                    print(f"   âš ï¸ å¯ç”¨ä½†æ— æ•°æ®")
                
                api_status = {
                    'name': api_name,
                    'description': api_info['description'],
                    'category': category,
                    'status': status,
                    'sample_count': sample_count
                }
                
                available_apis.append(api_status)
                
                # æŒ‰ç±»åˆ«ç»Ÿè®¡
                if category not in permission_summary:
                    permission_summary[category] = {'available': 0, 'total': 0}
                permission_summary[category]['available'] += 1
                permission_summary[category]['total'] += 1
                
            except Exception as e:
                print(f"   âŒ ä¸å¯ç”¨: {e}")
                
                api_status = {
                    'name': api_name,
                    'description': api_info['description'],
                    'category': category,
                    'status': 'error',
                    'error': str(e)
                }
                
                available_apis.append(api_status)
                
                if category not in permission_summary:
                    permission_summary[category] = {'available': 0, 'total': 0}
                permission_summary[category]['total'] += 1
        
        self.report['available_apis'] = available_apis
        self.report['permissions']['summary'] = permission_summary
        
        # æ˜¾ç¤ºæƒé™æ€»ç»“
        print(f"\nğŸ“Š æƒé™æ€»ç»“:")
        for category, stats in permission_summary.items():
            print(f"   {category}: {stats['available']}/{stats['total']} å¯ç”¨")
    
    def check_downloaded_data(self):
        """æ£€æŸ¥å·²ä¸‹è½½çš„æ•°æ®"""
        print("\nğŸ“‚ æ£€æŸ¥å·²ä¸‹è½½çš„æ•°æ®...")
        
        if not self.data_dir.exists():
            print("âŒ æ•°æ®ç›®å½•ä¸å­˜åœ¨")
            self.report['data_status'] = {
                'directory_exists': False,
                'total_files': 0,
                'total_size': 0
            }
            return
        
        # æ‰«ææ•°æ®æ–‡ä»¶
        csv_files = list(self.data_dir.glob('*.csv'))
        parquet_files = list(self.data_dir.glob('*.parquet'))
        all_data_files = csv_files + parquet_files
        
        if not all_data_files:
            print("âŒ æœªæ‰¾åˆ°æ•°æ®æ–‡ä»¶")
            self.report['data_status'] = {
                'directory_exists': True,
                'total_files': 0,
                'total_size': 0,
                'file_types': {'csv': 0, 'parquet': 0}
            }
            return
        
        print(f"âœ… æ‰¾åˆ° {len(all_data_files)} ä¸ªæ•°æ®æ–‡ä»¶")
        
        # åˆ†ææ–‡ä»¶ä¿¡æ¯
        file_analysis = {
            'total_files': len(all_data_files),
            'csv_files': len(csv_files),
            'parquet_files': len(parquet_files),
            'total_size': 0,
            'files_by_size': [],
            'date_range': {},
            'symbols': set()
        }
        
        print("ğŸ“Š åˆ†ææ–‡ä»¶è¯¦æƒ…...")
        
        # åˆ†ææ¯ä¸ªæ–‡ä»¶
        for file_path in all_data_files[:20]:  # é™åˆ¶åˆ†æå‰20ä¸ªæ–‡ä»¶ï¼Œé¿å…å¤ªæ…¢
            try:
                file_size = file_path.stat().st_size
                file_analysis['total_size'] += file_size
                
                # ä»æ–‡ä»¶åæå–è‚¡ç¥¨ä»£ç 
                symbol = file_path.stem
                file_analysis['symbols'].add(symbol)
                
                # è¯»å–æ–‡ä»¶è·å–æ—¥æœŸèŒƒå›´ï¼ˆé™åˆ¶è¡Œæ•°é¿å…å¤ªæ…¢ï¼‰
                if file_path.suffix == '.csv':
                    try:
                        df = pd.read_csv(file_path, nrows=1000)
                        if 'date' in df.columns:
                            dates = pd.to_datetime(df['date'], errors='coerce')
                            valid_dates = dates.dropna()
                            if not valid_dates.empty:
                                min_date = valid_dates.min()
                                max_date = valid_dates.max()
                                
                                if symbol not in file_analysis['date_range']:
                                    file_analysis['date_range'][symbol] = {
                                        'start': min_date,
                                        'end': max_date,
                                        'days': (max_date - min_date).days + 1
                                    }
                    except Exception as e:
                        pass  # è·³è¿‡è¯»å–å¤±è´¥çš„æ–‡ä»¶
                
                file_analysis['files_by_size'].append({
                    'name': file_path.name,
                    'size': file_size,
                    'size_mb': round(file_size / 1024 / 1024, 2)
                })
                
            except Exception as e:
                print(f"   âš ï¸ åˆ†ææ–‡ä»¶å¤±è´¥ {file_path.name}: {e}")
        
        # æŒ‰å¤§å°æ’åº
        file_analysis['files_by_size'].sort(key=lambda x: x['size'], reverse=True)
        
        # ç»Ÿè®¡ä¿¡æ¯
        total_size_mb = file_analysis['total_size'] / 1024 / 1024
        total_size_gb = total_size_mb / 1024
        
        print(f"ğŸ“Š æ•°æ®ç»Ÿè®¡:")
        print(f"   æ€»æ–‡ä»¶æ•°: {file_analysis['total_files']}")
        print(f"   CSVæ–‡ä»¶: {file_analysis['csv_files']}")
        print(f"   Parquetæ–‡ä»¶: {file_analysis['parquet_files']}")
        print(f"   æ€»å¤§å°: {total_size_mb:.1f} MB ({total_size_gb:.2f} GB)")
        print(f"   è‚¡ç¥¨æ•°é‡: {len(file_analysis['symbols'])}")
        
        if file_analysis['files_by_size']:
            print(f"\nğŸ“‹ æœ€å¤§çš„5ä¸ªæ–‡ä»¶:")
            for file_info in file_analysis['files_by_size'][:5]:
                print(f"   {file_info['name']}: {file_info['size_mb']} MB")
        
        if file_analysis['date_range']:
            print(f"\nğŸ“… æ•°æ®æ—¥æœŸèŒƒå›´ï¼ˆéƒ¨åˆ†æ ·æœ¬ï¼‰:")
            for symbol, date_info in list(file_analysis['date_range'].items())[:5]:
                start_str = date_info['start'].strftime('%Y-%m-%d')
                end_str = date_info['end'].strftime('%Y-%m-%d')
                print(f"   {symbol}: {start_str} åˆ° {end_str} ({date_info['days']}å¤©)")
        
        # æ›´æ–°æŠ¥å‘Š
        self.report['data_status'] = {
            'directory_exists': True,
            'total_files': file_analysis['total_files'],
            'csv_files': file_analysis['csv_files'],
            'parquet_files': file_analysis['parquet_files'],
            'total_size_mb': round(total_size_mb, 2),
            'total_size_gb': round(total_size_gb, 3),
            'symbols_count': len(file_analysis['symbols']),
            'sample_symbols': list(file_analysis['symbols'])[:10],
            'largest_files': file_analysis['files_by_size'][:5],
            'date_range_samples': {
                symbol: {
                    'start': date_info['start'].strftime('%Y-%m-%d'),
                    'end': date_info['end'].strftime('%Y-%m-%d'),
                    'days': date_info['days']
                } 
                for symbol, date_info in list(file_analysis['date_range'].items())[:5]
            }
        }
    
    def generate_recommendations(self):
        """ç”Ÿæˆæ¨èå»ºè®®"""
        print("\nğŸ’¡ ç”Ÿæˆæ¨èå»ºè®®...")
        
        recommendations = []
        
        # TokençŠ¶æ€å»ºè®®
        if self.report['token_status'] == 'missing':
            recommendations.append({
                'type': 'critical',
                'title': 'é…ç½®ä¼˜çŸ¿Token',
                'description': 'æœªæ‰¾åˆ°ä¼˜çŸ¿API Tokenï¼Œè¯·é…ç½®åæ‰èƒ½ä½¿ç”¨æ•°æ®ä¸‹è½½åŠŸèƒ½',
                'action': 'è®¾ç½®ç¯å¢ƒå˜é‡ UQER_TOKEN æˆ–åˆ›å»ºé…ç½®æ–‡ä»¶'
            })
        elif self.report['token_status'] == 'connection_failed':
            recommendations.append({
                'type': 'warning',
                'title': 'æ£€æŸ¥ç½‘ç»œè¿æ¥',
                'description': 'ä¼˜çŸ¿APIè¿æ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œå’ŒTokenæœ‰æ•ˆæ€§',
                'action': 'ç¡®è®¤ç½‘ç»œç•…é€šä¸”Tokenæœªè¿‡æœŸ'
            })
        
        # æƒé™å»ºè®®
        if 'summary' in self.report['permissions']:
            for category, stats in self.report['permissions']['summary'].items():
                if stats['available'] < stats['total']:
                    recommendations.append({
                        'type': 'info',
                        'title': f'æ‰©å±•{category}æƒé™',
                        'description': f'{category}ç±»APIåªæœ‰{stats["available"]}/{stats["total"]}å¯ç”¨',
                        'action': 'è”ç³»ä¼˜çŸ¿å®¢æœç”³è¯·æ›´å¤šæƒé™æˆ–å‡çº§è´¦æˆ·ç­‰çº§'
                    })
        
        # æ•°æ®çŠ¶æ€å»ºè®®
        data_status = self.report['data_status']
        if data_status.get('total_files', 0) == 0:
            recommendations.append({
                'type': 'info',
                'title': 'å¼€å§‹æ•°æ®ä¸‹è½½',
                'description': 'æœªå‘ç°å†å²æ•°æ®ï¼Œå»ºè®®å¼€å§‹é¦–æ¬¡å…¨é‡ä¸‹è½½',
                'action': 'è¿è¡Œ python download_uqer_data.py'
            })
        elif data_status.get('total_files', 0) > 0:
            recommendations.append({
                'type': 'success',
                'title': 'è®¾ç½®å®šæœŸæ›´æ–°',
                'description': f'å·²æœ‰{data_status["total_files"]}ä¸ªæ•°æ®æ–‡ä»¶ï¼Œå»ºè®®é…ç½®è‡ªåŠ¨æ›´æ–°',
                'action': 'è¿è¡Œ python setup_scheduler.py é…ç½®å®šæ—¶ä»»åŠ¡'
            })
        
        # å­˜å‚¨ç©ºé—´å»ºè®®
        if data_status.get('total_size_gb', 0) > 5:
            recommendations.append({
                'type': 'warning',
                'title': 'ç›‘æ§å­˜å‚¨ç©ºé—´',
                'description': f'æ•°æ®å·²å ç”¨{data_status["total_size_gb"]:.1f}GBç©ºé—´',
                'action': 'å®šæœŸæ¸…ç†æ—§æ•°æ®æˆ–æ‰©å±•å­˜å‚¨ç©ºé—´'
            })
        
        self.report['recommendations'] = recommendations
        
        # æ˜¾ç¤ºå»ºè®®
        if recommendations:
            print("ğŸ“ å»ºè®®äº‹é¡¹:")
            for rec in recommendations:
                icon = {'critical': 'ğŸ”´', 'warning': 'ğŸŸ¡', 'info': 'ğŸ”µ', 'success': 'ğŸŸ¢'}.get(rec['type'], 'ğŸ’¡')
                print(f"   {icon} {rec['title']}")
                print(f"      {rec['description']}")
                print(f"      æ“ä½œ: {rec['action']}")
        else:
            print("âœ… ç³»ç»ŸçŠ¶æ€è‰¯å¥½ï¼Œæ— ç‰¹æ®Šå»ºè®®")
    
    def save_report(self):
        """ä¿å­˜æ£€æŸ¥æŠ¥å‘Š"""
        print("\nğŸ“ ä¿å­˜æ£€æŸ¥æŠ¥å‘Š...")
        
        # åˆ›å»ºæŠ¥å‘Šç›®å½•
        reports_dir = Path('reports')
        reports_dir.mkdir(exist_ok=True)
        
        # ç”ŸæˆæŠ¥å‘Šæ–‡ä»¶å
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        report_file = reports_dir / f'uqer_status_check_{timestamp}.json'
        
        # ä¿å­˜JSONæŠ¥å‘Š
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(self.report, f, ensure_ascii=False, indent=2, default=str)
        
        # ç”Ÿæˆæ–‡æœ¬æŠ¥å‘Š
        text_report = self.generate_text_report()
        text_report_file = reports_dir / f'uqer_status_check_{timestamp}.txt'
        
        with open(text_report_file, 'w', encoding='utf-8') as f:
            f.write(text_report)
        
        print(f"âœ… æŠ¥å‘Šå·²ä¿å­˜:")
        print(f"   JSON: {report_file}")
        print(f"   æ–‡æœ¬: {text_report_file}")
        
        return report_file, text_report_file
    
    def generate_text_report(self):
        """ç”Ÿæˆæ–‡æœ¬æ ¼å¼æŠ¥å‘Š"""
        report_lines = []
        report_lines.append("=" * 60)
        report_lines.append("ğŸ” ä¼˜çŸ¿æƒé™å’Œæ•°æ®çŠ¶æ€æ£€æŸ¥æŠ¥å‘Š")
        report_lines.append("=" * 60)
        report_lines.append(f"ğŸ“… æ£€æŸ¥æ—¶é—´: {self.report['check_time'].strftime('%Y-%m-%d %H:%M:%S')}")
        report_lines.append("")
        
        # TokençŠ¶æ€
        report_lines.append("ğŸ”‘ TokençŠ¶æ€:")
        status_icon = {'valid': 'âœ…', 'missing': 'âŒ', 'connection_failed': 'âš ï¸'}.get(
            self.report['token_status'], 'â“'
        )
        report_lines.append(f"   {status_icon} {self.report['token_status']}")
        report_lines.append("")
        
        # APIæƒé™
        report_lines.append("ğŸ“‹ APIæƒé™çŠ¶æ€:")
        if self.report['available_apis']:
            for api in self.report['available_apis']:
                status_icon = {'available': 'âœ…', 'available_but_empty': 'âš ï¸', 'error': 'âŒ'}.get(
                    api['status'], 'â“'
                )
                report_lines.append(f"   {status_icon} {api['name']}: {api['description']}")
        else:
            report_lines.append("   âŒ æ— å¯ç”¨API")
        report_lines.append("")
        
        # æ•°æ®çŠ¶æ€
        report_lines.append("ğŸ“‚ æ•°æ®çŠ¶æ€:")
        data_status = self.report['data_status']
        if data_status.get('directory_exists', False):
            report_lines.append(f"   ğŸ“ æ•°æ®ç›®å½•: å­˜åœ¨")
            report_lines.append(f"   ğŸ“Š æ–‡ä»¶æ€»æ•°: {data_status.get('total_files', 0)}")
            report_lines.append(f"   ğŸ“ˆ è‚¡ç¥¨æ•°é‡: {data_status.get('symbols_count', 0)}")
            report_lines.append(f"   ğŸ’¾ æ€»å¤§å°: {data_status.get('total_size_gb', 0):.2f} GB")
        else:
            report_lines.append("   âŒ æ•°æ®ç›®å½•ä¸å­˜åœ¨")
        report_lines.append("")
        
        # å»ºè®®äº‹é¡¹
        report_lines.append("ğŸ’¡ å»ºè®®äº‹é¡¹:")
        if self.report['recommendations']:
            for rec in self.report['recommendations']:
                icon = {'critical': 'ğŸ”´', 'warning': 'ğŸŸ¡', 'info': 'ğŸ”µ', 'success': 'ğŸŸ¢'}.get(rec['type'], 'ğŸ’¡')
                report_lines.append(f"   {icon} {rec['title']}")
                report_lines.append(f"      {rec['description']}")
                report_lines.append(f"      æ“ä½œ: {rec['action']}")
        else:
            report_lines.append("   âœ… ç³»ç»ŸçŠ¶æ€è‰¯å¥½")
        
        report_lines.append("")
        report_lines.append("=" * 60)
        
        return "\n".join(report_lines)
    
    def run_full_check(self):
        """è¿è¡Œå®Œæ•´æ£€æŸ¥"""
        print("ğŸš€ å¼€å§‹ä¼˜çŸ¿æƒé™å’Œæ•°æ®çŠ¶æ€æ£€æŸ¥")
        print("=" * 50)
        
        # 1. æ£€æŸ¥æƒé™
        permissions_ok = self.check_uqer_permissions()
        
        # 2. æ£€æŸ¥APIæ¥å£
        if permissions_ok:
            self.check_available_apis()
        
        # 3. æ£€æŸ¥å·²ä¸‹è½½æ•°æ®
        self.check_downloaded_data()
        
        # 4. ç”Ÿæˆå»ºè®®
        self.generate_recommendations()
        
        # 5. ä¿å­˜æŠ¥å‘Š
        report_files = self.save_report()
        
        print("\n" + "=" * 50)
        print("ğŸ‰ æ£€æŸ¥å®Œæˆ!")
        
        return self.report

def main():
    """ä¸»å‡½æ•°"""
    checker = UqerStatusChecker()
    report = checker.run_full_check()
    
    # æ˜¾ç¤ºç®€è¦æ€»ç»“
    print(f"\nğŸ“Š æ£€æŸ¥æ€»ç»“:")
    print(f"   TokençŠ¶æ€: {report['token_status']}")
    print(f"   å¯ç”¨API: {len([api for api in report.get('available_apis', []) if api['status'] == 'available'])}")
    print(f"   æ•°æ®æ–‡ä»¶: {report['data_status'].get('total_files', 0)}")
    print(f"   å»ºè®®äº‹é¡¹: {len(report.get('recommendations', []))}")
    
    return report

if __name__ == "__main__":
    main()